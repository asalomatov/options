{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgPK9lEHAxrt",
        "outputId": "3acf2469-82e3-4ac1-e4c0-21985b2973f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFh6e6yjnKK7",
        "outputId": "b551e62c-411a-4b24-f86a-635813e2e8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/924.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/924.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/924.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m727.0/924.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.6/924.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q keras-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lATimc-gpJQI",
        "outputId": "f2d6d9c4-f4f8-4050-9ff6-e66cbfbc7ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX-EJFZanKK8"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LNBC3ef8nKK8"
      },
      "outputs": [],
      "source": [
        "import jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH-r2BDQnKK8",
        "outputId": "9eec99b8-4849-4e2d-d918-168bfc2c5a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using JAX backend.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "\n",
        "# Note that keras_core should only be imported after the backend\n",
        "# has been configured. The backend cannot be changed once the\n",
        "# package is imported.\n",
        "import keras_core as keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGIcqjR_nKK8",
        "outputId": "f1e67b89-1549-451d-ebbe-f6ca501f333f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras_core' from '/usr/local/lib/python3.10/dist-packages/keras_core/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja6-R0JoSSfp",
        "outputId": "26cf2c0e-0f5b-4f2e-8d72-d577cb35c43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.28)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3.post1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "# get the data\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OsvpsSxRSYb3"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjRkWnTXnKK8",
        "outputId": "d48d4f35-6820-4a50-911f-7b4ad5184032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  5 of 5 completed\n",
            "            Adj Close                                  Close           \\\n",
            "                  AGG DBC VIXY        VTI   ^VIX         AGG DBC VIXY   \n",
            "Date                                                                    \n",
            "2006-01-03  58.752556 NaN  NaN  45.043755  11.14  100.639999 NaN  NaN   \n",
            "2006-01-04  58.892632 NaN  NaN  45.371281  11.37  100.879997 NaN  NaN   \n",
            "2006-01-05  58.892632 NaN  NaN  45.342487  11.31  100.879997 NaN  NaN   \n",
            "2006-01-06  58.758373 NaN  NaN  45.788765  11.00  100.650002 NaN  NaN   \n",
            "2006-01-09  58.822563 NaN  NaN  45.957932  11.13  100.760002 NaN  NaN   \n",
            "\n",
            "                              ...        Open                             \\\n",
            "                  VTI   ^VIX  ...         AGG DBC VIXY        VTI   ^VIX   \n",
            "Date                          ...                                          \n",
            "2006-01-03  62.575001  11.14  ...  100.470001 NaN  NaN  61.855000  12.25   \n",
            "2006-01-04  63.029999  11.37  ...  100.690002 NaN  NaN  62.660000  11.22   \n",
            "2006-01-05  62.990002  11.31  ...  100.820000 NaN  NaN  62.985001  11.43   \n",
            "2006-01-06  63.610001  11.00  ...  100.879997 NaN  NaN  63.415001  11.23   \n",
            "2006-01-09  63.845001  11.13  ...  100.739998 NaN  NaN  63.665001  11.35   \n",
            "\n",
            "            Volume                         \n",
            "               AGG DBC VIXY      VTI ^VIX  \n",
            "Date                                       \n",
            "2006-01-03  170600 NaN  NaN  1769800    0  \n",
            "2006-01-04  284500 NaN  NaN   763600    0  \n",
            "2006-01-05  203100 NaN  NaN   258200    0  \n",
            "2006-01-06  201100 NaN  NaN   436000    0  \n",
            "2006-01-09  170500 NaN  NaN   689600    0  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "            Adj Close                                               Close  \\\n",
            "                  AGG        DBC       VIXY         VTI   ^VIX        AGG   \n",
            "Date                                                                        \n",
            "2023-09-06  95.430000  25.059999  21.780001  221.940002  14.45  95.430000   \n",
            "2023-09-07  95.730003  25.010000  21.740000  221.179993  14.40  95.730003   \n",
            "2023-09-08  95.779999  25.059999  21.309999  221.419998  13.84  95.779999   \n",
            "2023-09-11  95.669998  25.209999  20.760000  222.809998  13.80  95.669998   \n",
            "2023-09-12  95.705704  25.299999  20.930000  221.679993  14.27  95.705704   \n",
            "\n",
            "                                                     ...       Open  \\\n",
            "                  DBC       VIXY         VTI   ^VIX  ...        AGG   \n",
            "Date                                                 ...              \n",
            "2023-09-06  25.059999  21.780001  221.940002  14.45  ...  95.629997   \n",
            "2023-09-07  25.010000  21.740000  221.179993  14.40  ...  95.589996   \n",
            "2023-09-08  25.059999  21.309999  221.419998  13.84  ...  95.930000   \n",
            "2023-09-11  25.209999  20.760000  222.809998  13.80  ...  95.660004   \n",
            "2023-09-12  25.299999  20.930000  221.679993  14.27  ...  95.709999   \n",
            "\n",
            "                                                      Volume             \\\n",
            "                  DBC       VIXY         VTI   ^VIX      AGG        DBC   \n",
            "Date                                                                      \n",
            "2023-09-06  24.959999  21.450001  222.990005  14.27  8379200   843800.0   \n",
            "2023-09-07  24.990000  22.459999  220.380005  14.81  5077800   388800.0   \n",
            "2023-09-08  25.020000  21.670000  221.210007  14.22  4774200   611500.0   \n",
            "2023-09-11  25.250000  20.900000  222.660004  14.17  4077200   553900.0   \n",
            "2023-09-12  25.290001  21.010000  222.139999  14.02  4367689  1014457.0   \n",
            "\n",
            "                                     \n",
            "                 VIXY      VTI ^VIX  \n",
            "Date                                 \n",
            "2023-09-06  2995500.0  2473700    0  \n",
            "2023-09-07  2814200.0  2964700    0  \n",
            "2023-09-08  3085400.0  2244400    0  \n",
            "2023-09-11  2662400.0  2087900    0  \n",
            "2023-09-12  2528908.0  2280535    0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "start_date = '2006-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "# Add multiple space separated tickers here\n",
        "ticker = 'VTI AGG DBC VIXY ^VIX'\n",
        "data = yf.download(ticker, start_date, end_date)\n",
        "print(data.head())\n",
        "print(data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgRGt-DBSsQs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnhcSOvESqMA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS67lc-9nKK9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rjra_QLxe9E7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# import optax\n",
        "# import yfinance as yf\n",
        "# from ml.ml_utils import  binary_classification_metrics\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lEDnC57e9E-"
      },
      "outputs": [],
      "source": [
        "# needed this on mac to get autocomplete to work\n",
        "# %config Completer.use_jedi = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAqRbBRAxrw"
      },
      "source": [
        "### What device is being used for computing?\n",
        "\n",
        "Use conda to install cuda: conda install cuda -c nvidia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho53t9uSAxrw",
        "outputId": "7592ae5d-193e-444e-ac9a-9f37103053b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[CpuDevice(id=0)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k4oAnNnCAxrw",
        "outputId": "0ed92a98-79bc-4766-e4f8-9762dc976e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.devices()[0].platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq3I7_b4nKLB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zc_75gaAxrw",
        "outputId": "4e6fbcea-fd69-456d-8943-3b15820c37fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def jax_has_gpu():\n",
        "    try:\n",
        "        _ = jax.device_put(jax.numpy.ones(1), device=jax.devices('gpu')[0])\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "jax_has_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LQbiExqe9FN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc2KmO3de9FN"
      },
      "source": [
        "### Fully connected neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf1_Tm_ee9FN"
      },
      "source": [
        "$x \\in R^n$, an input vector, transformed to a vector of length $m$ via\n",
        "$$\n",
        "x = xW + b, \\newline\n",
        "x = activation\\_function(x),\n",
        "$$\n",
        "where $W \\in R^{n\\times m}, b \\in R^m$.\n",
        "This represents one layer of the network. The final layer transforms to the dimension of the output, and in case of classsification - sigmoid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDVc1PGce9FN"
      },
      "outputs": [],
      "source": [
        "# A link to the data is availailable in the following blog post\n",
        "# https://scipython.com/blog/a-shallow-neural-network-for-simple-nonlinear-classification/\n",
        "df = pd.read_csv('../non_linear_class_example/labeled_points.txt', sep=' ',\n",
        "                usecols=[1,3,5], names=['x1', 'x2', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jxFukGFe9FN",
        "outputId": "c768784e-9557-457e-ad90-0d67ef3ceae8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50873</td>\n",
              "      <td>0.08490</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.96767</td>\n",
              "      <td>0.96752</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.72096</td>\n",
              "      <td>0.90628</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.66071</td>\n",
              "      <td>0.32757</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.48690</td>\n",
              "      <td>0.58265</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        x1       x2  label\n",
              "0  0.50873  0.08490      1\n",
              "1  0.96767  0.96752      1\n",
              "2  0.72096  0.90628      1\n",
              "3  0.66071  0.32757      1\n",
              "4  0.48690  0.58265      0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFDqqQ7WpJQO",
        "outputId": "4ec5d983-0994-4963-c211-d1ecffafc94d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2506, 3)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD9-_C_ie9FN",
        "outputId": "e3b5d89d-e3e1-42a3-b440-2330884e3af3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fecb0465420>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "df_cl1 = df[df.label == 0]\n",
        "df_cl2 = df[df.label == 1]\n",
        "ax1.scatter(df_cl1.x1, df_cl1.x2, s=5, c='b', marker=\"s\", label='class1')\n",
        "ax1.scatter(df_cl2.x1, df_cl2.x2, s=5, c='r', marker=\"s\", label='class2')\n",
        "fig.tight_layout()\n",
        "plt.title('Two classes')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcziA3tze9FN",
        "outputId": "e7954141-2c31-4d09-8538-b4686eb52cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2506, 2)\n",
            "(2506,)\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "x = np.array(df[['x1', 'x2']])\n",
        "y = np.array(df['label'])\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xqSv6pge9FO",
        "outputId": "ef877d46-7353-4899-e36a-ac8b2d4e2efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1754, 2), (752, 2), (1754, 2), (752, 2)]\n",
            "1754.0 752.0\n"
          ]
        }
      ],
      "source": [
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x,\n",
        "    y,\n",
        "    stratify=y,\n",
        "    test_size=0.3, random_state=212\n",
        ")\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "print(list(map(lambda i: i.shape, (X_train, X_test, y_train, y_test))))\n",
        "print(y_train.sum(), y_test.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm5jaLv8pJQO",
        "outputId": "4bf6a104-3714-48c5-9597-d58293f04900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1754, 1, 2), (752, 1, 2), (1754,), (752,)]\n",
            "1051 451\n"
          ]
        }
      ],
      "source": [
        "# adjust dim\n",
        "X_train = np.expand_dims(X_train, axis=1)\n",
        "X_test = np.expand_dims(X_test, axis=1)\n",
        "print(list(map(lambda i: i.shape, (X_train, X_test, y_train, y_test))))\n",
        "print(y_train.sum(), y_test.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n3bXGiJpJQO",
        "outputId": "419d2500-658b-422d-8fe5-bad69256ee24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.78773, 0.50679],\n",
              "       [0.741  , 0.72341],\n",
              "       [0.71376, 0.54406],\n",
              "       ...,\n",
              "       [0.6239 , 0.37316],\n",
              "       [0.46939, 0.59623],\n",
              "       [0.62713, 0.77273]])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxpWfKSNpJQO",
        "outputId": "45ff05ae-4a5e-4bef-beee-9e9997c6ef07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.utils.to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-nlu0b8pJQO",
        "outputId": "725050be-daff-4a6a-9018-b0de744822d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb4S-0uupJQO"
      },
      "outputs": [],
      "source": [
        "# keras sequential\n",
        "num_classes = 2\n",
        "input_shape = (2,)\n",
        "hidden_dim = 128\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=input_shape),\n",
        "        keras.layers.Dense(hidden_dim, activation=\"relu\"),\n",
        "        keras.layers.Dense(hidden_dim, activation=\"relu\"),\n",
        "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxUd8luypJQO",
        "outputId": "2cf50313-4147-4085-bf0b-111be2516d6b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │        <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m384\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │     \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │        \u001b[38;5;34m258\u001b[0m │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,154</span> (536.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,154\u001b[0m (536.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,154</span> (536.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,154\u001b[0m (536.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OdufV5qpJQO"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\n",
        "        keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
        "        keras.metrics.AUC(name='auc')\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppQ-ZhF3pJQO",
        "outputId": "384d55a8-82ee-4f49-d6e6-685325ad38fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9248 - auc: 0.9565 - loss: 0.2458 - val_acc: 0.9280 - val_auc: 0.9638 - val_loss: 0.1842\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9242 - auc: 0.9577 - loss: 0.2412 - val_acc: 0.9318 - val_auc: 0.9626 - val_loss: 0.1838\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9274 - auc: 0.9601 - loss: 0.2340 - val_acc: 0.9242 - val_auc: 0.9630 - val_loss: 0.1803\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9375 - auc: 0.9699 - loss: 0.2090 - val_acc: 0.9394 - val_auc: 0.9638 - val_loss: 0.1799\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9234 - auc: 0.9588 - loss: 0.2392 - val_acc: 0.9280 - val_auc: 0.9645 - val_loss: 0.1831\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9207 - auc: 0.9583 - loss: 0.2415 - val_acc: 0.9205 - val_auc: 0.9637 - val_loss: 0.1812\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9271 - auc: 0.9613 - loss: 0.2287 - val_acc: 0.9242 - val_auc: 0.9642 - val_loss: 0.1819\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9189 - auc: 0.9562 - loss: 0.2467 - val_acc: 0.9280 - val_auc: 0.9647 - val_loss: 0.1801\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9307 - auc: 0.9638 - loss: 0.2229 - val_acc: 0.9280 - val_auc: 0.9651 - val_loss: 0.1761\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9284 - auc: 0.9633 - loss: 0.2231 - val_acc: 0.9318 - val_auc: 0.9646 - val_loss: 0.1795\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9138 - auc: 0.9561 - loss: 0.2423 - val_acc: 0.9280 - val_auc: 0.9653 - val_loss: 0.1751\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9297 - auc: 0.9617 - loss: 0.2274 - val_acc: 0.9318 - val_auc: 0.9651 - val_loss: 0.1733\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9248 - auc: 0.9611 - loss: 0.2303 - val_acc: 0.9318 - val_auc: 0.9653 - val_loss: 0.1772\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9197 - auc: 0.9635 - loss: 0.2267 - val_acc: 0.9242 - val_auc: 0.9626 - val_loss: 0.1783\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9129 - auc: 0.9620 - loss: 0.2298 - val_acc: 0.9318 - val_auc: 0.9631 - val_loss: 0.1760\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9205 - auc: 0.9592 - loss: 0.2354 - val_acc: 0.9280 - val_auc: 0.9614 - val_loss: 0.1853\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9188 - auc: 0.9523 - loss: 0.2498 - val_acc: 0.9356 - val_auc: 0.9646 - val_loss: 0.1727\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9219 - auc: 0.9652 - loss: 0.2201 - val_acc: 0.9356 - val_auc: 0.9654 - val_loss: 0.1699\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9283 - auc: 0.9632 - loss: 0.2218 - val_acc: 0.9356 - val_auc: 0.9654 - val_loss: 0.1747\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9276 - auc: 0.9592 - loss: 0.2315 - val_acc: 0.9356 - val_auc: 0.9650 - val_loss: 0.1717\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9268 - auc: 0.9628 - loss: 0.2209 - val_acc: 0.9280 - val_auc: 0.9639 - val_loss: 0.1729\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9079 - auc: 0.9574 - loss: 0.2410 - val_acc: 0.9167 - val_auc: 0.9568 - val_loss: 0.2005\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9085 - auc: 0.9575 - loss: 0.2422 - val_acc: 0.9318 - val_auc: 0.9629 - val_loss: 0.1764\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9250 - auc: 0.9600 - loss: 0.2303 - val_acc: 0.9280 - val_auc: 0.9617 - val_loss: 0.1849\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9121 - auc: 0.9612 - loss: 0.2299 - val_acc: 0.9242 - val_auc: 0.9652 - val_loss: 0.1699\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9221 - auc: 0.9564 - loss: 0.2376 - val_acc: 0.9318 - val_auc: 0.9649 - val_loss: 0.1729\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9294 - auc: 0.9639 - loss: 0.2169 - val_acc: 0.9432 - val_auc: 0.9675 - val_loss: 0.1646\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9197 - auc: 0.9611 - loss: 0.2307 - val_acc: 0.9318 - val_auc: 0.9668 - val_loss: 0.1682\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9249 - auc: 0.9628 - loss: 0.2205 - val_acc: 0.9280 - val_auc: 0.9656 - val_loss: 0.1665\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9285 - auc: 0.9688 - loss: 0.2092 - val_acc: 0.9280 - val_auc: 0.9671 - val_loss: 0.1679\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9295 - auc: 0.9660 - loss: 0.2133 - val_acc: 0.9356 - val_auc: 0.9688 - val_loss: 0.1647\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9226 - auc: 0.9611 - loss: 0.2254 - val_acc: 0.9091 - val_auc: 0.9671 - val_loss: 0.1774\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9228 - auc: 0.9672 - loss: 0.2148 - val_acc: 0.9242 - val_auc: 0.9695 - val_loss: 0.1679\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9123 - auc: 0.9633 - loss: 0.2275 - val_acc: 0.9129 - val_auc: 0.9685 - val_loss: 0.1775\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8987 - auc: 0.9530 - loss: 0.2572 - val_acc: 0.9280 - val_auc: 0.9711 - val_loss: 0.1623\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9206 - auc: 0.9643 - loss: 0.2249 - val_acc: 0.9242 - val_auc: 0.9702 - val_loss: 0.1623\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9245 - auc: 0.9664 - loss: 0.2196 - val_acc: 0.9432 - val_auc: 0.9735 - val_loss: 0.1595\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9341 - auc: 0.9720 - loss: 0.1973 - val_acc: 0.9205 - val_auc: 0.9705 - val_loss: 0.1683\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9195 - auc: 0.9636 - loss: 0.2246 - val_acc: 0.9356 - val_auc: 0.9743 - val_loss: 0.1608\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9345 - auc: 0.9722 - loss: 0.2016 - val_acc: 0.9205 - val_auc: 0.9714 - val_loss: 0.1678\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9291 - auc: 0.9733 - loss: 0.2021 - val_acc: 0.9318 - val_auc: 0.9744 - val_loss: 0.1595\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9299 - auc: 0.9724 - loss: 0.2068 - val_acc: 0.9356 - val_auc: 0.9751 - val_loss: 0.1565\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9109 - auc: 0.9639 - loss: 0.2327 - val_acc: 0.9318 - val_auc: 0.9729 - val_loss: 0.1611\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9199 - auc: 0.9693 - loss: 0.2183 - val_acc: 0.9356 - val_auc: 0.9760 - val_loss: 0.1550\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9263 - auc: 0.9744 - loss: 0.2031 - val_acc: 0.9394 - val_auc: 0.9763 - val_loss: 0.1550\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9218 - auc: 0.9737 - loss: 0.2056 - val_acc: 0.9356 - val_auc: 0.9755 - val_loss: 0.1545\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9290 - auc: 0.9752 - loss: 0.2053 - val_acc: 0.9394 - val_auc: 0.9776 - val_loss: 0.1538\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9151 - auc: 0.9723 - loss: 0.2162 - val_acc: 0.9280 - val_auc: 0.9786 - val_loss: 0.1515\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9293 - auc: 0.9767 - loss: 0.1993 - val_acc: 0.9205 - val_auc: 0.9760 - val_loss: 0.1621\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9151 - auc: 0.9738 - loss: 0.2126 - val_acc: 0.9242 - val_auc: 0.9775 - val_loss: 0.1621\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9313 - auc: 0.9764 - loss: 0.2006 - val_acc: 0.9356 - val_auc: 0.9796 - val_loss: 0.1473\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9282 - auc: 0.9761 - loss: 0.2015 - val_acc: 0.9280 - val_auc: 0.9791 - val_loss: 0.1533\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9278 - auc: 0.9778 - loss: 0.1977 - val_acc: 0.9394 - val_auc: 0.9815 - val_loss: 0.1482\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9299 - auc: 0.9801 - loss: 0.1918 - val_acc: 0.9356 - val_auc: 0.9800 - val_loss: 0.1526\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9278 - auc: 0.9799 - loss: 0.1914 - val_acc: 0.9280 - val_auc: 0.9801 - val_loss: 0.1530\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9303 - auc: 0.9811 - loss: 0.1898 - val_acc: 0.9394 - val_auc: 0.9820 - val_loss: 0.1433\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9346 - auc: 0.9844 - loss: 0.1774 - val_acc: 0.9356 - val_auc: 0.9823 - val_loss: 0.1450\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9240 - auc: 0.9795 - loss: 0.1992 - val_acc: 0.9318 - val_auc: 0.9825 - val_loss: 0.1459\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9217 - auc: 0.9790 - loss: 0.1996 - val_acc: 0.9280 - val_auc: 0.9819 - val_loss: 0.1460\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9266 - auc: 0.9825 - loss: 0.1891 - val_acc: 0.9318 - val_auc: 0.9837 - val_loss: 0.1412\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9355 - auc: 0.9852 - loss: 0.1765 - val_acc: 0.9280 - val_auc: 0.9834 - val_loss: 0.1428\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9280 - auc: 0.9825 - loss: 0.1874 - val_acc: 0.9356 - val_auc: 0.9859 - val_loss: 0.1353\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9319 - auc: 0.9856 - loss: 0.1749 - val_acc: 0.9394 - val_auc: 0.9852 - val_loss: 0.1357\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9352 - auc: 0.9875 - loss: 0.1690 - val_acc: 0.9280 - val_auc: 0.9837 - val_loss: 0.1476\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9273 - auc: 0.9833 - loss: 0.1870 - val_acc: 0.9280 - val_auc: 0.9855 - val_loss: 0.1375\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9222 - auc: 0.9875 - loss: 0.1706 - val_acc: 0.9318 - val_auc: 0.9879 - val_loss: 0.1352\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9372 - auc: 0.9892 - loss: 0.1625 - val_acc: 0.9356 - val_auc: 0.9870 - val_loss: 0.1323\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9349 - auc: 0.9883 - loss: 0.1651 - val_acc: 0.9394 - val_auc: 0.9893 - val_loss: 0.1304\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9286 - auc: 0.9887 - loss: 0.1671 - val_acc: 0.9432 - val_auc: 0.9879 - val_loss: 0.1293\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9317 - auc: 0.9881 - loss: 0.1632 - val_acc: 0.9280 - val_auc: 0.9875 - val_loss: 0.1393\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9272 - auc: 0.9886 - loss: 0.1676 - val_acc: 0.9356 - val_auc: 0.9890 - val_loss: 0.1273\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9313 - auc: 0.9868 - loss: 0.1677 - val_acc: 0.9280 - val_auc: 0.9887 - val_loss: 0.1295\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9220 - auc: 0.9867 - loss: 0.1690 - val_acc: 0.9356 - val_auc: 0.9885 - val_loss: 0.1272\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9240 - auc: 0.9894 - loss: 0.1574 - val_acc: 0.9280 - val_auc: 0.9896 - val_loss: 0.1243\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9464 - auc: 0.9924 - loss: 0.1364 - val_acc: 0.9318 - val_auc: 0.9896 - val_loss: 0.1242\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9322 - auc: 0.9914 - loss: 0.1522 - val_acc: 0.9318 - val_auc: 0.9911 - val_loss: 0.1178\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9354 - auc: 0.9914 - loss: 0.1452 - val_acc: 0.9394 - val_auc: 0.9912 - val_loss: 0.1137\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9371 - auc: 0.9913 - loss: 0.1441 - val_acc: 0.9394 - val_auc: 0.9923 - val_loss: 0.1172\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9358 - auc: 0.9934 - loss: 0.1357 - val_acc: 0.9394 - val_auc: 0.9910 - val_loss: 0.1134\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9308 - auc: 0.9913 - loss: 0.1442 - val_acc: 0.9356 - val_auc: 0.9931 - val_loss: 0.1107\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9341 - auc: 0.9918 - loss: 0.1417 - val_acc: 0.9508 - val_auc: 0.9931 - val_loss: 0.1190\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9435 - auc: 0.9933 - loss: 0.1344 - val_acc: 0.9508 - val_auc: 0.9927 - val_loss: 0.1082\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9356 - auc: 0.9924 - loss: 0.1372 - val_acc: 0.9318 - val_auc: 0.9911 - val_loss: 0.1120\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9265 - auc: 0.9914 - loss: 0.1403 - val_acc: 0.9394 - val_auc: 0.9922 - val_loss: 0.1077\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9389 - auc: 0.9937 - loss: 0.1263 - val_acc: 0.9432 - val_auc: 0.9929 - val_loss: 0.1048\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9402 - auc: 0.9934 - loss: 0.1291 - val_acc: 0.9545 - val_auc: 0.9939 - val_loss: 0.1054\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9509 - auc: 0.9947 - loss: 0.1288 - val_acc: 0.9356 - val_auc: 0.9920 - val_loss: 0.1067\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9436 - auc: 0.9931 - loss: 0.1259 - val_acc: 0.9621 - val_auc: 0.9943 - val_loss: 0.1046\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9638 - auc: 0.9960 - loss: 0.1239 - val_acc: 0.9697 - val_auc: 0.9948 - val_loss: 0.0980\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9576 - auc: 0.9962 - loss: 0.1155 - val_acc: 0.9470 - val_auc: 0.9947 - val_loss: 0.0925\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9384 - auc: 0.9926 - loss: 0.1296 - val_acc: 0.9659 - val_auc: 0.9949 - val_loss: 0.0937\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9673 - auc: 0.9968 - loss: 0.1076 - val_acc: 0.9621 - val_auc: 0.9956 - val_loss: 0.0956\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9593 - auc: 0.9959 - loss: 0.1183 - val_acc: 0.9735 - val_auc: 0.9979 - val_loss: 0.0913\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9681 - auc: 0.9954 - loss: 0.1257 - val_acc: 0.9583 - val_auc: 0.9939 - val_loss: 0.1044\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9631 - auc: 0.9964 - loss: 0.1155 - val_acc: 0.9773 - val_auc: 0.9983 - val_loss: 0.0946\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9720 - auc: 0.9964 - loss: 0.1211 - val_acc: 0.9735 - val_auc: 0.9975 - val_loss: 0.0867\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9604 - auc: 0.9959 - loss: 0.1126 - val_acc: 0.9735 - val_auc: 0.9984 - val_loss: 0.0943\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9734 - auc: 0.9970 - loss: 0.1101 - val_acc: 0.9659 - val_auc: 0.9971 - val_loss: 0.0832\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9702 - auc: 0.9968 - loss: 0.1072 - val_acc: 0.9735 - val_auc: 0.9985 - val_loss: 0.0885\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9820 - auc: 0.9984 - loss: 0.0932 - val_acc: 0.9811 - val_auc: 0.9977 - val_loss: 0.0818\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=\"model_at_epoch_{epoch}.keras\"),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.15,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F-0qEVxpJQO",
        "outputId": "a1e25a92-d9a4-440e-95fb-7d3eac67604b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.09887848049402237, 0.9694148898124695, 0.9976348876953125]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnvNMhkcpJQP",
        "outputId": "9ddd3836-b910-41b5-eb80-1f3f51b2c151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor shape=(None, 2), dtype=float32, name=keras_tensor_32>"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[2].output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhjkj3tZpJQP",
        "outputId": "07c37037-a070-47aa-843a-eff812c1fc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206us/step      \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.6266550e-04, 9.9983728e-01],\n",
              "       [9.9050832e-01, 9.4917193e-03],\n",
              "       [2.9077446e-10, 1.0000000e+00],\n",
              "       ...,\n",
              "       [9.8016912e-01, 1.9830808e-02],\n",
              "       [8.7597519e-01, 1.2402478e-01],\n",
              "       [1.9679922e-01, 8.0320078e-01]], dtype=float32)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeeeK2vJpJQP",
        "outputId": "b3fc4bc2-fa58-43c1-fcd4-547db396e297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step      \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Array(0.9694149, dtype=float32)"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.metrics.categorical_accuracy(model.predict(X_test), y_test).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV2nX8mcpJQP"
      },
      "outputs": [],
      "source": [
        "# now functional model definition\n",
        "num_classes = 2\n",
        "input_shape = (2,)\n",
        "hidden_dim = 128\n",
        "\n",
        "def create_model(input_dim, output_dim):\n",
        "    inputs = keras.layers.Input(shape=input_dim)\n",
        "    x = keras.layers.Dense(units=hidden_dim, activation='relu')(inputs)\n",
        "    x = keras.layers.Dense(units=hidden_dim, activation='relu')(x)\n",
        "    outputs = keras.layers.Dense(units=output_dim, activation='softmax')(x)\n",
        "    return keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model = create_model(input_shape, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vryi2I-upJQP",
        "outputId": "34ab0da6-a2b7-4d52-908f-5661d33b1b34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │        <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
              "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │          \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │        \u001b[38;5;34m384\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │     \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │        \u001b[38;5;34m258\u001b[0m │\n",
              "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,154</span> (536.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,154\u001b[0m (536.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,154</span> (536.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,154\u001b[0m (536.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbvpzpWlpJQP"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    metrics=[\n",
        "        keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
        "        keras.metrics.AUC(name='auc')\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_P3Iv-9pJQP",
        "outputId": "c39f2bdc-9fb6-4170-81d0-604937c788b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step - acc: 0.5332 - auc: 0.5695 - loss: 0.6821 - val_acc: 0.5871 - val_auc: 0.7559 - val_loss: 0.6270\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6093 - auc: 0.7424 - loss: 0.6366 - val_acc: 0.5871 - val_auc: 0.7807 - val_loss: 0.5970\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5777 - auc: 0.7528 - loss: 0.6281 - val_acc: 0.5871 - val_auc: 0.8017 - val_loss: 0.5733\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6182 - auc: 0.8064 - loss: 0.5793 - val_acc: 0.5871 - val_auc: 0.8039 - val_loss: 0.5390\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6284 - auc: 0.7984 - loss: 0.5575 - val_acc: 0.7652 - val_auc: 0.8578 - val_loss: 0.5124\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7310 - auc: 0.8375 - loss: 0.5200 - val_acc: 0.7917 - val_auc: 0.8808 - val_loss: 0.4705\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7630 - auc: 0.8792 - loss: 0.4862 - val_acc: 0.8182 - val_auc: 0.9271 - val_loss: 0.4338\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7822 - auc: 0.8926 - loss: 0.4472 - val_acc: 0.8636 - val_auc: 0.9495 - val_loss: 0.4025\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8232 - auc: 0.9169 - loss: 0.4153 - val_acc: 0.8598 - val_auc: 0.9468 - val_loss: 0.3645\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8433 - auc: 0.9236 - loss: 0.3839 - val_acc: 0.8636 - val_auc: 0.9522 - val_loss: 0.3548\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8531 - auc: 0.9280 - loss: 0.3682 - val_acc: 0.8939 - val_auc: 0.9563 - val_loss: 0.3234\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8495 - auc: 0.9254 - loss: 0.3621 - val_acc: 0.8750 - val_auc: 0.9492 - val_loss: 0.3304\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8600 - auc: 0.9296 - loss: 0.3486 - val_acc: 0.8939 - val_auc: 0.9569 - val_loss: 0.2889\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8629 - auc: 0.9299 - loss: 0.3439 - val_acc: 0.8939 - val_auc: 0.9588 - val_loss: 0.2775\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8659 - auc: 0.9304 - loss: 0.3369 - val_acc: 0.9015 - val_auc: 0.9592 - val_loss: 0.2778\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8682 - auc: 0.9298 - loss: 0.3378 - val_acc: 0.9205 - val_auc: 0.9602 - val_loss: 0.2661\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8640 - auc: 0.9315 - loss: 0.3324 - val_acc: 0.9129 - val_auc: 0.9604 - val_loss: 0.2599\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8751 - auc: 0.9383 - loss: 0.3168 - val_acc: 0.9167 - val_auc: 0.9604 - val_loss: 0.2567\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8726 - auc: 0.9356 - loss: 0.3211 - val_acc: 0.8902 - val_auc: 0.9590 - val_loss: 0.2490\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8974 - auc: 0.9517 - loss: 0.2883 - val_acc: 0.8939 - val_auc: 0.9598 - val_loss: 0.2436\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8656 - auc: 0.9364 - loss: 0.3191 - val_acc: 0.9091 - val_auc: 0.9607 - val_loss: 0.2404\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8783 - auc: 0.9432 - loss: 0.3042 - val_acc: 0.9280 - val_auc: 0.9583 - val_loss: 0.2460\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8870 - auc: 0.9461 - loss: 0.2944 - val_acc: 0.9280 - val_auc: 0.9591 - val_loss: 0.2380\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8964 - auc: 0.9511 - loss: 0.2834 - val_acc: 0.8902 - val_auc: 0.9588 - val_loss: 0.2324\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8978 - auc: 0.9491 - loss: 0.2853 - val_acc: 0.9167 - val_auc: 0.9595 - val_loss: 0.2319\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8911 - auc: 0.9503 - loss: 0.2843 - val_acc: 0.9242 - val_auc: 0.9550 - val_loss: 0.2395\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8781 - auc: 0.9428 - loss: 0.2973 - val_acc: 0.9129 - val_auc: 0.9569 - val_loss: 0.2314\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9061 - auc: 0.9508 - loss: 0.2823 - val_acc: 0.9053 - val_auc: 0.9588 - val_loss: 0.2263\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9049 - auc: 0.9577 - loss: 0.2668 - val_acc: 0.8939 - val_auc: 0.9572 - val_loss: 0.2272\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9009 - auc: 0.9523 - loss: 0.2762 - val_acc: 0.9280 - val_auc: 0.9582 - val_loss: 0.2202\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8993 - auc: 0.9463 - loss: 0.2905 - val_acc: 0.9318 - val_auc: 0.9583 - val_loss: 0.2207\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9039 - auc: 0.9517 - loss: 0.2752 - val_acc: 0.9167 - val_auc: 0.9598 - val_loss: 0.2159\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9146 - auc: 0.9566 - loss: 0.2615 - val_acc: 0.9129 - val_auc: 0.9603 - val_loss: 0.2134\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9056 - auc: 0.9484 - loss: 0.2841 - val_acc: 0.8977 - val_auc: 0.9588 - val_loss: 0.2165\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8999 - auc: 0.9487 - loss: 0.2843 - val_acc: 0.8977 - val_auc: 0.9598 - val_loss: 0.2151\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.8986 - auc: 0.9446 - loss: 0.2923 - val_acc: 0.9167 - val_auc: 0.9605 - val_loss: 0.2110\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9123 - auc: 0.9543 - loss: 0.2657 - val_acc: 0.9167 - val_auc: 0.9606 - val_loss: 0.2061\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9011 - auc: 0.9478 - loss: 0.2818 - val_acc: 0.9280 - val_auc: 0.9601 - val_loss: 0.2098\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9153 - auc: 0.9578 - loss: 0.2602 - val_acc: 0.9318 - val_auc: 0.9589 - val_loss: 0.2054\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9167 - auc: 0.9548 - loss: 0.2602 - val_acc: 0.9167 - val_auc: 0.9606 - val_loss: 0.2080\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9135 - auc: 0.9562 - loss: 0.2588 - val_acc: 0.9356 - val_auc: 0.9608 - val_loss: 0.2043\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9132 - auc: 0.9530 - loss: 0.2637 - val_acc: 0.9205 - val_auc: 0.9621 - val_loss: 0.1982\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9221 - auc: 0.9583 - loss: 0.2521 - val_acc: 0.8977 - val_auc: 0.9598 - val_loss: 0.2064\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9055 - auc: 0.9512 - loss: 0.2726 - val_acc: 0.8977 - val_auc: 0.9596 - val_loss: 0.2066\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.8976 - auc: 0.9504 - loss: 0.2719 - val_acc: 0.9091 - val_auc: 0.9614 - val_loss: 0.2018\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9170 - auc: 0.9606 - loss: 0.2437 - val_acc: 0.9242 - val_auc: 0.9632 - val_loss: 0.1903\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9304 - auc: 0.9609 - loss: 0.2374 - val_acc: 0.9053 - val_auc: 0.9619 - val_loss: 0.1965\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9038 - auc: 0.9548 - loss: 0.2585 - val_acc: 0.9167 - val_auc: 0.9634 - val_loss: 0.1920\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9288 - auc: 0.9640 - loss: 0.2349 - val_acc: 0.9394 - val_auc: 0.9638 - val_loss: 0.1853\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9247 - auc: 0.9604 - loss: 0.2411 - val_acc: 0.9242 - val_auc: 0.9652 - val_loss: 0.1858\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9202 - auc: 0.9530 - loss: 0.2571 - val_acc: 0.9318 - val_auc: 0.9652 - val_loss: 0.1845\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9289 - auc: 0.9604 - loss: 0.2373 - val_acc: 0.9318 - val_auc: 0.9624 - val_loss: 0.1859\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9255 - auc: 0.9609 - loss: 0.2374 - val_acc: 0.9318 - val_auc: 0.9635 - val_loss: 0.1835\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9249 - auc: 0.9603 - loss: 0.2384 - val_acc: 0.9356 - val_auc: 0.9629 - val_loss: 0.1866\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9074 - auc: 0.9529 - loss: 0.2583 - val_acc: 0.9356 - val_auc: 0.9655 - val_loss: 0.1817\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9222 - auc: 0.9606 - loss: 0.2403 - val_acc: 0.9280 - val_auc: 0.9635 - val_loss: 0.1823\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9106 - auc: 0.9561 - loss: 0.2512 - val_acc: 0.9356 - val_auc: 0.9669 - val_loss: 0.1773\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9245 - auc: 0.9583 - loss: 0.2414 - val_acc: 0.9280 - val_auc: 0.9653 - val_loss: 0.1799\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9197 - auc: 0.9580 - loss: 0.2402 - val_acc: 0.9356 - val_auc: 0.9675 - val_loss: 0.1736\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9231 - auc: 0.9595 - loss: 0.2385 - val_acc: 0.9356 - val_auc: 0.9671 - val_loss: 0.1749\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9354 - auc: 0.9678 - loss: 0.2121 - val_acc: 0.9356 - val_auc: 0.9681 - val_loss: 0.1722\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9381 - auc: 0.9663 - loss: 0.2174 - val_acc: 0.9280 - val_auc: 0.9681 - val_loss: 0.1740\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9302 - auc: 0.9700 - loss: 0.2143 - val_acc: 0.9280 - val_auc: 0.9666 - val_loss: 0.1769\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9288 - auc: 0.9634 - loss: 0.2270 - val_acc: 0.9280 - val_auc: 0.9697 - val_loss: 0.1714\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9198 - auc: 0.9602 - loss: 0.2385 - val_acc: 0.9318 - val_auc: 0.9703 - val_loss: 0.1698\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9252 - auc: 0.9614 - loss: 0.2337 - val_acc: 0.9356 - val_auc: 0.9706 - val_loss: 0.1666\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9303 - auc: 0.9687 - loss: 0.2115 - val_acc: 0.9318 - val_auc: 0.9716 - val_loss: 0.1668\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9316 - auc: 0.9689 - loss: 0.2107 - val_acc: 0.9167 - val_auc: 0.9712 - val_loss: 0.1740\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9241 - auc: 0.9675 - loss: 0.2163 - val_acc: 0.8788 - val_auc: 0.9650 - val_loss: 0.1951\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9115 - auc: 0.9665 - loss: 0.2272 - val_acc: 0.9091 - val_auc: 0.9699 - val_loss: 0.1796\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9173 - auc: 0.9637 - loss: 0.2311 - val_acc: 0.9356 - val_auc: 0.9741 - val_loss: 0.1650\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9387 - auc: 0.9719 - loss: 0.2049 - val_acc: 0.9280 - val_auc: 0.9734 - val_loss: 0.1625\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9116 - auc: 0.9656 - loss: 0.2292 - val_acc: 0.9356 - val_auc: 0.9745 - val_loss: 0.1597\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9170 - auc: 0.9648 - loss: 0.2297 - val_acc: 0.9318 - val_auc: 0.9762 - val_loss: 0.1590\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9275 - auc: 0.9686 - loss: 0.2185 - val_acc: 0.9318 - val_auc: 0.9764 - val_loss: 0.1562\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9282 - auc: 0.9694 - loss: 0.2172 - val_acc: 0.9280 - val_auc: 0.9735 - val_loss: 0.1672\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9289 - auc: 0.9719 - loss: 0.2111 - val_acc: 0.9394 - val_auc: 0.9774 - val_loss: 0.1547\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9317 - auc: 0.9746 - loss: 0.2015 - val_acc: 0.9318 - val_auc: 0.9780 - val_loss: 0.1537\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9285 - auc: 0.9727 - loss: 0.2074 - val_acc: 0.9356 - val_auc: 0.9785 - val_loss: 0.1533\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9333 - auc: 0.9754 - loss: 0.1991 - val_acc: 0.9318 - val_auc: 0.9794 - val_loss: 0.1522\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9319 - auc: 0.9771 - loss: 0.1960 - val_acc: 0.9356 - val_auc: 0.9797 - val_loss: 0.1504\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9286 - auc: 0.9782 - loss: 0.1937 - val_acc: 0.9053 - val_auc: 0.9765 - val_loss: 0.1630\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9213 - auc: 0.9783 - loss: 0.1988 - val_acc: 0.9356 - val_auc: 0.9795 - val_loss: 0.1514\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9229 - auc: 0.9787 - loss: 0.1929 - val_acc: 0.9205 - val_auc: 0.9781 - val_loss: 0.1597\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9181 - auc: 0.9793 - loss: 0.1971 - val_acc: 0.9280 - val_auc: 0.9812 - val_loss: 0.1474\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9408 - auc: 0.9837 - loss: 0.1734 - val_acc: 0.9394 - val_auc: 0.9823 - val_loss: 0.1438\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9261 - auc: 0.9800 - loss: 0.1938 - val_acc: 0.9280 - val_auc: 0.9803 - val_loss: 0.1547\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9251 - auc: 0.9799 - loss: 0.1933 - val_acc: 0.9280 - val_auc: 0.9825 - val_loss: 0.1462\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9344 - auc: 0.9815 - loss: 0.1846 - val_acc: 0.9394 - val_auc: 0.9829 - val_loss: 0.1467\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.9313 - auc: 0.9824 - loss: 0.1836 - val_acc: 0.9318 - val_auc: 0.9838 - val_loss: 0.1404\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9256 - auc: 0.9795 - loss: 0.1943 - val_acc: 0.9356 - val_auc: 0.9849 - val_loss: 0.1391\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9374 - auc: 0.9844 - loss: 0.1754 - val_acc: 0.9318 - val_auc: 0.9846 - val_loss: 0.1414\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9261 - auc: 0.9817 - loss: 0.1866 - val_acc: 0.9280 - val_auc: 0.9848 - val_loss: 0.1405\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9199 - auc: 0.9817 - loss: 0.1912 - val_acc: 0.9280 - val_auc: 0.9845 - val_loss: 0.1456\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9274 - auc: 0.9826 - loss: 0.1842 - val_acc: 0.9280 - val_auc: 0.9858 - val_loss: 0.1409\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9366 - auc: 0.9864 - loss: 0.1713 - val_acc: 0.9356 - val_auc: 0.9848 - val_loss: 0.1381\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9305 - auc: 0.9827 - loss: 0.1836 - val_acc: 0.9205 - val_auc: 0.9840 - val_loss: 0.1394\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9350 - auc: 0.9841 - loss: 0.1759 - val_acc: 0.9205 - val_auc: 0.9813 - val_loss: 0.1510\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9255 - auc: 0.9851 - loss: 0.1775 - val_acc: 0.9356 - val_auc: 0.9872 - val_loss: 0.1299\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.9267 - auc: 0.9853 - loss: 0.1761 - val_acc: 0.9318 - val_auc: 0.9885 - val_loss: 0.1311\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=\"model_at_epoch_{epoch}.keras\"),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10),\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.15,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-zFzy6lpJQP",
        "outputId": "989b18ff-fc23-4fb5-cd0b-4651c6c0dcfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.16420626640319824, 0.9321808218955994, 0.9880088567733765]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNHmmkREpJQP"
      },
      "outputs": [],
      "source": [
        "# LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text data\n",
        "import io\n",
        "path = keras.utils.get_file(\n",
        "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
        ")\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "0ZGlhfT8peSL",
        "outputId": "3b545a42-6a56-4ce9-8a38-8d918ee14fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 600893\n",
            "Total chars: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# char_indices\n",
        "# indices_char"
      ],
      "metadata": {
        "id": "ISHuTNoA--3n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=int)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=int)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "v9Swf_aF_Z_2",
        "outputId": "cddc7883-6be2-466d-b693-2c63dbba91b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences: 200285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(x[0])"
      ],
      "metadata": {
        "id": "eiX1O236pepv",
        "outputId": "8c14dd7c-fded-4016-9375-d16fcaf1cf46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].shape"
      ],
      "metadata": {
        "id": "7UxkIFvMpah1",
        "outputId": "50f18d96-f8d9-4801-b7f3-7842e5e74371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        keras.layers.LSTM(128),\n",
        "        keras.layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "metadata": {
        "id": "tn2dEIXuEDBs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "hSqW58jNJTd6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
        "    print()\n",
        "    print(\"Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(\"...Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = text[start_index : start_index + maxlen]\n",
        "        print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print(\"...Generated: \", generated)\n",
        "        print()"
      ],
      "metadata": {
        "id": "siXIgrhLEWUd",
        "outputId": "357b422e-9091-4571-f2a8-ca1ac95ceb5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 69ms/step - loss: 2.8613\n",
            "\n",
            "Generating text after epoch: 0\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"to whom it has not yet occurred that he \"\n",
            "...Generated:  and the an the and and inge and the and the sat he the an the re and the in the an the ath e and the an the s athe an the an the the ant he ans the the at the and and te and the and so thee man the the an the the ant he ant athe se the and of the ant ion the ret athe and the and at his the an the ares the and at he the at he and an the and and the ins the ant he an the the and the ant ise the an t\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"to whom it has not yet occurred that he \"\n",
            "...Generated:  at re fan md ato wh acith ean d and ainte thos a with mae nnd aante or fore these it atein st he rte on whe whin and nto deer atn itha rered fan sbe to an oth  athe the se fincno the araly t he and issti thes ant iten adcera inte thna to wnet itos t hin on w hoe atn ith th aen ther ad thealy tein th eredi cthe ant couthe s hat ond sean tes matl alt hein d ath ti ere the lwheop wins de sat into hte\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"to whom it has not yet occurred that he \"\n",
            "...Generated:  qa-:ny aet atiss,n incinhnte for,e p\"octi cthoo tu sh thaleulsseidns t o homuire, n anid  itinis thspiet f otheepspre, rtewhd ihcve  osanay ats ntha, c sheivnel mty. f aenerjt. asinse nd don si tene,t hene sic miel,-ita it honef r buephdraanesg ask pau mnt areang tearme ds apnncgtihe.r soaotmae thtnmes a, t uadna thelt ierosvimelnp-ofm,da derigan, n cedhe asn dgarsen attecernd, teheucry, t haretao\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"to whom it has not yet occurred that he \"\n",
            "...Generated:  theass l wl fmo ounddrstb  oerot ihtox mamb-pout atss thpeeradytrereellb9alyx eal,s,u\"d roewmnceer dowwh av, othaeg fitl ecvthme,tisf anaindfcet-hitaintt ho wreuw  sth.idss leh- uwtilepsythipraotsmea edv,a,   toasl wohmce,a-t t h!he mertesai ntheess, toeb cihde rite gmotaie ed fthemt  ckarr aicune.d \"ous ke-lvbeomevks bxste ternfo meted usenhvir egeands tuistth thvhe aa to i tiofh l-r  atdehrue rb\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - loss: 2.5338\n",
            "\n",
            "Generating text after epoch: 1\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"e influence of napoleon is almost the hi\"\n",
            "...Generated:  s the and the and ingo th eand o for athe the and the an the the ing the ore ant he and at he man the the and the and at the and at the rat on at he the whe and the the as the and of the the and ing othe the and the an the rat int he and the and e the an on the and ist he an the the and whe the meran the and ond the the the of whe couring the as the rithe the mo and the the the re and the on the a\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"e influence of napoleon is almost the hi\"\n",
            "...Generated:  nen te at the an the ma on the th and iting o man isthe and s be cahce the ant end the and icsan dan dit orisc of o whe the the bere of rethes ain the whi on the as the and wher ato fon the nd omen ofelde regares to fero and theing anel an thear nd woth he mans and te the tis atin tes the thre re moon te th ase th woh the there o fre omn athed me anacmin covel and cerat  the mon teith as tion  whe\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"e influence of napoleon is almost the hi\"\n",
            "...Generated:  s sturlmsel aspithne b eaarpt chriess, mexf odo, ivanu  tel ihngeramude tangatomeno. ab whexc, head dinceloulds uso bvedou:l yof i-n--vaman\" salse nt-of niged o w whthrere inesd tewher s oa.cuhy so lmf oefro misot has beimnto rsh ire ththe isicmalnigve anrmt aynd icusoeny g hfe lmy oniwte, rriofre he abes thtei en af mordi.eg xsatero-vsten aadm-,a sbeoit  dxega ratel vrite stearat icasial falis by\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"e influence of napoleon is almost the hi\"\n",
            "...Generated:  scroetnred xheae ltito n i2gity al\"yt aes ta\"a hme trpitoas1y,  bteqo raeadnd od vcot, ad fo mle)a-an-dig,sar;eaw histisven--ed asdlic: carilmamaledh g whiwthie pspad ianse tilsr atbotn;et sartsi hn\" oned vera-siat-ls the rt,ohydecu, rurdt hey (somny  whovritgis yctoo fal nalky freel?m agan t aed imo, twr ics,ebe t cohal gdoust,\" tbn ?oownaelsl e pt2esine ym odupras t sh bechyein culo ncang mayt  \n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - loss: 2.4833\n",
            "\n",
            "Generating text after epoch: 2\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"ow and the day after the morrow, has eve\"\n",
            "...Generated:  re se the and of the isthe s of of or of ore the and om and of the an the s of ore an the and o and the s of of ore the and and as the res the and ind of f ore of the and the as the re an the and of the in the ancere the and se the and of the and the and the the and o the re and the and and ere sthe and of of he and the and ere and ine the s and of the and of reand the and the and es the an the ne\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"ow and the day after the morrow, has eve\"\n",
            "...Generated:   and whit ore sat or bese se th oun meen ad orthe peland ese an thes and setho es thores hif the pand ines ble the lgivete and the asthi spitot heas polf iasle poran th alde and eud ingel so of whe as and ed fo reof h one teres thes eand it hane to sth and end edo fen irthe s fot pereth is the ra nd ithe ta ront the int osth ou the spad and con ato nthe n whe the ant h mere andude ds ingeacnd inos\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"ow and the day after the morrow, has eve\"\n",
            "...Generated:  ser porl ith, o\"u urwead d , af \"her apourtbe and. tho l diinuc offrg uronad ton vere,r ude resin do ucheraniton shaislegdu;ey diblego fheand ans illvaeurasc, f whies fuonde singee rof amit, angthe aklincomos, whithme eslte bfl cuaalnryed, f thimqirni c_ouandgno t apondess, tfe oflsules, ran-bayn if  nekary go futhe ncewor es btioln ge ais ttoa ngoefn  dofe reingd s, a juedtrheetmon,  hanicy llo o\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"ow and the day after the morrow, has eve\"\n",
            "...Generated:  lane nde this elhpepsorperilmlofeif, lllesy th ingthie, w de ang imefit,n s(t lti hnang d fohay slt tho tet mivewito udesas pr anrangnecnrig,y uanc ho (copfealcdispys alorfkat,-ce-towf toraimnill to fmey, bty reilyagdindey, his ecen edoived mctie f lpeatr tas \"pirb wincehc-uonng ofrcoriidyne,  1sondy \"ivexqte oflyo whiingr eqset opgnoil \"on phtin ro u!ts wath sesende, it ruchse _icneve banto anw i\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - loss: 2.4671\n",
            "\n",
            "Generating text after epoch: 3\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" every philosophy at which the \"convicti\"\n",
            "...Generated:  s in the and inge and and the and and of of the reand ingo the and and and and and at ing and and of ore ned and ing and athe ro f and ithe the and al whe the and of rer athe and and of ore and and ere and of ro the manind inge the and ing and and the and inge rat he and the and inge and as there se fo fre and the of ore the and ond at here and on the and and inge rang athe rat on the and of the o\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" every philosophy at which the \"convicti\"\n",
            "...Generated:  se f anound a the is of o man enth erer ot he anpcor a the cherer of ngith e cath e the roure the wil ond the manse and e maand or of on maers anes sosa f al ith a cined ris the whe the rso f all ous athera nde the arist the and wofr athing an wico the man ther a ol the hare mon al ofre and ole ind aint and an te wor athel al poras ithe men ast inils d where th icme fraon as the withe mane so man \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" every philosophy at which the \"convicti\"\n",
            "...Generated:  t-i sp makd amyof r inch at olt oron the ti er om to nesso ity cin nwhecile ansg mle atonceasinde singof tirailkfe ffrecorne, unthitsthehve flig fo thed refingh turente,  mofe nrolk evecto onerity,s the it hepelis fdaalcicul lghaguctend aos ht o hw imtn adsirtis holy b8uth-in gcrea:knt-ere sowoll mat arth atpop.iosuca tno re thals tis as adespiso n wiciyre fewhherers tionpuand ecaony, wa anse lic \n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" every philosophy at which the \"convicti\"\n",
            "...Generated:  wo wthd ha hties mhyeghuvecomakt, wmilivty amsh,d inou madaront,eod asde.trre the alkdevineverfy-t\"h a temofmor,ualstubilmyl tyovetriothet  aaralde cihte pciorm,blel in;uimtt,isi fc. an be  urgsed owof raly, o sns hacod t iprenlig)thapwl, \"a ngtomila tmene d ahccet aningaann wn.e nc,\"he admev, mirtasbd poancdn\"es'id rpet, hattund s te nay teu preshca mtindog te o 1rherbay, fcaarltydosun.;whyr-at,h\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - loss: 2.4498\n",
            "\n",
            "Generating text after epoch: 4\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"re a picture that is unrolled before the\"\n",
            "...Generated:   the s the an the sit he mere sthe the re the s of of re athe rat he me pres atin the in the re sin the whe re of ore the the s there the the ong on the an inge the an the the and on whe the the an the the whe re the and is the and the ans the n of ore the on the ser te of the ore the on whe the re the man the whe s the on the the the re and the and ist of the and ist of of the and ond inge the an\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"re a picture that is unrolled before the\"\n",
            "...Generated:   pores the of \"e fre thine fo re nthe and antie there r itro the se pers he ste orus of uring the re marineg de matin inge ther the and iton tin de net onge of tharere ad of at oren than te ion atta himen the asn tisicon, the sthe the win ther end welesth onde thmeren wot hen aly owh is the li fe lof ous to eracon ti thes in the the mancot han set the reve seth ane ings ate rero thee w le of oree \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"re a picture that is unrolled before the\"\n",
            "...Generated:  rat mamandg,  aarnedites, h men cor pamipenseiscratr, thea t nefo gfreur si.t buy thec evi ng there nere w\"theet hs, whh auld abye muan, th th wellot thues, \"ilon f wif herrilse caäint th essmoe fandaey rlidin t hawt here mowarduigros thalidevesli: sat iofcisen fheman stokfkneilce,n m\" th eivecl.edl pisem lyeins teof dorlteo firceh-agrter oferslof has fantul lveitthe maporevoulyn,- w phertho peroh\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"re a picture that is unrolled before the\"\n",
            "...Generated:  ryte, awinsexesk ino ferhe phil islisto!  tihthigroises,  hadsesavilsietstyi bretrivet--ha gimetr: hemacs mrasto ounisg ceuc,riund as psel, ceasyv beincicismyt, \"ormema pteroe xw (utco theon, te on k1on qif ah lelvesd es, opbeligneqne f-es fat ha winche,u dmas oay:s sbisthhe mre thhaltisy heddre ads. ef l whois ihnaren ss\"ore--rdiurpropoolorft eahccivin.ie gr aora mlthisrateyk ulepenutrer cekos, a\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 66ms/step - loss: 2.4358\n",
            "\n",
            "Generating text after epoch: 5\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \" \"faust,\" part ii, act v. the words of d\"\n",
            "...Generated:  e and ond othe re the and the and ore sthe the so the whe the re whe re the the se mon the and is the the whe s of ore the and on the se the re the the s of ore the whe the the s the and ere the and inge the ore sthe and on whe the ans the res the and inger the and int of the sre and the se man the and and there and at he se fo fre and and ad the man as the mon the and onge and and ithe the on whe\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" \"faust,\" part ii, act v. the words of d\"\n",
            "...Generated:  o curat ond owhe de there at hes the mes antus ceand ist he s wihint he ran edina to f ole andi sme the is nd ongraend adin orcesous and and or ad mas porit ande the ise the pan the sand athe res paiste the re ate rdo the the cis and ethe as nof on owhel severe ald on theren of of are nad ingin the rem asinporelta olered ined ofthe sisepso, athesre sthe and raend ant aly on beutthere the mto nta t\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" \"faust,\" part ii, act v. the words of d\"\n",
            "...Generated:  hejichpe, weo lft heol thered ad, \"\"a ithse tinm hteras neengor, onand, is eh oubpens ed cerev ofr,ae rdue  stardfec irs, hanchto sheperig himo toan nog-o snt hemere an therlyle atmo sbue cureant h on locpheorly may phe ndi thmispcidal-killay owlkion kome se issi do ithsnel yicd anl yathe ormingese-b lilymy perlet misatal-ly poferorsaandtcethe wry atb aed id agt homp esciun ctohmte t whato, raingt\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \" \"faust,\" part ii, act v. the words of d\"\n",
            "...Generated:  orusg, ish emorteolyt ictatir aymk ifee fischate nss bely end,o pbyters,e anymity hinreigntk ehan vna ance rarpcabul.a tfusw i!gon be wifl thie hegaly ar bivevyeeven xicme nat  nuwcey, a d tomocevfe mliofl kdo-onwweyt ho wist cma sultthe rceniowc hirtal ; itecroeet )il nu f m emileoll, alergem pptionhidvorpki bain dat pesotihos peranlcd qaitr huges foritopef coonflis, he pbely  boslepors tyl eerti\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - loss: 2.4274\n",
            "\n",
            "Generating text after epoch: 6\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"tand its right to inverted commas (goose\"\n",
            "...Generated:   the and the and ing at he res of of reer and ore the the s of the ore the and ithe the as the an the the se pores and ore mans the and the man the so fre and ofre the perer athe s the are s of omere and of the and and ithe s art he and at he res the the s owhe the s the re fore the are s pore and ond es the res int he the res the the res the and the se the the s of ore the and of the the sere pre\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"tand its right to inverted commas (goose\"\n",
            "...Generated:  n tho wicorelin od unst eding ithe and ng arse  whe as th o whea rle the the whe and acthe orse pores bithere terapens theand this theringe of the proorty thel ine and,  cinte s ablily on of rande the ans and fors thi sin tores is the ast he mane fis ant on ad s and the ors ate sind egat is operis toth i ande s aterer of oth anor ans tor ess at s the acereratin, tis and atrean conto f ithe peres t\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"tand its right to inverted commas (goose\"\n",
            "...Generated:  d,t hsulald atidy beyi, ans the hmer th ed e f el avevin ofrev what iant theer wr thives ae sacy tu os\" heplisinc. ius als. it on c\"omuling yathelcuset,\" revilyod ins moeequtis, t on bat orbee s orfurevevreism an inge salf ourt boualsily  calferaungers fef etrel, ion ma cathedicsso-urpalse. cro swin maly.  whicot hsesing fedroucerypsokn omened artithitd as aol ftre aptrionf o. bleef a blitus ?phiu\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"tand its right to inverted commas (goose\"\n",
            "...Generated:  l atmeexpent oany amndd h-be wcacthetes bte waknoti ond di .u l ak ema teln swileev le. lian aing d6hictthe o wn wherly s nadud usrpeeanilgiso,, we mofloes, wrhe,s t haso ntoueng s 4echuutisbe, t acchedren rorimec,in fonegex tioncte ]a recutly; thi and dy. as 2okene dandd savefrrcetium gadul\", wa te thess t thgertetor,i-san.em-i--y matthrisciote akstitaemle.r sre htupev,t siccreer-peeyh-s camle\"js\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 67ms/step - loss: 2.4236\n",
            "\n",
            "Generating text after epoch: 7\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"from his superstitious and religious ide\"\n",
            "...Generated:   f of ore f of ore the and at he mand the the s ore and ing of here mand of the an the the s the s of ore the man the s of ore man the and of o fre ins of rere and of ore s of her of o me sin the and and atin to f ofre the and of or and isthe s of ore the an the s of ore me and the and of ore the s the man the and se the and is the and of ore and the an the s of ore the an the an the s of ore man \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"from his superstitious and religious ide\"\n",
            "...Generated:  vere man de shoe fs and anid cisnat ans the thear belexis the stiself ot heres \"otu ant the d oro whit ot hse exinten iand in toti the whe s allen d thie of there sthe aver laten there on we on a the he ra prerad at ore arit of of rint of re ind ond ing hin the maly hit hin to f oron th ores fores hit athe weris fo the tile sat of she atres of or the hand ce ther es isthe anc the and andecan othe \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"from his superstitious and religious ide\"\n",
            "...Generated:   sthe rinte-spuitr bit eonsculind sitod, inlaly dayta kle oumr ablea mitrelint chso \"wirmarly thous tha y e: sa mothe tbiel, wh antre otus ty ca\"rilenptoe,whif tivenga, e r thoe toriso zwienl acssc, al con isrodk be de-ab tghi. th of tuheg h mas lcthecook, phairyny gher aon fteo phray dos pichit hicansle y basladl tig nolat ankte, whe scomuat m papalst ote sereeske nepast hatrees then ind eradino \n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"from his superstitious and religious ide\"\n",
            "...Generated:  raruteina \"lsliv;at n id s\"aty slnopthpecri,d bhovoe pantlon, sas;;cior g heduspon wdori (stive e esthuten.-igigo cha tony sfiv, iod n(e 9o rary odank ingaa f thee vlea raludf et oerao dmusi,nd ongesrd. obecels lews,ig le gielvey os wahse wovthes  ( thrveount, s ho wis whiih gef is;e p rliompilestuger,\" wdo indcitnato,  atutul bendol. at-hses fcoifrsu, buisbsce suig on ware s abever hend  farsse w\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - loss: 2.4196\n",
            "\n",
            "Generating text after epoch: 8\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"re cases, only compulsorily, always with\"\n",
            "...Generated:  e the the the of of ore the mas the the the the the and isthe the whe the s of of ore the and of ore the an the the s of ore the the the se the the me sthe the mere the the ans the s of the res the se sthe and the and of ofre the so the the and ithe the at he the s of the and ore the on the the the ore the the the and the on of the the so f ere the and of ore the an the s the whe the s the aprere \n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"re cases, only compulsorily, always with\"\n",
            "...Generated:   aly overe fithing ally of nad the wheres the isot ithe wh o wh se mousb the and theeve rethe mon a theve ret mos se meind of thes ingh so the poreng the the theren sthe the so spreperesaso tof oured teon this t hae prof isthit he che rof owhin th o reresin the han ofre and ang athe an of fere there se the atit on and the and the sisunges the of he som the apre the sof he priingon sat hes when of \n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"re cases, only compulsorily, always with\"\n",
            "...Generated:  ee nod sreforeorat mdso of aptra te and wofre suturan tonhg tiheas int, and icommaalf sicm omon mul-pens pith heersm andst heraget ithin oft hou. polevere teluded at dthe arend wis at urecany or cou.h tist t at ev ealivh ighe d\"esuttios, \"\"ory, anso:ped athiy mtthey frow sth avya rande dsu sciospithoninthe dc ionsakan-d ceisinst, sibelclistes isthirs iculelvkereinsmablevy sarid.t igan torf nerat h\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"re cases, only compulsorily, always with\"\n",
            "...Generated:  a re relf ionn thoks lf;ynf, thertmur ein\"owd ty  beeghevergar t ien ca psomo tsiereq aisnw on oind. et rad;y shie,  whas h thiecn iveneedryuy.-. tho arghe, tthy ugontoiust os ndo uilive, vety hepry vet eron dofur ex_ f\"ofmereelys, ade dsa lteliten, apsy ond howte ta the \"roelelf-ithe halint ayk lofmty thouess,llef carwuithe xpsreto whioncet humon dedin onse-r)iletetshvee theargen cthandium. \"rs,a\n",
            "\n",
            "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 67ms/step - loss: 2.4105\n",
            "\n",
            "Generating text after epoch: 9\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"med a school of distrust, still more of \"\n",
            "...Generated:  on the se rand of ore whe s of or the and of the mand is the s pore the the the s of the and whe re the s of ore the whe re the ing of or and the an s of ore the and of the mere the the s the on the so f ore sat he and the so whe ro f ore and on of the the an the re the s of the alinge s the the and of the the the and is the s of of reer and ing her an the se the s and of ore the and is the the re\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"med a school of distrust, still more of \"\n",
            "...Generated:  the and eradt hoer so unt ho the an d in oto f ate aral paly speasre pastin tan ti set satin is courl of ofreveeran ti the thes peres ifo of thor ante oral teeres the tit he whe  f al whine sthe s porthe isae sof er ads omald the the the so there the ise re d albe the te ran ome the and se the mon tche s ant he ste porthe at is cule sitint of whe rals olf owins the at sof thee the be coto t in sou\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"med a school of distrust, still more of \"\n",
            "...Generated:  bto moredmer aminc ante ifer the aoaly fan, wh atererto.  haritand cealll yso f athpsie the fwo sbemaint t!hye smpeiprse fered ser athicsandrals, ghe aser an sd tia ral tghime!hi t of flit to far nud redst on spothe o whe besout-beo it buellef \"ham istn tcuat hman the \"lo whed ass -dal opan theres ov andhet beurm ad-ed pou prethe knigot h o ma there ten bwhe tithim uss ppgeaondte----ound-ilges pab\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"med a school of distrust, still more of \"\n",
            "...Generated:  ane' s hlveumspin tre na.  preal ne qubersa sot bcounrt,\"h  asp irkotsel te dareov hempoulpoths net anarke asgs hte bod indy viss oupth eegh b ang nperepheevfeco rulalgolepe obandl asuspf--evire n. the freringuglsed s utersi phess imne ter taly okepprsoide fen wiscthi porled s thiser, huadl ug?ri rof adis coandg bely. veanlepevneitoly, it hed eme ditre gha paln omeinxs he al-we tovhuses ta semnceo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7gXwqe3EDTm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6owf7kVEDdX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThGbL2LxEDk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO4AKgXzpJQP",
        "outputId": "4182a49b-6c26-449d-96f6-01e968e37d49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Dense name=dense_18, built=True>"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_layer(name='dense_18')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-aZXiKDe9FO",
        "outputId": "c6f2fd0e-2dd9-430f-fe16-b5743c190774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.50873 0.0849 ]\n",
            "init inputs with random numbers:\n",
            "dimensions:\n",
            "W: (2, 100)\n",
            "b: (1, 100)\n",
            "W1: (100, 100)\n",
            "b1: (1, 100)\n",
            "w: (100, 1)\n"
          ]
        }
      ],
      "source": [
        "#first point\n",
        "print(x[0])\n",
        "# W dim\n",
        "input_dim = 2\n",
        "hidden_dim = 100\n",
        "key = jax.random.PRNGKey(42)\n",
        "#key, subkey = random.split(key)\n",
        "#print(random.normal(subkey, shape=(5,)))\n",
        "print('init inputs with random numbers:')\n",
        "W = jax.random.normal(key, shape=(input_dim, hidden_dim)) * .01\n",
        "b = jax.random.normal(key, shape=(1, hidden_dim)) * .01\n",
        "W1 = jax.random.normal(key, shape=(hidden_dim, hidden_dim)) * .01\n",
        "b1 = jax.random.normal(key, shape=(1, hidden_dim)) * .01\n",
        "w = jax.random.normal(key, shape=(hidden_dim, 1)) * .01\n",
        "print('dimensions:')\n",
        "print('W:', W.shape)\n",
        "print('b:', b.shape)\n",
        "print('W1:', W1.shape)\n",
        "print('b1:', b1.shape)\n",
        "print('w:', w.shape)\n",
        "#print('model:')\n",
        "#print(model((W, b, W1, b1, w), x[0:10]))\n",
        "#print('loss function:')\n",
        "#print(loss_fn((W, b, W1, b1, w), x[0:10], y[0:10]))\n",
        "#print('gradient dim:')\n",
        "#print(list(map(lambda i: i.shape, grad(loss_fn)((W, b, W1, b1, w), x[0:5], y[0:5]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "587E8wrLe9FO"
      },
      "source": [
        "#### 2-layer nn using optax for optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6L-nnEqe9FO",
        "outputId": "8c843fbe-2abd-4ced-941b-907afa649e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions are  2 128 2\n",
            "Dimensions of w1 are  (2, 128)\n",
            "Dimensions of b1 are  (1, 128)\n",
            "Dimensions of w2 are  (128, 128)\n",
            "Dimensions of b2 are  (1, 128)\n",
            "Dimensions of w3 are  (128, 2)\n",
            "Dimensions of b3 are  (1, 2)\n"
          ]
        }
      ],
      "source": [
        "key, w1key, b1key, w2key, b2key, w3key, b3key = jax.random.split(key, 7)\n",
        "num_input = X_train.shape[1]\n",
        "num_hidden1 = 128\n",
        "num_hidden2 = 128\n",
        "num_labels = y_train.max() + 1\n",
        "print('Dimensions are ', num_input, num_hidden1, num_labels)\n",
        "#num_hidden2 = 1024\n",
        "params = dict(\n",
        "    w1 = 1e-2*jax.random.normal(w1key, (num_input, num_hidden1)),\n",
        "    b1 = 1e-2*jax.random.normal(b1key, (1, num_hidden1)),\n",
        "    w2 = 1e-2*jax.random.normal(w2key, (num_hidden1, num_hidden2)),\n",
        "    b2 = 1e-2*jax.random.normal(b2key, (1, num_hidden2)),\n",
        "    w3 = 1e-2*jax.random.normal(w3key, (num_hidden2, num_labels)),\n",
        "    b3 = 1e-2*jax.random.normal(b3key, (1, num_labels)),\n",
        ")\n",
        "for k in params.keys():\n",
        "    print(f'Dimensions of {k} are ', params[k].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWGwE2QMe9FO"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def net(params, x):\n",
        "    x = jax.nn.relu(x@params[\"w1\"] + params[\"b1\"])\n",
        "    x = jax.nn.relu(x@params[\"w2\"] + params[\"b2\"])\n",
        "    x = x@params[\"w3\"] + params[\"b3\"]\n",
        "#     x = sigmoid(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5esoZLYAxr6"
      },
      "source": [
        "### Common loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8XJLD51Axr6"
      },
      "source": [
        "#### L2 loss or squared loss\n",
        "\n",
        "$$\n",
        "Loss(y, \\hat{y}) = 0.5 * (y -\\hat{y})^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKQunpS1Axr7",
        "outputId": "c2c2ee3d-f10f-449e-8df6-02cfcff307be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.1757147e-03 1.4729156e+00 1.3867368e-01]\n",
            "0.53758836\n"
          ]
        }
      ],
      "source": [
        "import optax._src.loss as optax_loss\n",
        "l2 = optax_loss.l2_loss(jnp.array([1., 2., 3.]), jnp.array([1., 2.,3.]) + jax.random.normal(key, shape=(3,)))\n",
        "print(l2)\n",
        "# the acctual loss function should return the mean\n",
        "print(l2.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgCCUR66Axr7"
      },
      "source": [
        "#### Softmax cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9foI8URAxr7",
        "outputId": "bff445ac-7601-4074-c0cb-2f5e387d5382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[ 0.01146681, -0.00883568],\n",
              "       [ 0.01149749, -0.0088382 ],\n",
              "       [ 0.01148136, -0.00883772],\n",
              "       [ 0.01147696, -0.00883594],\n",
              "       [ 0.01146699, -0.00883682],\n",
              "       [ 0.01144741, -0.00884022],\n",
              "       [ 0.0114938 , -0.0088306 ],\n",
              "       [ 0.01146762, -0.00883694],\n",
              "       [ 0.01148721, -0.00883548],\n",
              "       [ 0.01145677, -0.00883814]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net(params, x[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Oo_n-mnAxr7",
        "outputId": "b558eaa0-e04a-43bf-cac3-f7f9440fdbfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1, 1, 1, 1, 0, 0, 1, 1, 1, 0], dtype=int32)"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntCkkyMsAxr7",
        "outputId": "2da8a2f8-ec98-45ff-ff94-ee4c9156f21c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.nn.one_hot(y[0:10], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeD85SJnAxr7",
        "outputId": "89e922d1-f178-4182-ea4a-923b0e1b69d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.70334995 0.70336664 0.70335835 0.7033552  0.6830468  0.6830548\n",
            " 0.70336103 0.70335096 0.7033601  0.6830512 ]\n",
            "0.69726557\n"
          ]
        }
      ],
      "source": [
        "xe = optax_loss.softmax_cross_entropy(net(params, x[0:10]), jax.nn.one_hot(y[0:10], 2))\n",
        "print(xe)\n",
        "print(xe.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YUDWma8e9FO"
      },
      "outputs": [],
      "source": [
        "# implement\n",
        "@jax.jit\n",
        "def xeloss(x, y):\n",
        "#    _elementwise_xeloss = jax.vmap(lambda x, y: -jax.nn.log_softmax(x)[y])\n",
        "    _elementwise_xeloss = jax.vmap(lambda x, y: -jax.nn.log_softmax(x)[y])\n",
        "    #print(_elementwise_xeloss(x, y))\n",
        "    return _elementwise_xeloss(x, y).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FvEhe2te9FP",
        "outputId": "d3f22a94-3631-46bf-f74f-4d260bb3f033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model:\n",
            "[[ 0.01146681 -0.00883568]\n",
            " [ 0.01149749 -0.0088382 ]\n",
            " [ 0.01148136 -0.00883772]\n",
            " [ 0.01147696 -0.00883594]\n",
            " [ 0.01146699 -0.00883682]\n",
            " [ 0.01144741 -0.00884022]\n",
            " [ 0.0114938  -0.0088306 ]\n",
            " [ 0.01146762 -0.00883694]\n",
            " [ 0.01148721 -0.00883548]\n",
            " [ 0.01145677 -0.00883814]]\n",
            "loss functions:\n",
            "0.69726557\n"
          ]
        }
      ],
      "source": [
        "print('model:')\n",
        "print(net(params, x[0:10]))\n",
        "print('loss functions:')\n",
        "print(xeloss(net(params, x[0:10]), y[0:10]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Xga9NOAxr7"
      },
      "source": [
        "#### Softmax cross entropy for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUC_VPrUe9FO",
        "outputId": "6ea76d40-577a-42ca-b906-ebbf20999dbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(1.3903873, dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@jax.jit\n",
        "def sigmoidXEloss(params: optax.Params, batch: jnp.ndarray, labels: jnp.ndarray) -> jnp.ndarray:\n",
        "  y_hat = net(params, batch)\n",
        "  # optax also provides a number of common loss functions.\n",
        "  loss_value = optax.sigmoid_binary_cross_entropy(y_hat, labels).sum(axis=-1)\n",
        "\n",
        "  return loss_value.mean()\n",
        "\n",
        "sigmoidXEloss(params, x[:10], jax.nn.one_hot(y[:10], 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32coBaRbAxr7",
        "outputId": "3bf6ee01-c747-4751-b65c-d656e4a32d13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(0.69726557, dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@jax.jit\n",
        "def softmaxXEloss(params: optax.Params, batch: jnp.ndarray, labels: jnp.ndarray) -> jnp.ndarray:\n",
        "  y_hat = net(params, batch)\n",
        "  # optax also provides a number of common loss functions.\n",
        "  loss_value = optax_loss.softmax_cross_entropy(y_hat, labels)\n",
        "  return loss_value.mean()\n",
        "\n",
        "softmaxXEloss(params, x[:10], jax.nn.one_hot(y[:10], 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-STpYjcje9FP",
        "outputId": "16fbe091-4afa-47ab-9650-eca8e2cfb623"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(30., dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@jax.jit\n",
        "def accuracy(x, y):\n",
        "    return 100*(jnp.argmax(x, 1) == y).mean()\n",
        "accuracy(net(params, x[0:10]), y[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJZW7yUZe9FP",
        "outputId": "2d02ed07-7d5a-4ee6-b6c1-57d1596fd949"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(0.69726557, dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@jax.jit\n",
        "def lossforward(params, x, y):\n",
        "    x = net(params, x)\n",
        "    loss = xeloss(x, y)\n",
        "    return loss\n",
        "lossforward(params, x[0:10], y[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r078GrVfe9FP",
        "outputId": "f0fc0357-e15f-4c99-ecd9-85502764d585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 1 0 0 1 1 1 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(y[0:10])\n",
        "jax.nn.one_hot(y[0:10], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI1PQR5Ce9FP",
        "outputId": "cf2f5cf1-2f82-4af2-da9f-425dcfcb5990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(1.3903874, dtype=float32)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import optax\n",
        "optax.sigmoid_binary_cross_entropy(net(params, x[0:10]), jax.nn.one_hot(y[0:10], 2)).sum(axis=-1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOZINWKwe9FP"
      },
      "outputs": [],
      "source": [
        "#print(-jnp.log(sigmoid(net(params, x[0:10]))) * jax.nn.one_hot(y[0:10], 2))\n",
        "#print(-jnp.log(sigmoid(-net(params, x[0:10]))) * (1-jax.nn.one_hot(y[0:10], 2)))\n",
        "#print(-jnp.log(sigmoid(net(params, x[0:10]))) * jax.nn.one_hot(y[0:10], 2) -\n",
        "#    jnp.log(sigmoid(-net(params, x[0:10]))) * (1-jax.nn.one_hot(y[0:10], 2)))\n",
        "#xe = (-jnp.log(sigmoid(net(params, x[0:10]))) * jax.nn.one_hot(y[0:10], 2) -\n",
        "#    jnp.log(sigmoid(-net(params, x[0:10]))) * (1-jax.nn.one_hot(y[0:10], 2)))\n",
        "#print(xe.sum(axis=-1))\n",
        "#xe.sum(axis=-1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1urJ5DWe9FP",
        "outputId": "c79a11a5-0688-40f6-9807-066b2be09e3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(-0.6936107, dtype=float32, weak_type=True)"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jnp.log(sigmoid(-0.00092671))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mzpMXtne9FQ",
        "outputId": "7aca5799-e046-45b7-fca8-b3d2bc7095a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(-0.6936107, dtype=float32, weak_type=True)"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jnp.log(jax.nn.sigmoid(-0.00092671))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gKCeh6Pe9FQ",
        "outputId": "f2075b09-3e0e-4874-8860-2e824ce3b553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(-0.6936107, dtype=float32, weak_type=True)"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.nn.log_sigmoid(-0.00092671)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl_DPYSAe9FQ",
        "outputId": "a6649344-e20b-4d31-df39-1c739cec2654"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1754, 2)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMlHuNw1e9FQ",
        "outputId": "b9b5e5ab-f018-47c5-96fb-848a7dda3726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0, loss: 0.6914153099060059\n",
            "step 100, loss: 0.3371897041797638\n",
            "step 200, loss: 0.23597250878810883\n",
            "step 300, loss: 0.19311030209064484\n",
            "step 400, loss: 0.17671062052249908\n"
          ]
        }
      ],
      "source": [
        "# optimizer\n",
        "# import optax\n",
        "# learning_rate = 0.001\n",
        "batch_size = 500\n",
        "train_size = X_train.shape[0]\n",
        "num_steps = 500\n",
        "def fit(params: optax.Params, optimizer: optax.GradientTransformation) -> optax.Params:\n",
        "    opt_state = optimizer.init(params)\n",
        "\n",
        "    @jax.jit\n",
        "    def step(params, opt_state, batch, labels):\n",
        "        loss_value, grads = jax.value_and_grad(softmaxXEloss)(params, batch, labels)\n",
        "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "        params = optax.apply_updates(params, updates)\n",
        "        return params, opt_state, loss_value\n",
        "    key = jax.random.PRNGKey(42)\n",
        "    for i in range(num_steps):\n",
        "        # draw a batch randomly from training set\n",
        "        key, key1 = jax.random.split(key)\n",
        "        idxs = jax.random.randint(key1, (batch_size,), 0, train_size)\n",
        "        x = X_train[idxs]\n",
        "        y = jax.nn.one_hot(y_train[idxs], 2)\n",
        "\n",
        "        params, opt_state, loss_value = step(params, opt_state, x, y)\n",
        "        if i % 100 == 0:\n",
        "          print(f'step {i}, loss: {loss_value}')\n",
        "\n",
        "    return params\n",
        "\n",
        "# Finally, we can fit our parametrized function using the Adam optimizer\n",
        "# provided by optax.\n",
        "optimizer = optax.adam(learning_rate=1e-1)\n",
        "params = fit(params, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmkzfVIxe9FQ",
        "outputId": "77988331-5695-4e30-d846-7ead408a1df2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(0.67345995, dtype=float32)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print(params)\n",
        "softmaxXEloss(params, X_train, jax.nn.one_hot(y_train, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8JIUMAFe9FQ",
        "outputId": "eca0a281-532c-4869-f073-a43d12859a73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([0.21850298, 0.21850298, 0.21850298, ..., 0.21850298, 0.21850298,\n",
              "       0.21850298], dtype=float32)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net(params, X_train)[:, 1] #, jax.nn.one_hot(y_train, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5PAh8oye9FQ",
        "outputId": "620d1e67-4d40-408f-abb8-a131e3640221"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jnp.round(jax.nn.sigmoid(net(params, X_train)[:, 1]),0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVdR-A6GAxr8",
        "outputId": "17e08ccf-0b25-42f7-b475-57b0fad1d140"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jnp.round(jax.nn.softmax(net(params, X_train)),0)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlHi65E8e9FR",
        "outputId": "28d93cf3-d177-4ae9-a0d9-65c554e52896"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prevalence</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>FPR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>AUC</th>\n",
              "      <th>LogLoss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5992</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>0.9331</td>\n",
              "      <td>0.9413</td>\n",
              "      <td>0.9549</td>\n",
              "      <td>0.9508</td>\n",
              "      <td>0.0669</td>\n",
              "      <td>0.8781</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.2043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prevalence  Sensitivity  Specificity  Accuracy  Precision      F1     FPR  \\\n",
              "0      0.5992       0.9467       0.9331    0.9413     0.9549  0.9508  0.0669   \n",
              "\n",
              "      MCC     AUC  LogLoss  \n",
              "0  0.8781  0.9833   0.2043  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# performance metrics on training set\n",
        "binary_classification_metrics(y_train,\n",
        "                              jnp.round(jax.nn.sigmoid(net(params, X_train)[:, 1]),0),\n",
        "                              jax.nn.sigmoid(net(params, X_train)[:, 1]),\n",
        "                              4\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KShQCNrAe9FR",
        "outputId": "90c8c9db-2a10-440e-acd3-05627023ce61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prevalence</th>\n",
              "      <th>Sensitivity</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>FPR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>AUC</th>\n",
              "      <th>LogLoss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5997</td>\n",
              "      <td>0.929</td>\n",
              "      <td>0.9435</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>0.961</td>\n",
              "      <td>0.9448</td>\n",
              "      <td>0.0565</td>\n",
              "      <td>0.8661</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>0.2093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prevalence  Sensitivity  Specificity  Accuracy  Precision      F1     FPR  \\\n",
              "0      0.5997        0.929       0.9435    0.9348      0.961  0.9448  0.0565   \n",
              "\n",
              "      MCC     AUC  LogLoss  \n",
              "0  0.8661  0.9793   0.2093  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# performance metrics on validation set\n",
        "binary_classification_metrics(y_test,\n",
        "                              jnp.round(jax.nn.sigmoid(net(params, X_test)[:, 1]),0),\n",
        "                              jax.nn.sigmoid(net(params, X_test)[:, 1]),\n",
        "                              4\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF738tWIe9FR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TlSqvyHe9FR"
      },
      "outputs": [],
      "source": [
        "# @jax.jit\n",
        "# def train_step(step, optim_state, x, y):\n",
        "#     params = optim_params(optim_state)\n",
        "#     loss, grads = jax.value_and_grad(lossforward)(params, x, y)\n",
        "#     optim_state = optim_update(step, grads, optim_state)\n",
        "#     return loss, optim_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6euc4znZe9FR"
      },
      "outputs": [],
      "source": [
        "# history = []\n",
        "# batch_size = 100\n",
        "# num_steps = 2000\n",
        "# for step in range(num_steps):\n",
        "#     if step%200 == 0 or step == num_steps - 1:\n",
        "#         valid_logits = forward(optim_params(optim_state), valid_values)\n",
        "#         valid_loss = xeloss(valid_logits, valid_labels)\n",
        "#         valid_accuracy = accuracy(valid_logits, valid_labels)\n",
        "#         history.append((step, valid_loss, valid_accuracy))\n",
        "#         print(f\"Step {step:5.0f}\\t Valid. Acc. = {valid_accuracy:5.2f}\")\n",
        "#     prng, key = jax.random.split(prng)\n",
        "#     idxs = jax.random.randint(key, (batch_size,), 0, train_size)\n",
        "#     x = train_values[idxs]\n",
        "#     y = train_labels[idxs]\n",
        "#     loss, optim_state = train_step(step, optim_state, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M7diHfoe9FR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygXEJIK2e9FR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUaBHlJ-e9FS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Snmy0qFARc"
      },
      "source": [
        "Reading financial data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OYHEZjFEy2b"
      },
      "outputs": [],
      "source": [
        "# from pandas_datareader import wb\n",
        "# from datetime import datetime\n",
        "# import plotly.graph_objects as go\n",
        "# import pandas_datareader.data as web\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaHPyWw2FIiM"
      },
      "outputs": [],
      "source": [
        "from pandas_datareader.nasdaq_trader import get_nasdaq_symbols\n",
        "symbols = get_nasdaq_symbols()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2KE1t-REy-7",
        "outputId": "33a3f88b-f467-439f-fa1f-dab74738d800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Nasdaq Traded                            True\n",
              "Security Name       Apple Inc. - Common Stock\n",
              "Listing Exchange                            Q\n",
              "Market Category                             Q\n",
              "ETF                                     False\n",
              "Round Lot Size                          100.0\n",
              "Test Issue                              False\n",
              "Financial Status                            N\n",
              "CQS Symbol                                NaN\n",
              "NASDAQ Symbol                            AAPL\n",
              "NextShares                              False\n",
              "Name: AAPL, dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "symbols.loc['AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6aUzNQcGBOH"
      },
      "outputs": [],
      "source": [
        "#stock = 'MSFT'\n",
        "symbol = 'WIKI/AAPL'  # or 'AAPL.US'\n",
        "start = datetime(2019, 1, 1)\n",
        "\n",
        "#df = web.DataReader(symbol, data_source='quandl', start=start)\n",
        "df = web.DataReader('^DJI', 'stooq')\n",
        "df = web.DataReader('^SPX', 'stooq')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "KBiKiyJlEzDz",
        "outputId": "d3d0b48a-4f15-46cc-96d6-6e288b7d6a87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-05-26</th>\n",
              "      <td>4156.16</td>\n",
              "      <td>4212.87</td>\n",
              "      <td>4156.16</td>\n",
              "      <td>4205.45</td>\n",
              "      <td>2.589576e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-25</th>\n",
              "      <td>4155.71</td>\n",
              "      <td>4165.74</td>\n",
              "      <td>4129.73</td>\n",
              "      <td>4151.28</td>\n",
              "      <td>2.827445e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-24</th>\n",
              "      <td>4132.96</td>\n",
              "      <td>4132.96</td>\n",
              "      <td>4103.98</td>\n",
              "      <td>4115.24</td>\n",
              "      <td>2.295841e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-23</th>\n",
              "      <td>4176.80</td>\n",
              "      <td>4185.68</td>\n",
              "      <td>4142.54</td>\n",
              "      <td>4145.58</td>\n",
              "      <td>2.437496e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-22</th>\n",
              "      <td>4190.78</td>\n",
              "      <td>4209.22</td>\n",
              "      <td>4179.68</td>\n",
              "      <td>4192.63</td>\n",
              "      <td>2.222521e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-06-04</th>\n",
              "      <td>2741.67</td>\n",
              "      <td>2749.16</td>\n",
              "      <td>2740.54</td>\n",
              "      <td>2746.87</td>\n",
              "      <td>1.875839e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-06-01</th>\n",
              "      <td>2718.70</td>\n",
              "      <td>2736.93</td>\n",
              "      <td>2718.70</td>\n",
              "      <td>2734.62</td>\n",
              "      <td>2.046739e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-31</th>\n",
              "      <td>2720.98</td>\n",
              "      <td>2722.50</td>\n",
              "      <td>2700.68</td>\n",
              "      <td>2705.27</td>\n",
              "      <td>2.352983e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-30</th>\n",
              "      <td>2702.43</td>\n",
              "      <td>2729.34</td>\n",
              "      <td>2702.43</td>\n",
              "      <td>2724.01</td>\n",
              "      <td>1.978361e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-29</th>\n",
              "      <td>2705.11</td>\n",
              "      <td>2710.67</td>\n",
              "      <td>2676.81</td>\n",
              "      <td>2689.86</td>\n",
              "      <td>2.076050e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1259 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Open     High      Low    Close        Volume\n",
              "Date                                                        \n",
              "2023-05-26  4156.16  4212.87  4156.16  4205.45  2.589576e+09\n",
              "2023-05-25  4155.71  4165.74  4129.73  4151.28  2.827445e+09\n",
              "2023-05-24  4132.96  4132.96  4103.98  4115.24  2.295841e+09\n",
              "2023-05-23  4176.80  4185.68  4142.54  4145.58  2.437496e+09\n",
              "2023-05-22  4190.78  4209.22  4179.68  4192.63  2.222521e+09\n",
              "...             ...      ...      ...      ...           ...\n",
              "2018-06-04  2741.67  2749.16  2740.54  2746.87  1.875839e+09\n",
              "2018-06-01  2718.70  2736.93  2718.70  2734.62  2.046739e+09\n",
              "2018-05-31  2720.98  2722.50  2700.68  2705.27  2.352983e+09\n",
              "2018-05-30  2702.43  2729.34  2702.43  2724.01  1.978361e+09\n",
              "2018-05-29  2705.11  2710.67  2676.81  2689.86  2.076050e+09\n",
              "\n",
              "[1259 rows x 5 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCDeR5S4nKLI"
      },
      "source": [
        "#### Use NASDAQ API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWJCcUmWnKLI"
      },
      "outputs": [],
      "source": [
        "oil = nasdaqdatalink.get('NSE/OIL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93SHNZOpnKLI",
        "outputId": "b9df9d34-22cc-4e60-eeab-da4c2a6a460e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Last</th>\n",
              "      <th>Close</th>\n",
              "      <th>Total Trade Quantity</th>\n",
              "      <th>Turnover (Lacs)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-09-30</th>\n",
              "      <td>1096.0</td>\n",
              "      <td>1156.7</td>\n",
              "      <td>1090.0</td>\n",
              "      <td>1135.00</td>\n",
              "      <td>1141.20</td>\n",
              "      <td>19748012.0</td>\n",
              "      <td>223877.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-10-01</th>\n",
              "      <td>1102.0</td>\n",
              "      <td>1173.7</td>\n",
              "      <td>1102.0</td>\n",
              "      <td>1167.00</td>\n",
              "      <td>1166.35</td>\n",
              "      <td>3074254.0</td>\n",
              "      <td>35463.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-10-05</th>\n",
              "      <td>1152.0</td>\n",
              "      <td>1165.9</td>\n",
              "      <td>1136.6</td>\n",
              "      <td>1143.00</td>\n",
              "      <td>1140.55</td>\n",
              "      <td>919832.0</td>\n",
              "      <td>10581.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-10-06</th>\n",
              "      <td>1149.8</td>\n",
              "      <td>1157.2</td>\n",
              "      <td>1132.1</td>\n",
              "      <td>1143.30</td>\n",
              "      <td>1144.90</td>\n",
              "      <td>627957.0</td>\n",
              "      <td>7185.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-10-07</th>\n",
              "      <td>1153.8</td>\n",
              "      <td>1160.7</td>\n",
              "      <td>1140.0</td>\n",
              "      <td>1141.45</td>\n",
              "      <td>1141.60</td>\n",
              "      <td>698216.0</td>\n",
              "      <td>8032.98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High     Low     Last    Close  Total Trade Quantity  \\\n",
              "Date                                                                         \n",
              "2009-09-30  1096.0  1156.7  1090.0  1135.00  1141.20            19748012.0   \n",
              "2009-10-01  1102.0  1173.7  1102.0  1167.00  1166.35             3074254.0   \n",
              "2009-10-05  1152.0  1165.9  1136.6  1143.00  1140.55              919832.0   \n",
              "2009-10-06  1149.8  1157.2  1132.1  1143.30  1144.90              627957.0   \n",
              "2009-10-07  1153.8  1160.7  1140.0  1141.45  1141.60              698216.0   \n",
              "\n",
              "            Turnover (Lacs)  \n",
              "Date                         \n",
              "2009-09-30        223877.07  \n",
              "2009-10-01         35463.78  \n",
              "2009-10-05         10581.13  \n",
              "2009-10-06          7185.90  \n",
              "2009-10-07          8032.98  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oil.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7UfqePhnKLI"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_oil = nasdaqdatalink.get(\"EIA/PET_RWTC_D\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUYwghTSnKLJ",
        "outputId": "d0279442-1716-49e0-8a3a-fc4f9783b5c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-02-02</th>\n",
              "      <td>88.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-03</th>\n",
              "      <td>90.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-04</th>\n",
              "      <td>92.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-07</th>\n",
              "      <td>91.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-08</th>\n",
              "      <td>89.32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Value\n",
              "Date             \n",
              "2022-02-02  88.16\n",
              "2022-02-03  90.17\n",
              "2022-02-04  92.27\n",
              "2022-02-07  91.25\n",
              "2022-02-08  89.32"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_oil.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27m50TXXnKLJ"
      },
      "source": [
        "#### Use yfinance\n",
        "pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYOqgVM6nKLJ"
      },
      "outputs": [],
      "source": [
        "#import yfinance as yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvLuTwxVnKLJ",
        "outputId": "425ad9c1-125e-4498-9359-ffa313c7a645"
      },
      "outputs": [
        {
          "ename": "HTTPError",
          "evalue": "401 Client Error: Unauthorized for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/GOOG?modules=summaryProfile%2CfinancialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&ssl=true",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ticker \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOOG\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(ticker)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(ticker.keys())\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/yfinance/ticker.py:138\u001b[0m, in \u001b[0;36mTicker.info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_info()\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/yfinance/base.py:1020\u001b[0m, in \u001b[0;36mTickerBase.get_info\u001b[0;34m(self, proxy)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quote\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;241m=\u001b[39m proxy\n\u001b[0;32m-> 1020\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quote\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/yfinance/scrapers/quote.py:555\u001b[0m, in \u001b[0;36mQuote.info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;66;03m# self._scrape(self.proxy)  # decrypt broken\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy)\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_complementary(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy)\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/yfinance/scrapers/quote.py:706\u001b[0m, in \u001b[0;36mQuote._fetch\u001b[0;34m(self, proxy)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_already_fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    704\u001b[0m modules \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummaryProfile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinancialData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquoteType\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    705\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefaultKeyStatistics\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massetProfile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummaryDetail\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 706\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mget_raw_json(\n\u001b[1;32m    707\u001b[0m     _BASIC_URL_ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodules\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(modules), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m}, proxy\u001b[38;5;241m=\u001b[39mproxy\n\u001b[1;32m    708\u001b[0m )\n\u001b[1;32m    709\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquoteSummary\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mticker\n\u001b[1;32m    710\u001b[0m query1_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m    711\u001b[0m     (info \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquoteSummary\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, []) \u001b[38;5;28;01mif\u001b[39;00m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mticker),\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    713\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/yfinance/data.py:209\u001b[0m, in \u001b[0;36mTickerData.get_raw_json\u001b[0;34m(self, url, user_agent_headers, params, proxy, timeout)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_raw_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, user_agent_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m    208\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(url, user_agent_headers\u001b[38;5;241m=\u001b[39muser_agent_headers, params\u001b[38;5;241m=\u001b[39mparams, proxy\u001b[38;5;241m=\u001b[39mproxy, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m--> 209\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/GOOG?modules=summaryProfile%2CfinancialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&ssl=true"
          ]
        }
      ],
      "source": [
        "ticker = yf.Ticker('GOOG').info\n",
        "print(ticker)\n",
        "#print(ticker.keys())\n",
        "market_price = ticker['currentPrice']\n",
        "previous_close_price = ticker['regularMarketPreviousClose']\n",
        "print('Ticker: GOOG')\n",
        "print('Market Price:', market_price)\n",
        "print('Previous Close Price:', previous_close_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5msgaFj7nKLJ",
        "outputId": "9b95a0f0-aec9-4522-9945-b856553342e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "                  Open        High         Low       Close   Adj Close  \\\n",
            "Date                                                                     \n",
            "2023-05-22  418.640015  420.390015  417.350006  418.790009  417.240143   \n",
            "2023-05-23  417.079987  418.720001  413.679993  414.089996  412.557526   \n",
            "2023-05-24  412.420013  412.820007  409.880005  411.089996  409.568604   \n",
            "2023-05-25  414.739990  416.160004  412.410004  414.649994  413.115448   \n",
            "2023-05-26  415.329987  420.769989  415.250000  420.019989  418.465546   \n",
            "\n",
            "              Volume  \n",
            "Date                  \n",
            "2023-05-22  60745400  \n",
            "2023-05-23  86383500  \n",
            "2023-05-24  89213700  \n",
            "2023-05-25  90961600  \n",
            "2023-05-26  93830000  \n"
          ]
        }
      ],
      "source": [
        "# Importing the yfinance package\n",
        "import yfinance as yf\n",
        "\n",
        "# Set the start and end date\n",
        "start_date = '2020-01-01'\n",
        "end_date = '2023-05-29'\n",
        "\n",
        "# Set the ticker\n",
        "ticker = 'SPY'\n",
        "\n",
        "# Get the data\n",
        "data = yf.download(ticker, start_date, end_date)\n",
        "\n",
        "# Print the last 5 rows\n",
        "print(data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgWGNgahnKLJ",
        "outputId": "464d3d07-8cf3-4fa1-bca7-92849c82fd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "            Adj Close                                  Close           \\\n",
            "                  AGG DBC VIXY        VTI   ^VIX         AGG DBC VIXY   \n",
            "Date                                                                    \n",
            "2006-01-03  59.071033 NaN  NaN  45.043736  11.14  100.639999 NaN  NaN   \n",
            "2006-01-04  59.211880 NaN  NaN  45.371265  11.37  100.879997 NaN  NaN   \n",
            "2006-01-05  59.211880 NaN  NaN  45.342472  11.31  100.879997 NaN  NaN   \n",
            "2006-01-06  59.076832 NaN  NaN  45.788773  11.00  100.650002 NaN  NaN   \n",
            "2006-01-09  59.141441 NaN  NaN  45.957928  11.13  100.760002 NaN  NaN   \n",
            "\n",
            "                              ...        Open                             \\\n",
            "                  VTI   ^VIX  ...         AGG DBC VIXY        VTI   ^VIX   \n",
            "Date                          ...                                          \n",
            "2006-01-03  62.575001  11.14  ...  100.470001 NaN  NaN  61.855000  12.25   \n",
            "2006-01-04  63.029999  11.37  ...  100.690002 NaN  NaN  62.660000  11.22   \n",
            "2006-01-05  62.990002  11.31  ...  100.820000 NaN  NaN  62.985001  11.43   \n",
            "2006-01-06  63.610001  11.00  ...  100.879997 NaN  NaN  63.415001  11.23   \n",
            "2006-01-09  63.845001  11.13  ...  100.739998 NaN  NaN  63.665001  11.35   \n",
            "\n",
            "            Volume                         \n",
            "               AGG DBC VIXY      VTI ^VIX  \n",
            "Date                                       \n",
            "2006-01-03  170600 NaN  NaN  1769800    0  \n",
            "2006-01-04  284500 NaN  NaN   763600    0  \n",
            "2006-01-05  203100 NaN  NaN   258200    0  \n",
            "2006-01-06  201100 NaN  NaN   436000    0  \n",
            "2006-01-09  170500 NaN  NaN   689600    0  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "            Adj Close                                               Close  \\\n",
            "                  AGG        DBC       VIXY         VTI   ^VIX        AGG   \n",
            "Date                                                                        \n",
            "2023-07-10  96.800003  23.030001  25.760000  218.990005  15.07  96.800003   \n",
            "2023-07-11  97.010002  23.299999  25.549999  220.710007  14.84  97.010002   \n",
            "2023-07-12  97.800003  23.469999  24.120001  222.399994  13.54  97.800003   \n",
            "2023-07-13  98.410004  23.799999  24.280001  224.279999  13.61  98.410004   \n",
            "2023-07-14  97.940002  23.639999  23.990000  223.949997  13.34  97.940002   \n",
            "\n",
            "                                                     ...       Open  \\\n",
            "                  DBC       VIXY         VTI   ^VIX  ...        AGG   \n",
            "Date                                                 ...              \n",
            "2023-07-10  23.030001  25.760000  218.990005  15.07  ...  96.570000   \n",
            "2023-07-11  23.299999  25.549999  220.710007  14.84  ...  96.940002   \n",
            "2023-07-12  23.469999  24.120001  222.399994  13.54  ...  97.510002   \n",
            "2023-07-13  23.799999  24.280001  224.279999  13.61  ...  98.180000   \n",
            "2023-07-14  23.639999  23.990000  223.949997  13.34  ...  98.230003   \n",
            "\n",
            "                                                      Volume            \\\n",
            "                  DBC       VIXY         VTI   ^VIX      AGG       DBC   \n",
            "Date                                                                     \n",
            "2023-07-10  22.980000  26.040001  217.899994  16.08  8827400  632400.0   \n",
            "2023-07-11  23.180000  25.240000  219.380005  15.02  5978500  457800.0   \n",
            "2023-07-12  23.520000  24.639999  222.570007  14.82  7189100  599600.0   \n",
            "2023-07-13  23.549999  23.670000  223.460007  13.44  7458500  582900.0   \n",
            "2023-07-14  23.830000  24.270000  224.850006  13.72  7208400  669800.0   \n",
            "\n",
            "                                     \n",
            "                 VIXY      VTI ^VIX  \n",
            "Date                                 \n",
            "2023-07-10  2625600.0  2080500    0  \n",
            "2023-07-11  3004200.0  2158200    0  \n",
            "2023-07-12  3307200.0  3030200    0  \n",
            "2023-07-13  2034000.0  4113300    0  \n",
            "2023-07-14  2294100.0  2911500    0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "start_date = '2006-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "# Add multiple space separated tickers here\n",
        "ticker = 'VTI AGG DBC VIXY ^VIX'\n",
        "data = yf.download(ticker, start_date, end_date)\n",
        "print(data.head())\n",
        "print(data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R6vLFvUnKLJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5Tu1jgPnKLJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80JLRaiEnKLJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUn0S07YGUfc"
      },
      "outputs": [],
      "source": [
        "# Functionality needed\n",
        "# Prepare data, train-test split.\n",
        "# Iputs are N securuties with daily data of length k.\n",
        "# Each asset is described by kxm matrix, where each one of the m features decribes something about the asset.\n",
        "# Price might be enough (or should be enough), but we can provide returns, highs, lows, ranges, volume, options data etc.\n",
        "# X will be of dimension kxmN\n",
        "# y could be a range, a TS of price, vol ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjaEuErenKLJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGGVh7yEnKLJ"
      },
      "source": [
        "### Prepare dataset for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M27ITNcbnKLJ",
        "outputId": "a5112ab7-6940-42b1-b944-f487297c3a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  4 of 4 completed\n",
            "             Adj Close                                     Close              \\\n",
            "                   QQQ         SPY         TLT  ^VIX         QQQ         SPY   \n",
            "Date                                                                           \n",
            "2018-01-02  152.677368  244.918671  111.429482  9.77  158.490005  268.769989   \n",
            "\n",
            "                                    High              ...     Low        \\\n",
            "                   TLT  ^VIX         QQQ         SPY  ...     TLT  ^VIX   \n",
            "Date                                                  ...                 \n",
            "2018-01-02  125.489998  9.77  158.529999  268.809998  ...  125.07  9.52   \n",
            "\n",
            "                  Open                                   Volume            \\\n",
            "                   QQQ         SPY         TLT   ^VIX       QQQ       SPY   \n",
            "Date                                                                        \n",
            "2018-01-02  156.559998  267.839996  126.489998  10.95  32573300  86655700   \n",
            "\n",
            "                           \n",
            "                 TLT ^VIX  \n",
            "Date                       \n",
            "2018-01-02  16238200    0  \n",
            "\n",
            "[1 rows x 24 columns]\n",
            "             Adj Close                                      Close              \\\n",
            "                   QQQ         SPY         TLT   ^VIX         QQQ         SPY   \n",
            "Date                                                                            \n",
            "2023-07-12  372.820007  446.019989  100.830002  13.54  372.820007  446.019989   \n",
            "2023-07-13  379.149994  449.559998  101.889999  13.61  379.149994  449.559998   \n",
            "\n",
            "                                     High              ...         Low         \\\n",
            "                   TLT   ^VIX         QQQ         SPY  ...         TLT   ^VIX   \n",
            "Date                                                   ...                      \n",
            "2023-07-12  100.830002  13.54  374.190002  447.480011  ...   99.769997  13.51   \n",
            "2023-07-13  101.889999  13.61  379.989990  450.380005  ...  101.029999  13.12   \n",
            "\n",
            "                  Open                                   Volume            \\\n",
            "                   QQQ         SPY         TLT   ^VIX       QQQ       SPY   \n",
            "Date                                                                        \n",
            "2023-07-12  372.339996  446.390015  100.099998  14.82  61975400  91924500   \n",
            "2023-07-13  376.049988  447.899994  101.309998  13.44  46960000  72425200   \n",
            "\n",
            "                           \n",
            "                 TLT ^VIX  \n",
            "Date                       \n",
            "2023-07-12  31928000    0  \n",
            "2023-07-13  32441500    0  \n",
            "\n",
            "[2 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "# create dataset\n",
        "start_date = '2018-01-01'\n",
        "end_date = '2023-07-14'\n",
        "tickers = 'SPY ^VIX TLT QQQ'\n",
        "\n",
        "data = yf.download(tickers, start_date, end_date)\n",
        "print(data.head(1))\n",
        "print(data.tail(2))\n",
        "#data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eJqrM1HnKLJ",
        "outputId": "7c49f8d2-318f-45ec-c9c7-a247c55fc71e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiIndex([('Adj Close',  'QQQ'),\n",
              "            ('Adj Close',  'SPY'),\n",
              "            ('Adj Close',  'TLT'),\n",
              "            ('Adj Close', '^VIX'),\n",
              "            (    'Close',  'QQQ'),\n",
              "            (    'Close',  'SPY'),\n",
              "            (    'Close',  'TLT'),\n",
              "            (    'Close', '^VIX'),\n",
              "            (     'High',  'QQQ'),\n",
              "            (     'High',  'SPY'),\n",
              "            (     'High',  'TLT'),\n",
              "            (     'High', '^VIX'),\n",
              "            (      'Low',  'QQQ'),\n",
              "            (      'Low',  'SPY'),\n",
              "            (      'Low',  'TLT'),\n",
              "            (      'Low', '^VIX'),\n",
              "            (     'Open',  'QQQ'),\n",
              "            (     'Open',  'SPY'),\n",
              "            (     'Open',  'TLT'),\n",
              "            (     'Open', '^VIX'),\n",
              "            (   'Volume',  'QQQ'),\n",
              "            (   'Volume',  'SPY'),\n",
              "            (   'Volume',  'TLT'),\n",
              "            (   'Volume', '^VIX')],\n",
              "           )"
            ]
          },
          "execution_count": 488,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq_cEGUSnKLJ",
        "outputId": "708e164e-0ad0-44e7-aee6-cc04522796bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Adj Close', 'SPY'), ('Adj Close', '^VIX'), ('Adj Close', 'TLT'), ('Adj Close', 'QQQ')]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>TLT</th>\n",
              "      <th>QQQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-02</th>\n",
              "      <td>244.918671</td>\n",
              "      <td>9.77</td>\n",
              "      <td>111.429482</td>\n",
              "      <td>152.677368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-03</th>\n",
              "      <td>246.467758</td>\n",
              "      <td>9.15</td>\n",
              "      <td>111.962242</td>\n",
              "      <td>154.160858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-04</th>\n",
              "      <td>247.506638</td>\n",
              "      <td>9.22</td>\n",
              "      <td>111.944473</td>\n",
              "      <td>154.430603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-05</th>\n",
              "      <td>249.155991</td>\n",
              "      <td>9.22</td>\n",
              "      <td>111.624779</td>\n",
              "      <td>155.981552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-08</th>\n",
              "      <td>249.611694</td>\n",
              "      <td>9.52</td>\n",
              "      <td>111.553772</td>\n",
              "      <td>156.588440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>438.549988</td>\n",
              "      <td>14.83</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>366.239990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-10</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>15.07</td>\n",
              "      <td>99.209999</td>\n",
              "      <td>366.359985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-11</th>\n",
              "      <td>442.459991</td>\n",
              "      <td>14.84</td>\n",
              "      <td>99.720001</td>\n",
              "      <td>368.170013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-12</th>\n",
              "      <td>446.019989</td>\n",
              "      <td>13.54</td>\n",
              "      <td>100.830002</td>\n",
              "      <td>372.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-13</th>\n",
              "      <td>449.559998</td>\n",
              "      <td>13.61</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>379.149994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1391 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close                               \n",
              "                   SPY   ^VIX         TLT         QQQ\n",
              "Date                                                 \n",
              "2018-01-02  244.918671   9.77  111.429482  152.677368\n",
              "2018-01-03  246.467758   9.15  111.962242  154.160858\n",
              "2018-01-04  247.506638   9.22  111.944473  154.430603\n",
              "2018-01-05  249.155991   9.22  111.624779  155.981552\n",
              "2018-01-08  249.611694   9.52  111.553772  156.588440\n",
              "...                ...    ...         ...         ...\n",
              "2023-07-07  438.549988  14.83   99.080002  366.239990\n",
              "2023-07-10  439.660004  15.07   99.209999  366.359985\n",
              "2023-07-11  442.459991  14.84   99.720001  368.170013\n",
              "2023-07-12  446.019989  13.54  100.830002  372.820007\n",
              "2023-07-13  449.559998  13.61  101.889999  379.149994\n",
              "\n",
              "[1391 rows x 4 columns]"
            ]
          },
          "execution_count": 489,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clmns = [('Adj Close', i) for i in tickers.split()]\n",
        "print(clmns)\n",
        "data[clmns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuRnkqygnKLJ"
      },
      "outputs": [],
      "source": [
        "# add returns\n",
        "for col in clmns:\n",
        "    data[('Ret', col[1])] = data[col]/data[col].shift(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnx0TZoGnKLJ",
        "outputId": "df7a1748-88da-4ee2-cecc-d3ba4d7f29ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Ret</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Ret</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>^VIX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-06-29</th>\n",
              "      <td>438.109985</td>\n",
              "      <td>1.003941</td>\n",
              "      <td>13.54</td>\n",
              "      <td>1.008191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>443.279999</td>\n",
              "      <td>1.011801</td>\n",
              "      <td>13.59</td>\n",
              "      <td>1.003693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03</th>\n",
              "      <td>443.790009</td>\n",
              "      <td>1.001151</td>\n",
              "      <td>13.57</td>\n",
              "      <td>0.998528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>443.130005</td>\n",
              "      <td>0.998513</td>\n",
              "      <td>14.18</td>\n",
              "      <td>1.044952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>0.992169</td>\n",
              "      <td>15.44</td>\n",
              "      <td>1.088857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>438.549988</td>\n",
              "      <td>0.997475</td>\n",
              "      <td>14.83</td>\n",
              "      <td>0.960492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-10</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>1.002531</td>\n",
              "      <td>15.07</td>\n",
              "      <td>1.016183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-11</th>\n",
              "      <td>442.459991</td>\n",
              "      <td>1.006369</td>\n",
              "      <td>14.84</td>\n",
              "      <td>0.984738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-12</th>\n",
              "      <td>446.019989</td>\n",
              "      <td>1.008046</td>\n",
              "      <td>13.54</td>\n",
              "      <td>0.912399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-13</th>\n",
              "      <td>449.559998</td>\n",
              "      <td>1.007937</td>\n",
              "      <td>13.61</td>\n",
              "      <td>1.005170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close       Ret Adj Close       Ret\n",
              "                   SPY       SPY      ^VIX      ^VIX\n",
              "Date                                                \n",
              "2023-06-29  438.109985  1.003941     13.54  1.008191\n",
              "2023-06-30  443.279999  1.011801     13.59  1.003693\n",
              "2023-07-03  443.790009  1.001151     13.57  0.998528\n",
              "2023-07-05  443.130005  0.998513     14.18  1.044952\n",
              "2023-07-06  439.660004  0.992169     15.44  1.088857\n",
              "2023-07-07  438.549988  0.997475     14.83  0.960492\n",
              "2023-07-10  439.660004  1.002531     15.07  1.016183\n",
              "2023-07-11  442.459991  1.006369     14.84  0.984738\n",
              "2023-07-12  446.019989  1.008046     13.54  0.912399\n",
              "2023-07-13  449.559998  1.007937     13.61  1.005170"
            ]
          },
          "execution_count": 491,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[[('Adj Close', 'SPY'), ('Ret', 'SPY'), ('Adj Close', '^VIX'), ('Ret', '^VIX')]].tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AILNAQhknKLJ"
      },
      "outputs": [],
      "source": [
        "def extractFinTS(start_date, end_date, tickers='SPY ^VIX TLT', hrzn=5):\n",
        "    \"\"\" Extract historical ts for the specified assets,\n",
        "        add computed columns.\"\"\"\n",
        "    l_tickers = tickers.split()\n",
        "    data = yf.download(l_tickers, start_date, end_date)\n",
        "    close_clmns = [('Adj Close', i) for i in l_tickers]\n",
        "    # add computed columns\n",
        "    for col in close_clmns:\n",
        "        data[('Ret', col[1])] = np.log(data[col]/data[col].shift(1))\n",
        "        data[('hh', col[1])] = np.log(data[col].rolling(hrzn).max().shift(-hrzn)/data[col])\n",
        "        data[('ll', col[1])] = np.log(data[col].rolling(hrzn).min().shift(-hrzn)/data[col])\n",
        "\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xb24yjYnKLJ",
        "outputId": "4cd7dc83-1797-4848-c55f-eeac3380d695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  3 of 3 completed\n"
          ]
        }
      ],
      "source": [
        "data = extractFinTS('2018-01-01', '2023-12-31')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdAcj-TOnKLK",
        "outputId": "23471ac3-e7a9-4149-a193-226918565e1d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Adj Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">High</th>\n",
              "      <th>Low</th>\n",
              "      <th>...</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Ret</th>\n",
              "      <th>hh</th>\n",
              "      <th>ll</th>\n",
              "      <th>Ret</th>\n",
              "      <th>hh</th>\n",
              "      <th>ll</th>\n",
              "      <th>Ret</th>\n",
              "      <th>hh</th>\n",
              "      <th>ll</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>...</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>SPY</th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>TLT</th>\n",
              "      <th>TLT</th>\n",
              "      <th>TLT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-06-16</th>\n",
              "      <td>439.459991</td>\n",
              "      <td>102.322914</td>\n",
              "      <td>13.54</td>\n",
              "      <td>439.459991</td>\n",
              "      <td>102.599998</td>\n",
              "      <td>13.54</td>\n",
              "      <td>443.609985</td>\n",
              "      <td>102.830002</td>\n",
              "      <td>14.540000</td>\n",
              "      <td>438.970001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.003412</td>\n",
              "      <td>-0.005202</td>\n",
              "      <td>-0.018418</td>\n",
              "      <td>-0.068500</td>\n",
              "      <td>0.051109</td>\n",
              "      <td>-0.047646</td>\n",
              "      <td>-0.003891</td>\n",
              "      <td>0.009313</td>\n",
              "      <td>-0.002830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-20</th>\n",
              "      <td>437.179993</td>\n",
              "      <td>103.030998</td>\n",
              "      <td>13.88</td>\n",
              "      <td>437.179993</td>\n",
              "      <td>103.309998</td>\n",
              "      <td>13.88</td>\n",
              "      <td>438.369995</td>\n",
              "      <td>103.660004</td>\n",
              "      <td>14.670000</td>\n",
              "      <td>435.029999</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.005202</td>\n",
              "      <td>-0.001534</td>\n",
              "      <td>-0.013217</td>\n",
              "      <td>0.024801</td>\n",
              "      <td>0.026308</td>\n",
              "      <td>-0.072447</td>\n",
              "      <td>0.006896</td>\n",
              "      <td>0.002417</td>\n",
              "      <td>-0.009727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-21</th>\n",
              "      <td>434.940002</td>\n",
              "      <td>103.280319</td>\n",
              "      <td>13.20</td>\n",
              "      <td>434.940002</td>\n",
              "      <td>103.559998</td>\n",
              "      <td>13.20</td>\n",
              "      <td>436.989990</td>\n",
              "      <td>103.650002</td>\n",
              "      <td>13.890000</td>\n",
              "      <td>434.329987</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.005137</td>\n",
              "      <td>0.003603</td>\n",
              "      <td>-0.008080</td>\n",
              "      <td>-0.050232</td>\n",
              "      <td>0.076540</td>\n",
              "      <td>-0.022215</td>\n",
              "      <td>0.002417</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>-0.012144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-22</th>\n",
              "      <td>436.510010</td>\n",
              "      <td>102.033699</td>\n",
              "      <td>12.91</td>\n",
              "      <td>436.510010</td>\n",
              "      <td>102.309998</td>\n",
              "      <td>12.91</td>\n",
              "      <td>436.619995</td>\n",
              "      <td>103.250000</td>\n",
              "      <td>13.980000</td>\n",
              "      <td>433.600006</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003603</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>-0.011683</td>\n",
              "      <td>-0.022215</td>\n",
              "      <td>0.098755</td>\n",
              "      <td>0.039489</td>\n",
              "      <td>-0.012144</td>\n",
              "      <td>0.012626</td>\n",
              "      <td>-0.005587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-23</th>\n",
              "      <td>433.209991</td>\n",
              "      <td>103.050949</td>\n",
              "      <td>13.44</td>\n",
              "      <td>433.209991</td>\n",
              "      <td>103.330002</td>\n",
              "      <td>13.44</td>\n",
              "      <td>435.059998</td>\n",
              "      <td>103.949997</td>\n",
              "      <td>13.800000</td>\n",
              "      <td>432.470001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.007589</td>\n",
              "      <td>0.022979</td>\n",
              "      <td>-0.004094</td>\n",
              "      <td>0.040233</td>\n",
              "      <td>0.058522</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>0.009920</td>\n",
              "      <td>0.002706</td>\n",
              "      <td>-0.015507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-26</th>\n",
              "      <td>431.440002</td>\n",
              "      <td>103.160652</td>\n",
              "      <td>14.25</td>\n",
              "      <td>431.440002</td>\n",
              "      <td>103.440002</td>\n",
              "      <td>14.25</td>\n",
              "      <td>434.609985</td>\n",
              "      <td>103.800003</td>\n",
              "      <td>14.710000</td>\n",
              "      <td>431.190002</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.004094</td>\n",
              "      <td>0.028223</td>\n",
              "      <td>0.010904</td>\n",
              "      <td>0.058522</td>\n",
              "      <td>-0.036446</td>\n",
              "      <td>-0.059266</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>0.001642</td>\n",
              "      <td>-0.016571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-27</th>\n",
              "      <td>436.170013</td>\n",
              "      <td>102.891373</td>\n",
              "      <td>13.74</td>\n",
              "      <td>436.170013</td>\n",
              "      <td>103.169998</td>\n",
              "      <td>13.74</td>\n",
              "      <td>436.809998</td>\n",
              "      <td>103.949997</td>\n",
              "      <td>14.340000</td>\n",
              "      <td>431.880005</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.010904</td>\n",
              "      <td>0.017319</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>-0.036446</td>\n",
              "      <td>0.031521</td>\n",
              "      <td>-0.022820</td>\n",
              "      <td>-0.002614</td>\n",
              "      <td>0.004256</td>\n",
              "      <td>-0.017465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-28</th>\n",
              "      <td>436.390015</td>\n",
              "      <td>103.330185</td>\n",
              "      <td>13.43</td>\n",
              "      <td>436.390015</td>\n",
              "      <td>103.610001</td>\n",
              "      <td>13.43</td>\n",
              "      <td>437.440002</td>\n",
              "      <td>103.839996</td>\n",
              "      <td>13.960000</td>\n",
              "      <td>434.410004</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.016815</td>\n",
              "      <td>0.003934</td>\n",
              "      <td>-0.022820</td>\n",
              "      <td>0.139470</td>\n",
              "      <td>0.008157</td>\n",
              "      <td>0.004256</td>\n",
              "      <td>-0.006487</td>\n",
              "      <td>-0.035964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-29</th>\n",
              "      <td>438.109985</td>\n",
              "      <td>101.465233</td>\n",
              "      <td>13.54</td>\n",
              "      <td>438.109985</td>\n",
              "      <td>101.739998</td>\n",
              "      <td>13.54</td>\n",
              "      <td>438.279999</td>\n",
              "      <td>102.339996</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>435.540009</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003934</td>\n",
              "      <td>0.012882</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>0.008157</td>\n",
              "      <td>0.131313</td>\n",
              "      <td>0.002213</td>\n",
              "      <td>-0.018213</td>\n",
              "      <td>0.011726</td>\n",
              "      <td>-0.023789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>443.279999</td>\n",
              "      <td>102.662003</td>\n",
              "      <td>13.59</td>\n",
              "      <td>443.279999</td>\n",
              "      <td>102.940002</td>\n",
              "      <td>13.59</td>\n",
              "      <td>444.299988</td>\n",
              "      <td>103.059998</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>441.109985</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011732</td>\n",
              "      <td>0.001150</td>\n",
              "      <td>-0.010728</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.127627</td>\n",
              "      <td>-0.001473</td>\n",
              "      <td>0.011726</td>\n",
              "      <td>-0.005685</td>\n",
              "      <td>-0.035514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03</th>\n",
              "      <td>443.790009</td>\n",
              "      <td>102.080002</td>\n",
              "      <td>13.57</td>\n",
              "      <td>443.790009</td>\n",
              "      <td>102.080002</td>\n",
              "      <td>13.57</td>\n",
              "      <td>444.079987</td>\n",
              "      <td>103.260002</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>442.630005</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001150</td>\n",
              "      <td>-0.001488</td>\n",
              "      <td>-0.011878</td>\n",
              "      <td>-0.001473</td>\n",
              "      <td>0.129100</td>\n",
              "      <td>0.043971</td>\n",
              "      <td>-0.005685</td>\n",
              "      <td>-0.009548</td>\n",
              "      <td>-0.029829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>443.130005</td>\n",
              "      <td>101.110001</td>\n",
              "      <td>14.18</td>\n",
              "      <td>443.130005</td>\n",
              "      <td>101.110001</td>\n",
              "      <td>14.18</td>\n",
              "      <td>443.890015</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>14.740000</td>\n",
              "      <td>441.899994</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.001488</td>\n",
              "      <td>0.006501</td>\n",
              "      <td>-0.010389</td>\n",
              "      <td>0.043971</td>\n",
              "      <td>0.085129</td>\n",
              "      <td>-0.046184</td>\n",
              "      <td>-0.009548</td>\n",
              "      <td>-0.002773</td>\n",
              "      <td>-0.020281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.680000</td>\n",
              "      <td>15.44</td>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.680000</td>\n",
              "      <td>15.44</td>\n",
              "      <td>440.100006</td>\n",
              "      <td>100.379997</td>\n",
              "      <td>17.080000</td>\n",
              "      <td>437.059998</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.007861</td>\n",
              "      <td>0.022268</td>\n",
              "      <td>-0.002528</td>\n",
              "      <td>0.085129</td>\n",
              "      <td>-0.024256</td>\n",
              "      <td>-0.131313</td>\n",
              "      <td>-0.014244</td>\n",
              "      <td>0.021929</td>\n",
              "      <td>-0.006037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>438.549988</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>14.83</td>\n",
              "      <td>438.549988</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>14.83</td>\n",
              "      <td>442.640015</td>\n",
              "      <td>99.599998</td>\n",
              "      <td>16.059999</td>\n",
              "      <td>438.299988</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.002528</td>\n",
              "      <td>0.024796</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>-0.040309</td>\n",
              "      <td>0.016054</td>\n",
              "      <td>-0.105885</td>\n",
              "      <td>-0.006037</td>\n",
              "      <td>0.027966</td>\n",
              "      <td>0.001311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-10</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.209999</td>\n",
              "      <td>15.07</td>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.209999</td>\n",
              "      <td>15.07</td>\n",
              "      <td>439.839996</td>\n",
              "      <td>99.529999</td>\n",
              "      <td>16.209999</td>\n",
              "      <td>437.589996</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.016054</td>\n",
              "      <td>-0.015380</td>\n",
              "      <td>-0.121939</td>\n",
              "      <td>0.001311</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-11</th>\n",
              "      <td>442.459991</td>\n",
              "      <td>99.720001</td>\n",
              "      <td>14.84</td>\n",
              "      <td>442.459991</td>\n",
              "      <td>99.720001</td>\n",
              "      <td>14.84</td>\n",
              "      <td>442.970001</td>\n",
              "      <td>99.970001</td>\n",
              "      <td>15.250000</td>\n",
              "      <td>439.440002</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006348</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.015380</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-12</th>\n",
              "      <td>446.019989</td>\n",
              "      <td>100.830002</td>\n",
              "      <td>13.54</td>\n",
              "      <td>446.019989</td>\n",
              "      <td>100.830002</td>\n",
              "      <td>13.54</td>\n",
              "      <td>447.480011</td>\n",
              "      <td>101.120003</td>\n",
              "      <td>14.820000</td>\n",
              "      <td>444.910004</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.008014</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.091678</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.011070</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-13</th>\n",
              "      <td>449.559998</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>13.61</td>\n",
              "      <td>449.559998</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>13.61</td>\n",
              "      <td>450.380005</td>\n",
              "      <td>101.970001</td>\n",
              "      <td>13.610000</td>\n",
              "      <td>447.450012</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007906</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.005157</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.010458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-14</th>\n",
              "      <td>449.279999</td>\n",
              "      <td>101.290001</td>\n",
              "      <td>13.34</td>\n",
              "      <td>449.279999</td>\n",
              "      <td>101.290001</td>\n",
              "      <td>13.34</td>\n",
              "      <td>451.359985</td>\n",
              "      <td>101.940002</td>\n",
              "      <td>13.760000</td>\n",
              "      <td>448.489990</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.000623</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.020038</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.005906</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.041841</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close                          Close                     \\\n",
              "                   SPY         TLT   ^VIX         SPY         TLT   ^VIX   \n",
              "Date                                                                       \n",
              "2023-06-16  439.459991  102.322914  13.54  439.459991  102.599998  13.54   \n",
              "2023-06-20  437.179993  103.030998  13.88  437.179993  103.309998  13.88   \n",
              "2023-06-21  434.940002  103.280319  13.20  434.940002  103.559998  13.20   \n",
              "2023-06-22  436.510010  102.033699  12.91  436.510010  102.309998  12.91   \n",
              "2023-06-23  433.209991  103.050949  13.44  433.209991  103.330002  13.44   \n",
              "2023-06-26  431.440002  103.160652  14.25  431.440002  103.440002  14.25   \n",
              "2023-06-27  436.170013  102.891373  13.74  436.170013  103.169998  13.74   \n",
              "2023-06-28  436.390015  103.330185  13.43  436.390015  103.610001  13.43   \n",
              "2023-06-29  438.109985  101.465233  13.54  438.109985  101.739998  13.54   \n",
              "2023-06-30  443.279999  102.662003  13.59  443.279999  102.940002  13.59   \n",
              "2023-07-03  443.790009  102.080002  13.57  443.790009  102.080002  13.57   \n",
              "2023-07-05  443.130005  101.110001  14.18  443.130005  101.110001  14.18   \n",
              "2023-07-06  439.660004   99.680000  15.44  439.660004   99.680000  15.44   \n",
              "2023-07-07  438.549988   99.080002  14.83  438.549988   99.080002  14.83   \n",
              "2023-07-10  439.660004   99.209999  15.07  439.660004   99.209999  15.07   \n",
              "2023-07-11  442.459991   99.720001  14.84  442.459991   99.720001  14.84   \n",
              "2023-07-12  446.019989  100.830002  13.54  446.019989  100.830002  13.54   \n",
              "2023-07-13  449.559998  101.889999  13.61  449.559998  101.889999  13.61   \n",
              "2023-07-14  449.279999  101.290001  13.34  449.279999  101.290001  13.34   \n",
              "2023-07-17         NaN         NaN  13.91         NaN         NaN  13.91   \n",
              "\n",
              "                  High                                Low  ... Volume  \\\n",
              "                   SPY         TLT       ^VIX         SPY  ...   ^VIX   \n",
              "Date                                                       ...          \n",
              "2023-06-16  443.609985  102.830002  14.540000  438.970001  ...      0   \n",
              "2023-06-20  438.369995  103.660004  14.670000  435.029999  ...      0   \n",
              "2023-06-21  436.989990  103.650002  13.890000  434.329987  ...      0   \n",
              "2023-06-22  436.619995  103.250000  13.980000  433.600006  ...      0   \n",
              "2023-06-23  435.059998  103.949997  13.800000  432.470001  ...      0   \n",
              "2023-06-26  434.609985  103.800003  14.710000  431.190002  ...      0   \n",
              "2023-06-27  436.809998  103.949997  14.340000  431.880005  ...      0   \n",
              "2023-06-28  437.440002  103.839996  13.960000  434.410004  ...      0   \n",
              "2023-06-29  438.279999  102.339996  13.850000  435.540009  ...      0   \n",
              "2023-06-30  444.299988  103.059998  13.590000  441.109985  ...      0   \n",
              "2023-07-03  444.079987  103.260002  13.850000  442.630005  ...      0   \n",
              "2023-07-05  443.890015  102.000000  14.740000  441.899994  ...      0   \n",
              "2023-07-06  440.100006  100.379997  17.080000  437.059998  ...      0   \n",
              "2023-07-07  442.640015   99.599998  16.059999  438.299988  ...      0   \n",
              "2023-07-10  439.839996   99.529999  16.209999  437.589996  ...      0   \n",
              "2023-07-11  442.970001   99.970001  15.250000  439.440002  ...      0   \n",
              "2023-07-12  447.480011  101.120003  14.820000  444.910004  ...      0   \n",
              "2023-07-13  450.380005  101.970001  13.610000  447.450012  ...      0   \n",
              "2023-07-14  451.359985  101.940002  13.760000  448.489990  ...      0   \n",
              "2023-07-17         NaN         NaN  14.000000         NaN  ...      0   \n",
              "\n",
              "                 Ret        hh        ll       Ret        hh        ll  \\\n",
              "                 SPY       SPY       SPY      ^VIX      ^VIX      ^VIX   \n",
              "Date                                                                     \n",
              "2023-06-16 -0.003412 -0.005202 -0.018418 -0.068500  0.051109 -0.047646   \n",
              "2023-06-20 -0.005202 -0.001534 -0.013217  0.024801  0.026308 -0.072447   \n",
              "2023-06-21 -0.005137  0.003603 -0.008080 -0.050232  0.076540 -0.022215   \n",
              "2023-06-22  0.003603  0.003659 -0.011683 -0.022215  0.098755  0.039489   \n",
              "2023-06-23 -0.007589  0.022979 -0.004094  0.040233  0.058522 -0.000744   \n",
              "2023-06-26 -0.004094  0.028223  0.010904  0.058522 -0.036446 -0.059266   \n",
              "2023-06-27  0.010904  0.017319  0.000504 -0.036446  0.031521 -0.022820   \n",
              "2023-06-28  0.000504  0.016815  0.003934 -0.022820  0.139470  0.008157   \n",
              "2023-06-29  0.003934  0.012882  0.001004  0.008157  0.131313  0.002213   \n",
              "2023-06-30  0.011732  0.001150 -0.010728  0.003686  0.127627 -0.001473   \n",
              "2023-07-03  0.001150 -0.001488 -0.011878 -0.001473  0.129100  0.043971   \n",
              "2023-07-05 -0.001488  0.006501 -0.010389  0.043971  0.085129 -0.046184   \n",
              "2023-07-06 -0.007861  0.022268 -0.002528  0.085129 -0.024256 -0.131313   \n",
              "2023-07-07 -0.002528  0.024796  0.002528 -0.040309  0.016054 -0.105885   \n",
              "2023-07-10  0.002528       NaN       NaN  0.016054 -0.015380 -0.121939   \n",
              "2023-07-11  0.006348       NaN       NaN -0.015380       NaN       NaN   \n",
              "2023-07-12  0.008014       NaN       NaN -0.091678       NaN       NaN   \n",
              "2023-07-13  0.007906       NaN       NaN  0.005157       NaN       NaN   \n",
              "2023-07-14 -0.000623       NaN       NaN -0.020038       NaN       NaN   \n",
              "2023-07-17       NaN       NaN       NaN  0.041841       NaN       NaN   \n",
              "\n",
              "                 Ret        hh        ll  \n",
              "                 TLT       TLT       TLT  \n",
              "Date                                      \n",
              "2023-06-16 -0.003891  0.009313 -0.002830  \n",
              "2023-06-20  0.006896  0.002417 -0.009727  \n",
              "2023-06-21  0.002417  0.000483 -0.012144  \n",
              "2023-06-22 -0.012144  0.012626 -0.005587  \n",
              "2023-06-23  0.009920  0.002706 -0.015507  \n",
              "2023-06-26  0.001064  0.001642 -0.016571  \n",
              "2023-06-27 -0.002614  0.004256 -0.017465  \n",
              "2023-06-28  0.004256 -0.006487 -0.035964  \n",
              "2023-06-29 -0.018213  0.011726 -0.023789  \n",
              "2023-06-30  0.011726 -0.005685 -0.035514  \n",
              "2023-07-03 -0.005685 -0.009548 -0.029829  \n",
              "2023-07-05 -0.009548 -0.002773 -0.020281  \n",
              "2023-07-06 -0.014244  0.021929 -0.006037  \n",
              "2023-07-07 -0.006037  0.027966  0.001311  \n",
              "2023-07-10  0.001311       NaN       NaN  \n",
              "2023-07-11  0.005127       NaN       NaN  \n",
              "2023-07-12  0.011070       NaN       NaN  \n",
              "2023-07-13  0.010458       NaN       NaN  \n",
              "2023-07-14 -0.005906       NaN       NaN  \n",
              "2023-07-17       NaN       NaN       NaN  \n",
              "\n",
              "[20 rows x 27 columns]"
            ]
          },
          "execution_count": 685,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-CHwlMBnKLK",
        "outputId": "05207650-8f6d-4d0c-8b94-806d979b7b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-14 00:00:00\n",
            "Friday\n",
            "Monday Tuesday Thursday\n"
          ]
        }
      ],
      "source": [
        "d = pd.Timestamp('2023-7-14')\n",
        "print(d)\n",
        "print(d.day_name())\n",
        "d1 = d + pd.offsets.BDay()\n",
        "d2 = d + pd.offsets.BDay(2)\n",
        "d3 = d + pd.offsets.BDay(-1)\n",
        "print(d1.day_name(), d2.day_name(), d3.day_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwT-nlcznKLK",
        "outputId": "5bdff20a-d49d-4a42-d0bf-21c68793412c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Adj Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">High</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Low</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Open</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Volume</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Ret</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>...</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>TLT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-17</th>\n",
              "      <td>404.210144</td>\n",
              "      <td>101.070587</td>\n",
              "      <td>20.020000</td>\n",
              "      <td>407.260010</td>\n",
              "      <td>102.379997</td>\n",
              "      <td>20.020000</td>\n",
              "      <td>407.510010</td>\n",
              "      <td>102.379997</td>\n",
              "      <td>21.299999</td>\n",
              "      <td>404.049988</td>\n",
              "      <td>...</td>\n",
              "      <td>19.820000</td>\n",
              "      <td>406.059998</td>\n",
              "      <td>101.099998</td>\n",
              "      <td>20.940001</td>\n",
              "      <td>89257800</td>\n",
              "      <td>19560900</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997502</td>\n",
              "      <td>0.992563</td>\n",
              "      <td>1.007776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-21</th>\n",
              "      <td>396.101318</td>\n",
              "      <td>99.106041</td>\n",
              "      <td>22.870001</td>\n",
              "      <td>399.089996</td>\n",
              "      <td>100.389999</td>\n",
              "      <td>22.870001</td>\n",
              "      <td>404.160004</td>\n",
              "      <td>101.199997</td>\n",
              "      <td>23.340000</td>\n",
              "      <td>398.820007</td>\n",
              "      <td>...</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>403.059998</td>\n",
              "      <td>101.010002</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>82655900</td>\n",
              "      <td>22728000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.979939</td>\n",
              "      <td>1.142358</td>\n",
              "      <td>0.980563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-22</th>\n",
              "      <td>395.555420</td>\n",
              "      <td>100.014267</td>\n",
              "      <td>22.290001</td>\n",
              "      <td>398.540009</td>\n",
              "      <td>101.309998</td>\n",
              "      <td>22.290001</td>\n",
              "      <td>401.130005</td>\n",
              "      <td>101.690002</td>\n",
              "      <td>23.629999</td>\n",
              "      <td>397.019989</td>\n",
              "      <td>...</td>\n",
              "      <td>22.020000</td>\n",
              "      <td>399.519989</td>\n",
              "      <td>100.989998</td>\n",
              "      <td>23.030001</td>\n",
              "      <td>83742300</td>\n",
              "      <td>15165400</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998622</td>\n",
              "      <td>0.974639</td>\n",
              "      <td>1.009164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-23</th>\n",
              "      <td>397.659546</td>\n",
              "      <td>100.991623</td>\n",
              "      <td>21.139999</td>\n",
              "      <td>400.660004</td>\n",
              "      <td>102.300003</td>\n",
              "      <td>21.139999</td>\n",
              "      <td>402.200012</td>\n",
              "      <td>102.589996</td>\n",
              "      <td>22.430000</td>\n",
              "      <td>396.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>20.889999</td>\n",
              "      <td>401.559998</td>\n",
              "      <td>101.540001</td>\n",
              "      <td>21.959999</td>\n",
              "      <td>96242400</td>\n",
              "      <td>15829100</td>\n",
              "      <td>0</td>\n",
              "      <td>1.005319</td>\n",
              "      <td>0.948407</td>\n",
              "      <td>1.009772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-24</th>\n",
              "      <td>393.411591</td>\n",
              "      <td>99.678627</td>\n",
              "      <td>21.670000</td>\n",
              "      <td>396.380005</td>\n",
              "      <td>100.970001</td>\n",
              "      <td>21.670000</td>\n",
              "      <td>397.250000</td>\n",
              "      <td>101.800003</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>393.640015</td>\n",
              "      <td>...</td>\n",
              "      <td>21.320000</td>\n",
              "      <td>395.420013</td>\n",
              "      <td>101.440002</td>\n",
              "      <td>21.350000</td>\n",
              "      <td>108194400</td>\n",
              "      <td>21403600</td>\n",
              "      <td>0</td>\n",
              "      <td>0.989318</td>\n",
              "      <td>1.025071</td>\n",
              "      <td>0.986999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>443.279999</td>\n",
              "      <td>102.662003</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>443.279999</td>\n",
              "      <td>102.940002</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>444.299988</td>\n",
              "      <td>103.059998</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>441.109985</td>\n",
              "      <td>...</td>\n",
              "      <td>12.960000</td>\n",
              "      <td>441.440002</td>\n",
              "      <td>102.059998</td>\n",
              "      <td>13.510000</td>\n",
              "      <td>104921500</td>\n",
              "      <td>32018800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.011801</td>\n",
              "      <td>1.003693</td>\n",
              "      <td>1.011795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03</th>\n",
              "      <td>443.790009</td>\n",
              "      <td>102.080002</td>\n",
              "      <td>13.570000</td>\n",
              "      <td>443.790009</td>\n",
              "      <td>102.080002</td>\n",
              "      <td>13.570000</td>\n",
              "      <td>444.079987</td>\n",
              "      <td>103.260002</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>442.630005</td>\n",
              "      <td>...</td>\n",
              "      <td>13.470000</td>\n",
              "      <td>442.920013</td>\n",
              "      <td>102.839996</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>32793400</td>\n",
              "      <td>16011800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.001151</td>\n",
              "      <td>0.998528</td>\n",
              "      <td>0.994331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>443.130005</td>\n",
              "      <td>101.110001</td>\n",
              "      <td>14.180000</td>\n",
              "      <td>443.130005</td>\n",
              "      <td>101.110001</td>\n",
              "      <td>14.180000</td>\n",
              "      <td>443.890015</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>14.740000</td>\n",
              "      <td>441.899994</td>\n",
              "      <td>...</td>\n",
              "      <td>14.050000</td>\n",
              "      <td>441.910004</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>14.190000</td>\n",
              "      <td>58418400</td>\n",
              "      <td>28170300</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998513</td>\n",
              "      <td>1.044952</td>\n",
              "      <td>0.990498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.680000</td>\n",
              "      <td>15.440000</td>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.680000</td>\n",
              "      <td>15.440000</td>\n",
              "      <td>440.100006</td>\n",
              "      <td>100.379997</td>\n",
              "      <td>17.080000</td>\n",
              "      <td>437.059998</td>\n",
              "      <td>...</td>\n",
              "      <td>14.790000</td>\n",
              "      <td>439.420013</td>\n",
              "      <td>100.199997</td>\n",
              "      <td>14.850000</td>\n",
              "      <td>80658300</td>\n",
              "      <td>41375700</td>\n",
              "      <td>0</td>\n",
              "      <td>0.992169</td>\n",
              "      <td>1.088857</td>\n",
              "      <td>0.985857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>438.549988</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>14.830000</td>\n",
              "      <td>438.549988</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>14.830000</td>\n",
              "      <td>442.640015</td>\n",
              "      <td>99.599998</td>\n",
              "      <td>16.059999</td>\n",
              "      <td>438.299988</td>\n",
              "      <td>...</td>\n",
              "      <td>14.330000</td>\n",
              "      <td>438.630005</td>\n",
              "      <td>99.180000</td>\n",
              "      <td>15.970000</td>\n",
              "      <td>86076100</td>\n",
              "      <td>28979600</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997475</td>\n",
              "      <td>0.960492</td>\n",
              "      <td>0.993981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close                              Close              \\\n",
              "                   SPY         TLT       ^VIX         SPY         TLT   \n",
              "Date                                                                    \n",
              "2023-02-17  404.210144  101.070587  20.020000  407.260010  102.379997   \n",
              "2023-02-21  396.101318   99.106041  22.870001  399.089996  100.389999   \n",
              "2023-02-22  395.555420  100.014267  22.290001  398.540009  101.309998   \n",
              "2023-02-23  397.659546  100.991623  21.139999  400.660004  102.300003   \n",
              "2023-02-24  393.411591   99.678627  21.670000  396.380005  100.970001   \n",
              "...                ...         ...        ...         ...         ...   \n",
              "2023-06-30  443.279999  102.662003  13.590000  443.279999  102.940002   \n",
              "2023-07-03  443.790009  102.080002  13.570000  443.790009  102.080002   \n",
              "2023-07-05  443.130005  101.110001  14.180000  443.130005  101.110001   \n",
              "2023-07-06  439.660004   99.680000  15.440000  439.660004   99.680000   \n",
              "2023-07-07  438.549988   99.080002  14.830000  438.549988   99.080002   \n",
              "\n",
              "                             High                                Low  ...  \\\n",
              "                 ^VIX         SPY         TLT       ^VIX         SPY  ...   \n",
              "Date                                                                  ...   \n",
              "2023-02-17  20.020000  407.510010  102.379997  21.299999  404.049988  ...   \n",
              "2023-02-21  22.870001  404.160004  101.199997  23.340000  398.820007  ...   \n",
              "2023-02-22  22.290001  401.130005  101.690002  23.629999  397.019989  ...   \n",
              "2023-02-23  21.139999  402.200012  102.589996  22.430000  396.250000  ...   \n",
              "2023-02-24  21.670000  397.250000  101.800003  22.900000  393.640015  ...   \n",
              "...               ...         ...         ...        ...         ...  ...   \n",
              "2023-06-30  13.590000  444.299988  103.059998  13.590000  441.109985  ...   \n",
              "2023-07-03  13.570000  444.079987  103.260002  13.850000  442.630005  ...   \n",
              "2023-07-05  14.180000  443.890015  102.000000  14.740000  441.899994  ...   \n",
              "2023-07-06  15.440000  440.100006  100.379997  17.080000  437.059998  ...   \n",
              "2023-07-07  14.830000  442.640015   99.599998  16.059999  438.299988  ...   \n",
              "\n",
              "                             Open                            Volume            \\\n",
              "                 ^VIX         SPY         TLT       ^VIX        SPY       TLT   \n",
              "Date                                                                            \n",
              "2023-02-17  19.820000  406.059998  101.099998  20.940001   89257800  19560900   \n",
              "2023-02-21  21.799999  403.059998  101.010002  21.799999   82655900  22728000   \n",
              "2023-02-22  22.020000  399.519989  100.989998  23.030001   83742300  15165400   \n",
              "2023-02-23  20.889999  401.559998  101.540001  21.959999   96242400  15829100   \n",
              "2023-02-24  21.320000  395.420013  101.440002  21.350000  108194400  21403600   \n",
              "...               ...         ...         ...        ...        ...       ...   \n",
              "2023-06-30  12.960000  441.440002  102.059998  13.510000  104921500  32018800   \n",
              "2023-07-03  13.470000  442.920013  102.839996  13.850000   32793400  16011800   \n",
              "2023-07-05  14.050000  441.910004  101.889999  14.190000   58418400  28170300   \n",
              "2023-07-06  14.790000  439.420013  100.199997  14.850000   80658300  41375700   \n",
              "2023-07-07  14.330000  438.630005   99.180000  15.970000   86076100  28979600   \n",
              "\n",
              "                      Ret                      \n",
              "           ^VIX       SPY      ^VIX       TLT  \n",
              "Date                                           \n",
              "2023-02-17    0  0.997502  0.992563  1.007776  \n",
              "2023-02-21    0  0.979939  1.142358  0.980563  \n",
              "2023-02-22    0  0.998622  0.974639  1.009164  \n",
              "2023-02-23    0  1.005319  0.948407  1.009772  \n",
              "2023-02-24    0  0.989318  1.025071  0.986999  \n",
              "...         ...       ...       ...       ...  \n",
              "2023-06-30    0  1.011801  1.003693  1.011795  \n",
              "2023-07-03    0  1.001151  0.998528  0.994331  \n",
              "2023-07-05    0  0.998513  1.044952  0.990498  \n",
              "2023-07-06    0  0.992169  1.088857  0.985857  \n",
              "2023-07-07    0  0.997475  0.960492  0.993981  \n",
              "\n",
              "[96 rows x 21 columns]"
            ]
          },
          "execution_count": 548,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train\n",
        "data.loc[d + pd.offsets.BDay(-(100 + 5)) : d + pd.offsets.BDay(-5) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbxuqgGOnKLK",
        "outputId": "ec96c649-ca10-4046-f1f7-112678eee32b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Adj Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">High</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Low</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Open</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Volume</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Ret</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>...</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>TLT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-05-05</th>\n",
              "      <td>411.102936</td>\n",
              "      <td>104.329445</td>\n",
              "      <td>17.190001</td>\n",
              "      <td>412.630005</td>\n",
              "      <td>104.889999</td>\n",
              "      <td>17.190001</td>\n",
              "      <td>413.720001</td>\n",
              "      <td>104.900002</td>\n",
              "      <td>19.629999</td>\n",
              "      <td>408.640015</td>\n",
              "      <td>...</td>\n",
              "      <td>16.690001</td>\n",
              "      <td>408.910004</td>\n",
              "      <td>104.349998</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>87844000</td>\n",
              "      <td>15090900</td>\n",
              "      <td>0</td>\n",
              "      <td>1.018513</td>\n",
              "      <td>0.855650</td>\n",
              "      <td>0.996674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-08</th>\n",
              "      <td>411.212494</td>\n",
              "      <td>102.867302</td>\n",
              "      <td>16.980000</td>\n",
              "      <td>412.739990</td>\n",
              "      <td>103.419998</td>\n",
              "      <td>16.980000</td>\n",
              "      <td>413.239990</td>\n",
              "      <td>103.870003</td>\n",
              "      <td>17.879999</td>\n",
              "      <td>411.279999</td>\n",
              "      <td>...</td>\n",
              "      <td>16.830000</td>\n",
              "      <td>412.970001</td>\n",
              "      <td>103.519997</td>\n",
              "      <td>17.730000</td>\n",
              "      <td>50046800</td>\n",
              "      <td>20587000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000266</td>\n",
              "      <td>0.987784</td>\n",
              "      <td>0.985985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-09</th>\n",
              "      <td>409.409210</td>\n",
              "      <td>102.499283</td>\n",
              "      <td>17.709999</td>\n",
              "      <td>410.929993</td>\n",
              "      <td>103.050003</td>\n",
              "      <td>17.709999</td>\n",
              "      <td>412.089996</td>\n",
              "      <td>103.639999</td>\n",
              "      <td>17.860001</td>\n",
              "      <td>410.690002</td>\n",
              "      <td>...</td>\n",
              "      <td>17.219999</td>\n",
              "      <td>411.130005</td>\n",
              "      <td>103.500000</td>\n",
              "      <td>17.290001</td>\n",
              "      <td>49220100</td>\n",
              "      <td>19182500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.995615</td>\n",
              "      <td>1.042992</td>\n",
              "      <td>0.996422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-10</th>\n",
              "      <td>411.322113</td>\n",
              "      <td>103.493935</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>412.850006</td>\n",
              "      <td>104.050003</td>\n",
              "      <td>16.940001</td>\n",
              "      <td>414.540009</td>\n",
              "      <td>104.239998</td>\n",
              "      <td>18.309999</td>\n",
              "      <td>408.869995</td>\n",
              "      <td>...</td>\n",
              "      <td>16.360001</td>\n",
              "      <td>413.880005</td>\n",
              "      <td>103.669998</td>\n",
              "      <td>17.580000</td>\n",
              "      <td>96142900</td>\n",
              "      <td>22886800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.004672</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>1.009704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-11</th>\n",
              "      <td>410.604767</td>\n",
              "      <td>104.588058</td>\n",
              "      <td>16.930000</td>\n",
              "      <td>412.130005</td>\n",
              "      <td>105.150002</td>\n",
              "      <td>16.930000</td>\n",
              "      <td>412.429993</td>\n",
              "      <td>105.519997</td>\n",
              "      <td>18.190001</td>\n",
              "      <td>409.970001</td>\n",
              "      <td>...</td>\n",
              "      <td>16.629999</td>\n",
              "      <td>411.950012</td>\n",
              "      <td>105.300003</td>\n",
              "      <td>16.799999</td>\n",
              "      <td>70157100</td>\n",
              "      <td>19147200</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998256</td>\n",
              "      <td>0.999410</td>\n",
              "      <td>1.010572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-12</th>\n",
              "      <td>410.066772</td>\n",
              "      <td>103.712761</td>\n",
              "      <td>17.030001</td>\n",
              "      <td>411.589996</td>\n",
              "      <td>104.269997</td>\n",
              "      <td>17.030001</td>\n",
              "      <td>413.640015</td>\n",
              "      <td>105.250000</td>\n",
              "      <td>17.920000</td>\n",
              "      <td>409.070007</td>\n",
              "      <td>...</td>\n",
              "      <td>16.379999</td>\n",
              "      <td>413.420013</td>\n",
              "      <td>105.050003</td>\n",
              "      <td>16.830000</td>\n",
              "      <td>70439400</td>\n",
              "      <td>14195900</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998690</td>\n",
              "      <td>1.005907</td>\n",
              "      <td>0.991631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-15</th>\n",
              "      <td>411.481506</td>\n",
              "      <td>102.638535</td>\n",
              "      <td>17.120001</td>\n",
              "      <td>413.010010</td>\n",
              "      <td>103.190002</td>\n",
              "      <td>17.120001</td>\n",
              "      <td>413.429993</td>\n",
              "      <td>103.470001</td>\n",
              "      <td>18.160000</td>\n",
              "      <td>410.230011</td>\n",
              "      <td>...</td>\n",
              "      <td>17.080000</td>\n",
              "      <td>412.220001</td>\n",
              "      <td>103.389999</td>\n",
              "      <td>17.440001</td>\n",
              "      <td>54289400</td>\n",
              "      <td>20085300</td>\n",
              "      <td>0</td>\n",
              "      <td>1.003450</td>\n",
              "      <td>1.005285</td>\n",
              "      <td>0.989642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-16</th>\n",
              "      <td>408.731720</td>\n",
              "      <td>102.330185</td>\n",
              "      <td>17.990000</td>\n",
              "      <td>410.250000</td>\n",
              "      <td>102.879997</td>\n",
              "      <td>17.990000</td>\n",
              "      <td>412.820007</td>\n",
              "      <td>102.900002</td>\n",
              "      <td>18.299999</td>\n",
              "      <td>410.239990</td>\n",
              "      <td>...</td>\n",
              "      <td>17.260000</td>\n",
              "      <td>411.859985</td>\n",
              "      <td>102.400002</td>\n",
              "      <td>17.540001</td>\n",
              "      <td>57705500</td>\n",
              "      <td>29251700</td>\n",
              "      <td>0</td>\n",
              "      <td>0.993317</td>\n",
              "      <td>1.050818</td>\n",
              "      <td>0.996996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-17</th>\n",
              "      <td>413.693298</td>\n",
              "      <td>102.031792</td>\n",
              "      <td>16.870001</td>\n",
              "      <td>415.230011</td>\n",
              "      <td>102.580002</td>\n",
              "      <td>16.870001</td>\n",
              "      <td>415.859985</td>\n",
              "      <td>103.160004</td>\n",
              "      <td>18.260000</td>\n",
              "      <td>410.640015</td>\n",
              "      <td>...</td>\n",
              "      <td>16.680000</td>\n",
              "      <td>412.350006</td>\n",
              "      <td>103.080002</td>\n",
              "      <td>17.959999</td>\n",
              "      <td>87287000</td>\n",
              "      <td>21340900</td>\n",
              "      <td>0</td>\n",
              "      <td>1.012139</td>\n",
              "      <td>0.937743</td>\n",
              "      <td>0.997084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-18</th>\n",
              "      <td>417.678497</td>\n",
              "      <td>101.275856</td>\n",
              "      <td>16.049999</td>\n",
              "      <td>419.230011</td>\n",
              "      <td>101.820000</td>\n",
              "      <td>16.049999</td>\n",
              "      <td>419.670013</td>\n",
              "      <td>102.260002</td>\n",
              "      <td>17.150000</td>\n",
              "      <td>414.670013</td>\n",
              "      <td>...</td>\n",
              "      <td>16.049999</td>\n",
              "      <td>414.899994</td>\n",
              "      <td>102.199997</td>\n",
              "      <td>16.920000</td>\n",
              "      <td>97177200</td>\n",
              "      <td>25536600</td>\n",
              "      <td>0</td>\n",
              "      <td>1.009633</td>\n",
              "      <td>0.951393</td>\n",
              "      <td>0.992591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-19</th>\n",
              "      <td>417.070740</td>\n",
              "      <td>100.559700</td>\n",
              "      <td>16.809999</td>\n",
              "      <td>418.619995</td>\n",
              "      <td>101.099998</td>\n",
              "      <td>16.809999</td>\n",
              "      <td>420.720001</td>\n",
              "      <td>101.860001</td>\n",
              "      <td>17.360001</td>\n",
              "      <td>417.350006</td>\n",
              "      <td>...</td>\n",
              "      <td>15.850000</td>\n",
              "      <td>420.170013</td>\n",
              "      <td>101.260002</td>\n",
              "      <td>16.129999</td>\n",
              "      <td>103679700</td>\n",
              "      <td>29032300</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998545</td>\n",
              "      <td>1.047352</td>\n",
              "      <td>0.992929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-22</th>\n",
              "      <td>417.240143</td>\n",
              "      <td>100.201622</td>\n",
              "      <td>17.209999</td>\n",
              "      <td>418.790009</td>\n",
              "      <td>100.739998</td>\n",
              "      <td>17.209999</td>\n",
              "      <td>420.390015</td>\n",
              "      <td>101.709999</td>\n",
              "      <td>18.129999</td>\n",
              "      <td>417.350006</td>\n",
              "      <td>...</td>\n",
              "      <td>16.820000</td>\n",
              "      <td>418.640015</td>\n",
              "      <td>101.250000</td>\n",
              "      <td>17.450001</td>\n",
              "      <td>60745400</td>\n",
              "      <td>20131100</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000406</td>\n",
              "      <td>1.023795</td>\n",
              "      <td>0.996439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-23</th>\n",
              "      <td>412.557526</td>\n",
              "      <td>100.490074</td>\n",
              "      <td>18.530001</td>\n",
              "      <td>414.089996</td>\n",
              "      <td>101.029999</td>\n",
              "      <td>18.530001</td>\n",
              "      <td>418.720001</td>\n",
              "      <td>101.250000</td>\n",
              "      <td>19.309999</td>\n",
              "      <td>413.679993</td>\n",
              "      <td>...</td>\n",
              "      <td>17.299999</td>\n",
              "      <td>417.079987</td>\n",
              "      <td>100.430000</td>\n",
              "      <td>17.350000</td>\n",
              "      <td>86383500</td>\n",
              "      <td>21749500</td>\n",
              "      <td>0</td>\n",
              "      <td>0.988777</td>\n",
              "      <td>1.076700</td>\n",
              "      <td>1.002879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-24</th>\n",
              "      <td>409.568604</td>\n",
              "      <td>99.992744</td>\n",
              "      <td>20.030001</td>\n",
              "      <td>411.089996</td>\n",
              "      <td>100.529999</td>\n",
              "      <td>20.030001</td>\n",
              "      <td>412.820007</td>\n",
              "      <td>101.360001</td>\n",
              "      <td>20.809999</td>\n",
              "      <td>409.880005</td>\n",
              "      <td>...</td>\n",
              "      <td>18.799999</td>\n",
              "      <td>412.420013</td>\n",
              "      <td>101.279999</td>\n",
              "      <td>18.799999</td>\n",
              "      <td>89213700</td>\n",
              "      <td>18473400</td>\n",
              "      <td>0</td>\n",
              "      <td>0.992755</td>\n",
              "      <td>1.080950</td>\n",
              "      <td>0.995051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-25</th>\n",
              "      <td>413.115448</td>\n",
              "      <td>99.744080</td>\n",
              "      <td>19.139999</td>\n",
              "      <td>414.649994</td>\n",
              "      <td>100.279999</td>\n",
              "      <td>19.139999</td>\n",
              "      <td>416.160004</td>\n",
              "      <td>100.800003</td>\n",
              "      <td>19.950001</td>\n",
              "      <td>412.410004</td>\n",
              "      <td>...</td>\n",
              "      <td>18.700001</td>\n",
              "      <td>414.739990</td>\n",
              "      <td>100.699997</td>\n",
              "      <td>19.540001</td>\n",
              "      <td>90961600</td>\n",
              "      <td>22492800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.008660</td>\n",
              "      <td>0.955567</td>\n",
              "      <td>0.997513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-26</th>\n",
              "      <td>418.465546</td>\n",
              "      <td>100.549751</td>\n",
              "      <td>17.950001</td>\n",
              "      <td>420.019989</td>\n",
              "      <td>101.089996</td>\n",
              "      <td>17.950001</td>\n",
              "      <td>420.769989</td>\n",
              "      <td>101.169998</td>\n",
              "      <td>19.559999</td>\n",
              "      <td>415.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>17.270000</td>\n",
              "      <td>415.329987</td>\n",
              "      <td>100.120003</td>\n",
              "      <td>19.070000</td>\n",
              "      <td>93830000</td>\n",
              "      <td>17030300</td>\n",
              "      <td>0</td>\n",
              "      <td>1.012951</td>\n",
              "      <td>0.937827</td>\n",
              "      <td>1.008077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-30</th>\n",
              "      <td>418.624969</td>\n",
              "      <td>101.554359</td>\n",
              "      <td>17.459999</td>\n",
              "      <td>420.179993</td>\n",
              "      <td>102.099998</td>\n",
              "      <td>17.459999</td>\n",
              "      <td>422.579987</td>\n",
              "      <td>102.239998</td>\n",
              "      <td>18.340000</td>\n",
              "      <td>418.739990</td>\n",
              "      <td>...</td>\n",
              "      <td>16.980000</td>\n",
              "      <td>422.029999</td>\n",
              "      <td>101.400002</td>\n",
              "      <td>17.559999</td>\n",
              "      <td>72216000</td>\n",
              "      <td>23125200</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000381</td>\n",
              "      <td>0.972702</td>\n",
              "      <td>1.009991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>416.303619</td>\n",
              "      <td>102.439598</td>\n",
              "      <td>17.940001</td>\n",
              "      <td>417.850006</td>\n",
              "      <td>102.989998</td>\n",
              "      <td>17.940001</td>\n",
              "      <td>419.220001</td>\n",
              "      <td>103.180000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>416.220001</td>\n",
              "      <td>...</td>\n",
              "      <td>17.120001</td>\n",
              "      <td>418.279999</td>\n",
              "      <td>101.989998</td>\n",
              "      <td>18.040001</td>\n",
              "      <td>110811800</td>\n",
              "      <td>23787000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994455</td>\n",
              "      <td>1.027491</td>\n",
              "      <td>1.008717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-01</th>\n",
              "      <td>420.258911</td>\n",
              "      <td>102.841515</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>421.820007</td>\n",
              "      <td>103.120003</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>422.920013</td>\n",
              "      <td>103.629997</td>\n",
              "      <td>17.590000</td>\n",
              "      <td>416.790009</td>\n",
              "      <td>...</td>\n",
              "      <td>15.580000</td>\n",
              "      <td>418.089996</td>\n",
              "      <td>103.279999</td>\n",
              "      <td>17.240000</td>\n",
              "      <td>88865000</td>\n",
              "      <td>21040400</td>\n",
              "      <td>0</td>\n",
              "      <td>1.009501</td>\n",
              "      <td>0.872352</td>\n",
              "      <td>1.003923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-02</th>\n",
              "      <td>426.336334</td>\n",
              "      <td>101.714561</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>427.920013</td>\n",
              "      <td>101.989998</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>428.739990</td>\n",
              "      <td>103.070000</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>423.950012</td>\n",
              "      <td>...</td>\n",
              "      <td>14.420000</td>\n",
              "      <td>424.500000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>91366700</td>\n",
              "      <td>19122100</td>\n",
              "      <td>0</td>\n",
              "      <td>1.014461</td>\n",
              "      <td>0.932907</td>\n",
              "      <td>0.989042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-05</th>\n",
              "      <td>425.519379</td>\n",
              "      <td>101.525078</td>\n",
              "      <td>14.730000</td>\n",
              "      <td>427.100006</td>\n",
              "      <td>101.800003</td>\n",
              "      <td>14.730000</td>\n",
              "      <td>429.619995</td>\n",
              "      <td>102.440002</td>\n",
              "      <td>15.290000</td>\n",
              "      <td>426.369995</td>\n",
              "      <td>...</td>\n",
              "      <td>14.660000</td>\n",
              "      <td>428.279999</td>\n",
              "      <td>101.349998</td>\n",
              "      <td>15.280000</td>\n",
              "      <td>65460200</td>\n",
              "      <td>14433200</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998084</td>\n",
              "      <td>1.008904</td>\n",
              "      <td>0.998137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-06</th>\n",
              "      <td>426.445923</td>\n",
              "      <td>102.123459</td>\n",
              "      <td>13.960000</td>\n",
              "      <td>428.029999</td>\n",
              "      <td>102.400002</td>\n",
              "      <td>13.960000</td>\n",
              "      <td>428.579987</td>\n",
              "      <td>102.470001</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>425.989990</td>\n",
              "      <td>...</td>\n",
              "      <td>13.950000</td>\n",
              "      <td>426.670013</td>\n",
              "      <td>101.839996</td>\n",
              "      <td>14.910000</td>\n",
              "      <td>64022200</td>\n",
              "      <td>14332100</td>\n",
              "      <td>0</td>\n",
              "      <td>1.002177</td>\n",
              "      <td>0.947726</td>\n",
              "      <td>1.005894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-07</th>\n",
              "      <td>424.971375</td>\n",
              "      <td>100.607559</td>\n",
              "      <td>13.940000</td>\n",
              "      <td>426.549988</td>\n",
              "      <td>100.879997</td>\n",
              "      <td>13.940000</td>\n",
              "      <td>429.619995</td>\n",
              "      <td>102.430000</td>\n",
              "      <td>14.290000</td>\n",
              "      <td>426.109985</td>\n",
              "      <td>...</td>\n",
              "      <td>13.770000</td>\n",
              "      <td>428.440002</td>\n",
              "      <td>102.169998</td>\n",
              "      <td>14.140000</td>\n",
              "      <td>85373300</td>\n",
              "      <td>25251100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.996542</td>\n",
              "      <td>0.998567</td>\n",
              "      <td>0.985156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-08</th>\n",
              "      <td>427.541870</td>\n",
              "      <td>101.784370</td>\n",
              "      <td>13.650000</td>\n",
              "      <td>429.130005</td>\n",
              "      <td>102.059998</td>\n",
              "      <td>13.650000</td>\n",
              "      <td>429.600006</td>\n",
              "      <td>102.139999</td>\n",
              "      <td>14.210000</td>\n",
              "      <td>425.820007</td>\n",
              "      <td>...</td>\n",
              "      <td>13.530000</td>\n",
              "      <td>426.619995</td>\n",
              "      <td>100.870003</td>\n",
              "      <td>14.140000</td>\n",
              "      <td>61952800</td>\n",
              "      <td>23845100</td>\n",
              "      <td>0</td>\n",
              "      <td>1.006049</td>\n",
              "      <td>0.979197</td>\n",
              "      <td>1.011697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-09</th>\n",
              "      <td>428.308990</td>\n",
              "      <td>101.644753</td>\n",
              "      <td>13.830000</td>\n",
              "      <td>429.899994</td>\n",
              "      <td>101.919998</td>\n",
              "      <td>13.830000</td>\n",
              "      <td>431.989990</td>\n",
              "      <td>102.269997</td>\n",
              "      <td>14.140000</td>\n",
              "      <td>428.869995</td>\n",
              "      <td>...</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>429.959991</td>\n",
              "      <td>101.599998</td>\n",
              "      <td>13.780000</td>\n",
              "      <td>85742800</td>\n",
              "      <td>22147400</td>\n",
              "      <td>0</td>\n",
              "      <td>1.001794</td>\n",
              "      <td>1.013187</td>\n",
              "      <td>0.998628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-12</th>\n",
              "      <td>432.194550</td>\n",
              "      <td>101.943947</td>\n",
              "      <td>15.010000</td>\n",
              "      <td>433.799988</td>\n",
              "      <td>102.220001</td>\n",
              "      <td>15.010000</td>\n",
              "      <td>433.880005</td>\n",
              "      <td>102.300003</td>\n",
              "      <td>15.020000</td>\n",
              "      <td>430.170013</td>\n",
              "      <td>...</td>\n",
              "      <td>14.320000</td>\n",
              "      <td>430.920013</td>\n",
              "      <td>102.239998</td>\n",
              "      <td>14.440000</td>\n",
              "      <td>76104300</td>\n",
              "      <td>19010300</td>\n",
              "      <td>0</td>\n",
              "      <td>1.009072</td>\n",
              "      <td>1.085322</td>\n",
              "      <td>1.002944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-13</th>\n",
              "      <td>435.043976</td>\n",
              "      <td>100.936668</td>\n",
              "      <td>14.610000</td>\n",
              "      <td>436.660004</td>\n",
              "      <td>101.209999</td>\n",
              "      <td>14.610000</td>\n",
              "      <td>437.329987</td>\n",
              "      <td>102.330002</td>\n",
              "      <td>15.060000</td>\n",
              "      <td>434.630005</td>\n",
              "      <td>...</td>\n",
              "      <td>14.470000</td>\n",
              "      <td>435.320007</td>\n",
              "      <td>102.110001</td>\n",
              "      <td>14.990000</td>\n",
              "      <td>95899700</td>\n",
              "      <td>25910800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.006593</td>\n",
              "      <td>0.973351</td>\n",
              "      <td>0.990119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-14</th>\n",
              "      <td>435.562042</td>\n",
              "      <td>101.744476</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>437.179993</td>\n",
              "      <td>102.019997</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>439.059998</td>\n",
              "      <td>102.290001</td>\n",
              "      <td>14.730000</td>\n",
              "      <td>433.589996</td>\n",
              "      <td>...</td>\n",
              "      <td>13.830000</td>\n",
              "      <td>437.010010</td>\n",
              "      <td>101.629997</td>\n",
              "      <td>14.480000</td>\n",
              "      <td>100612100</td>\n",
              "      <td>29094200</td>\n",
              "      <td>0</td>\n",
              "      <td>1.001191</td>\n",
              "      <td>0.950034</td>\n",
              "      <td>1.008003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-15</th>\n",
              "      <td>440.962006</td>\n",
              "      <td>102.721832</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>442.600006</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>443.899994</td>\n",
              "      <td>103.629997</td>\n",
              "      <td>14.520000</td>\n",
              "      <td>436.230011</td>\n",
              "      <td>...</td>\n",
              "      <td>13.790000</td>\n",
              "      <td>436.329987</td>\n",
              "      <td>103.029999</td>\n",
              "      <td>14.090000</td>\n",
              "      <td>110303100</td>\n",
              "      <td>25732000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.012398</td>\n",
              "      <td>1.044669</td>\n",
              "      <td>1.009606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-16</th>\n",
              "      <td>439.459991</td>\n",
              "      <td>102.322914</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>439.459991</td>\n",
              "      <td>102.599998</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>443.609985</td>\n",
              "      <td>102.830002</td>\n",
              "      <td>14.540000</td>\n",
              "      <td>438.970001</td>\n",
              "      <td>...</td>\n",
              "      <td>13.480000</td>\n",
              "      <td>443.019989</td>\n",
              "      <td>102.440002</td>\n",
              "      <td>14.490000</td>\n",
              "      <td>114121300</td>\n",
              "      <td>16758200</td>\n",
              "      <td>0</td>\n",
              "      <td>0.996594</td>\n",
              "      <td>0.933793</td>\n",
              "      <td>0.996117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-20</th>\n",
              "      <td>437.179993</td>\n",
              "      <td>103.030998</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>437.179993</td>\n",
              "      <td>103.309998</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>438.369995</td>\n",
              "      <td>103.660004</td>\n",
              "      <td>14.670000</td>\n",
              "      <td>435.029999</td>\n",
              "      <td>...</td>\n",
              "      <td>13.860000</td>\n",
              "      <td>437.450012</td>\n",
              "      <td>103.110001</td>\n",
              "      <td>14.360000</td>\n",
              "      <td>76160400</td>\n",
              "      <td>17162900</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994812</td>\n",
              "      <td>1.025111</td>\n",
              "      <td>1.006920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-21</th>\n",
              "      <td>434.940002</td>\n",
              "      <td>103.280319</td>\n",
              "      <td>13.200000</td>\n",
              "      <td>434.940002</td>\n",
              "      <td>103.559998</td>\n",
              "      <td>13.200000</td>\n",
              "      <td>436.989990</td>\n",
              "      <td>103.650002</td>\n",
              "      <td>13.890000</td>\n",
              "      <td>434.329987</td>\n",
              "      <td>...</td>\n",
              "      <td>13.100000</td>\n",
              "      <td>436.160004</td>\n",
              "      <td>102.809998</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>76982300</td>\n",
              "      <td>19720100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.994876</td>\n",
              "      <td>0.951009</td>\n",
              "      <td>1.002420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-22</th>\n",
              "      <td>436.510010</td>\n",
              "      <td>102.033699</td>\n",
              "      <td>12.910000</td>\n",
              "      <td>436.510010</td>\n",
              "      <td>102.309998</td>\n",
              "      <td>12.910000</td>\n",
              "      <td>436.619995</td>\n",
              "      <td>103.250000</td>\n",
              "      <td>13.980000</td>\n",
              "      <td>433.600006</td>\n",
              "      <td>...</td>\n",
              "      <td>12.730000</td>\n",
              "      <td>433.950012</td>\n",
              "      <td>102.800003</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>70637200</td>\n",
              "      <td>23630700</td>\n",
              "      <td>0</td>\n",
              "      <td>1.003610</td>\n",
              "      <td>0.978030</td>\n",
              "      <td>0.987930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-23</th>\n",
              "      <td>433.209991</td>\n",
              "      <td>103.050949</td>\n",
              "      <td>13.440000</td>\n",
              "      <td>433.209991</td>\n",
              "      <td>103.330002</td>\n",
              "      <td>13.440000</td>\n",
              "      <td>435.059998</td>\n",
              "      <td>103.949997</td>\n",
              "      <td>13.800000</td>\n",
              "      <td>432.470001</td>\n",
              "      <td>...</td>\n",
              "      <td>12.880000</td>\n",
              "      <td>432.929993</td>\n",
              "      <td>103.830002</td>\n",
              "      <td>13.240000</td>\n",
              "      <td>92074500</td>\n",
              "      <td>22896800</td>\n",
              "      <td>0</td>\n",
              "      <td>0.992440</td>\n",
              "      <td>1.041053</td>\n",
              "      <td>1.009970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-26</th>\n",
              "      <td>431.440002</td>\n",
              "      <td>103.160652</td>\n",
              "      <td>14.250000</td>\n",
              "      <td>431.440002</td>\n",
              "      <td>103.440002</td>\n",
              "      <td>14.250000</td>\n",
              "      <td>434.609985</td>\n",
              "      <td>103.800003</td>\n",
              "      <td>14.710000</td>\n",
              "      <td>431.190002</td>\n",
              "      <td>...</td>\n",
              "      <td>13.780000</td>\n",
              "      <td>432.619995</td>\n",
              "      <td>103.620003</td>\n",
              "      <td>14.430000</td>\n",
              "      <td>72823600</td>\n",
              "      <td>12894900</td>\n",
              "      <td>0</td>\n",
              "      <td>0.995914</td>\n",
              "      <td>1.060268</td>\n",
              "      <td>1.001065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-27</th>\n",
              "      <td>436.170013</td>\n",
              "      <td>102.891373</td>\n",
              "      <td>13.740000</td>\n",
              "      <td>436.170013</td>\n",
              "      <td>103.169998</td>\n",
              "      <td>13.740000</td>\n",
              "      <td>436.809998</td>\n",
              "      <td>103.949997</td>\n",
              "      <td>14.340000</td>\n",
              "      <td>431.880005</td>\n",
              "      <td>...</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>432.350006</td>\n",
              "      <td>103.589996</td>\n",
              "      <td>14.110000</td>\n",
              "      <td>72813700</td>\n",
              "      <td>18105700</td>\n",
              "      <td>0</td>\n",
              "      <td>1.010963</td>\n",
              "      <td>0.964211</td>\n",
              "      <td>0.997390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-28</th>\n",
              "      <td>436.390015</td>\n",
              "      <td>103.330185</td>\n",
              "      <td>13.430000</td>\n",
              "      <td>436.390015</td>\n",
              "      <td>103.610001</td>\n",
              "      <td>13.430000</td>\n",
              "      <td>437.440002</td>\n",
              "      <td>103.839996</td>\n",
              "      <td>13.960000</td>\n",
              "      <td>434.410004</td>\n",
              "      <td>...</td>\n",
              "      <td>13.360000</td>\n",
              "      <td>435.049988</td>\n",
              "      <td>103.410004</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>75636000</td>\n",
              "      <td>23826800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000504</td>\n",
              "      <td>0.977438</td>\n",
              "      <td>1.004265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-29</th>\n",
              "      <td>438.109985</td>\n",
              "      <td>101.465233</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>438.109985</td>\n",
              "      <td>101.739998</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>438.279999</td>\n",
              "      <td>102.339996</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>435.540009</td>\n",
              "      <td>...</td>\n",
              "      <td>13.410000</td>\n",
              "      <td>435.959991</td>\n",
              "      <td>102.169998</td>\n",
              "      <td>13.640000</td>\n",
              "      <td>67882300</td>\n",
              "      <td>41091600</td>\n",
              "      <td>0</td>\n",
              "      <td>1.003941</td>\n",
              "      <td>1.008191</td>\n",
              "      <td>0.981952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>443.279999</td>\n",
              "      <td>102.662003</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>443.279999</td>\n",
              "      <td>102.940002</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>444.299988</td>\n",
              "      <td>103.059998</td>\n",
              "      <td>13.590000</td>\n",
              "      <td>441.109985</td>\n",
              "      <td>...</td>\n",
              "      <td>12.960000</td>\n",
              "      <td>441.440002</td>\n",
              "      <td>102.059998</td>\n",
              "      <td>13.510000</td>\n",
              "      <td>104921500</td>\n",
              "      <td>32018800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.011801</td>\n",
              "      <td>1.003693</td>\n",
              "      <td>1.011795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03</th>\n",
              "      <td>443.790009</td>\n",
              "      <td>102.080002</td>\n",
              "      <td>13.570000</td>\n",
              "      <td>443.790009</td>\n",
              "      <td>102.080002</td>\n",
              "      <td>13.570000</td>\n",
              "      <td>444.079987</td>\n",
              "      <td>103.260002</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>442.630005</td>\n",
              "      <td>...</td>\n",
              "      <td>13.470000</td>\n",
              "      <td>442.920013</td>\n",
              "      <td>102.839996</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>32793400</td>\n",
              "      <td>16011800</td>\n",
              "      <td>0</td>\n",
              "      <td>1.001151</td>\n",
              "      <td>0.998528</td>\n",
              "      <td>0.994331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>443.130005</td>\n",
              "      <td>101.110001</td>\n",
              "      <td>14.180000</td>\n",
              "      <td>443.130005</td>\n",
              "      <td>101.110001</td>\n",
              "      <td>14.180000</td>\n",
              "      <td>443.890015</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>14.740000</td>\n",
              "      <td>441.899994</td>\n",
              "      <td>...</td>\n",
              "      <td>14.050000</td>\n",
              "      <td>441.910004</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>14.190000</td>\n",
              "      <td>58418400</td>\n",
              "      <td>28170300</td>\n",
              "      <td>0</td>\n",
              "      <td>0.998513</td>\n",
              "      <td>1.044952</td>\n",
              "      <td>0.990498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.680000</td>\n",
              "      <td>15.440000</td>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.680000</td>\n",
              "      <td>15.440000</td>\n",
              "      <td>440.100006</td>\n",
              "      <td>100.379997</td>\n",
              "      <td>17.080000</td>\n",
              "      <td>437.059998</td>\n",
              "      <td>...</td>\n",
              "      <td>14.790000</td>\n",
              "      <td>439.420013</td>\n",
              "      <td>100.199997</td>\n",
              "      <td>14.850000</td>\n",
              "      <td>80658300</td>\n",
              "      <td>41375700</td>\n",
              "      <td>0</td>\n",
              "      <td>0.992169</td>\n",
              "      <td>1.088857</td>\n",
              "      <td>0.985857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>438.549988</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>14.830000</td>\n",
              "      <td>438.549988</td>\n",
              "      <td>99.080002</td>\n",
              "      <td>14.830000</td>\n",
              "      <td>442.640015</td>\n",
              "      <td>99.599998</td>\n",
              "      <td>16.059999</td>\n",
              "      <td>438.299988</td>\n",
              "      <td>...</td>\n",
              "      <td>14.330000</td>\n",
              "      <td>438.630005</td>\n",
              "      <td>99.180000</td>\n",
              "      <td>15.970000</td>\n",
              "      <td>86076100</td>\n",
              "      <td>28979600</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997475</td>\n",
              "      <td>0.960492</td>\n",
              "      <td>0.993981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-10</th>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.209999</td>\n",
              "      <td>15.070000</td>\n",
              "      <td>439.660004</td>\n",
              "      <td>99.209999</td>\n",
              "      <td>15.070000</td>\n",
              "      <td>439.839996</td>\n",
              "      <td>99.529999</td>\n",
              "      <td>16.209999</td>\n",
              "      <td>437.589996</td>\n",
              "      <td>...</td>\n",
              "      <td>15.040000</td>\n",
              "      <td>438.179993</td>\n",
              "      <td>98.860001</td>\n",
              "      <td>16.080000</td>\n",
              "      <td>62443500</td>\n",
              "      <td>24665200</td>\n",
              "      <td>0</td>\n",
              "      <td>1.002531</td>\n",
              "      <td>1.016183</td>\n",
              "      <td>1.001312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-11</th>\n",
              "      <td>442.459991</td>\n",
              "      <td>99.720001</td>\n",
              "      <td>14.840000</td>\n",
              "      <td>442.459991</td>\n",
              "      <td>99.720001</td>\n",
              "      <td>14.840000</td>\n",
              "      <td>442.970001</td>\n",
              "      <td>99.970001</td>\n",
              "      <td>15.250000</td>\n",
              "      <td>439.440002</td>\n",
              "      <td>...</td>\n",
              "      <td>14.630000</td>\n",
              "      <td>440.450012</td>\n",
              "      <td>99.570000</td>\n",
              "      <td>15.020000</td>\n",
              "      <td>64463800</td>\n",
              "      <td>20491100</td>\n",
              "      <td>0</td>\n",
              "      <td>1.006369</td>\n",
              "      <td>0.984738</td>\n",
              "      <td>1.005141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-12</th>\n",
              "      <td>446.019989</td>\n",
              "      <td>100.830002</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>446.019989</td>\n",
              "      <td>100.830002</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>447.480011</td>\n",
              "      <td>101.120003</td>\n",
              "      <td>14.820000</td>\n",
              "      <td>444.910004</td>\n",
              "      <td>...</td>\n",
              "      <td>13.510000</td>\n",
              "      <td>446.390015</td>\n",
              "      <td>100.099998</td>\n",
              "      <td>14.820000</td>\n",
              "      <td>91924500</td>\n",
              "      <td>31928000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.008046</td>\n",
              "      <td>0.912399</td>\n",
              "      <td>1.011131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-13</th>\n",
              "      <td>449.559998</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>13.610000</td>\n",
              "      <td>449.559998</td>\n",
              "      <td>101.889999</td>\n",
              "      <td>13.610000</td>\n",
              "      <td>450.380005</td>\n",
              "      <td>101.970001</td>\n",
              "      <td>13.610000</td>\n",
              "      <td>447.450012</td>\n",
              "      <td>...</td>\n",
              "      <td>13.120000</td>\n",
              "      <td>447.899994</td>\n",
              "      <td>101.309998</td>\n",
              "      <td>13.440000</td>\n",
              "      <td>72425200</td>\n",
              "      <td>32441500</td>\n",
              "      <td>0</td>\n",
              "      <td>1.007937</td>\n",
              "      <td>1.005170</td>\n",
              "      <td>1.010513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-14</th>\n",
              "      <td>449.279999</td>\n",
              "      <td>101.290001</td>\n",
              "      <td>13.340000</td>\n",
              "      <td>449.279999</td>\n",
              "      <td>101.290001</td>\n",
              "      <td>13.340000</td>\n",
              "      <td>451.359985</td>\n",
              "      <td>101.940002</td>\n",
              "      <td>13.760000</td>\n",
              "      <td>448.489990</td>\n",
              "      <td>...</td>\n",
              "      <td>13.220000</td>\n",
              "      <td>450.480011</td>\n",
              "      <td>101.720001</td>\n",
              "      <td>13.720000</td>\n",
              "      <td>69761800</td>\n",
              "      <td>18566200</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999377</td>\n",
              "      <td>0.980162</td>\n",
              "      <td>0.994111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close                              Close              \\\n",
              "                   SPY         TLT       ^VIX         SPY         TLT   \n",
              "Date                                                                    \n",
              "2023-05-05  411.102936  104.329445  17.190001  412.630005  104.889999   \n",
              "2023-05-08  411.212494  102.867302  16.980000  412.739990  103.419998   \n",
              "2023-05-09  409.409210  102.499283  17.709999  410.929993  103.050003   \n",
              "2023-05-10  411.322113  103.493935  16.940001  412.850006  104.050003   \n",
              "2023-05-11  410.604767  104.588058  16.930000  412.130005  105.150002   \n",
              "2023-05-12  410.066772  103.712761  17.030001  411.589996  104.269997   \n",
              "2023-05-15  411.481506  102.638535  17.120001  413.010010  103.190002   \n",
              "2023-05-16  408.731720  102.330185  17.990000  410.250000  102.879997   \n",
              "2023-05-17  413.693298  102.031792  16.870001  415.230011  102.580002   \n",
              "2023-05-18  417.678497  101.275856  16.049999  419.230011  101.820000   \n",
              "2023-05-19  417.070740  100.559700  16.809999  418.619995  101.099998   \n",
              "2023-05-22  417.240143  100.201622  17.209999  418.790009  100.739998   \n",
              "2023-05-23  412.557526  100.490074  18.530001  414.089996  101.029999   \n",
              "2023-05-24  409.568604   99.992744  20.030001  411.089996  100.529999   \n",
              "2023-05-25  413.115448   99.744080  19.139999  414.649994  100.279999   \n",
              "2023-05-26  418.465546  100.549751  17.950001  420.019989  101.089996   \n",
              "2023-05-30  418.624969  101.554359  17.459999  420.179993  102.099998   \n",
              "2023-05-31  416.303619  102.439598  17.940001  417.850006  102.989998   \n",
              "2023-06-01  420.258911  102.841515  15.650000  421.820007  103.120003   \n",
              "2023-06-02  426.336334  101.714561  14.600000  427.920013  101.989998   \n",
              "2023-06-05  425.519379  101.525078  14.730000  427.100006  101.800003   \n",
              "2023-06-06  426.445923  102.123459  13.960000  428.029999  102.400002   \n",
              "2023-06-07  424.971375  100.607559  13.940000  426.549988  100.879997   \n",
              "2023-06-08  427.541870  101.784370  13.650000  429.130005  102.059998   \n",
              "2023-06-09  428.308990  101.644753  13.830000  429.899994  101.919998   \n",
              "2023-06-12  432.194550  101.943947  15.010000  433.799988  102.220001   \n",
              "2023-06-13  435.043976  100.936668  14.610000  436.660004  101.209999   \n",
              "2023-06-14  435.562042  101.744476  13.880000  437.179993  102.019997   \n",
              "2023-06-15  440.962006  102.721832  14.500000  442.600006  103.000000   \n",
              "2023-06-16  439.459991  102.322914  13.540000  439.459991  102.599998   \n",
              "2023-06-20  437.179993  103.030998  13.880000  437.179993  103.309998   \n",
              "2023-06-21  434.940002  103.280319  13.200000  434.940002  103.559998   \n",
              "2023-06-22  436.510010  102.033699  12.910000  436.510010  102.309998   \n",
              "2023-06-23  433.209991  103.050949  13.440000  433.209991  103.330002   \n",
              "2023-06-26  431.440002  103.160652  14.250000  431.440002  103.440002   \n",
              "2023-06-27  436.170013  102.891373  13.740000  436.170013  103.169998   \n",
              "2023-06-28  436.390015  103.330185  13.430000  436.390015  103.610001   \n",
              "2023-06-29  438.109985  101.465233  13.540000  438.109985  101.739998   \n",
              "2023-06-30  443.279999  102.662003  13.590000  443.279999  102.940002   \n",
              "2023-07-03  443.790009  102.080002  13.570000  443.790009  102.080002   \n",
              "2023-07-05  443.130005  101.110001  14.180000  443.130005  101.110001   \n",
              "2023-07-06  439.660004   99.680000  15.440000  439.660004   99.680000   \n",
              "2023-07-07  438.549988   99.080002  14.830000  438.549988   99.080002   \n",
              "2023-07-10  439.660004   99.209999  15.070000  439.660004   99.209999   \n",
              "2023-07-11  442.459991   99.720001  14.840000  442.459991   99.720001   \n",
              "2023-07-12  446.019989  100.830002  13.540000  446.019989  100.830002   \n",
              "2023-07-13  449.559998  101.889999  13.610000  449.559998  101.889999   \n",
              "2023-07-14  449.279999  101.290001  13.340000  449.279999  101.290001   \n",
              "\n",
              "                             High                                Low  ...  \\\n",
              "                 ^VIX         SPY         TLT       ^VIX         SPY  ...   \n",
              "Date                                                                  ...   \n",
              "2023-05-05  17.190001  413.720001  104.900002  19.629999  408.640015  ...   \n",
              "2023-05-08  16.980000  413.239990  103.870003  17.879999  411.279999  ...   \n",
              "2023-05-09  17.709999  412.089996  103.639999  17.860001  410.690002  ...   \n",
              "2023-05-10  16.940001  414.540009  104.239998  18.309999  408.869995  ...   \n",
              "2023-05-11  16.930000  412.429993  105.519997  18.190001  409.970001  ...   \n",
              "2023-05-12  17.030001  413.640015  105.250000  17.920000  409.070007  ...   \n",
              "2023-05-15  17.120001  413.429993  103.470001  18.160000  410.230011  ...   \n",
              "2023-05-16  17.990000  412.820007  102.900002  18.299999  410.239990  ...   \n",
              "2023-05-17  16.870001  415.859985  103.160004  18.260000  410.640015  ...   \n",
              "2023-05-18  16.049999  419.670013  102.260002  17.150000  414.670013  ...   \n",
              "2023-05-19  16.809999  420.720001  101.860001  17.360001  417.350006  ...   \n",
              "2023-05-22  17.209999  420.390015  101.709999  18.129999  417.350006  ...   \n",
              "2023-05-23  18.530001  418.720001  101.250000  19.309999  413.679993  ...   \n",
              "2023-05-24  20.030001  412.820007  101.360001  20.809999  409.880005  ...   \n",
              "2023-05-25  19.139999  416.160004  100.800003  19.950001  412.410004  ...   \n",
              "2023-05-26  17.950001  420.769989  101.169998  19.559999  415.250000  ...   \n",
              "2023-05-30  17.459999  422.579987  102.239998  18.340000  418.739990  ...   \n",
              "2023-05-31  17.940001  419.220001  103.180000  18.400000  416.220001  ...   \n",
              "2023-06-01  15.650000  422.920013  103.629997  17.590000  416.790009  ...   \n",
              "2023-06-02  14.600000  428.739990  103.070000  15.650000  423.950012  ...   \n",
              "2023-06-05  14.730000  429.619995  102.440002  15.290000  426.369995  ...   \n",
              "2023-06-06  13.960000  428.579987  102.470001  14.970000  425.989990  ...   \n",
              "2023-06-07  13.940000  429.619995  102.430000  14.290000  426.109985  ...   \n",
              "2023-06-08  13.650000  429.600006  102.139999  14.210000  425.820007  ...   \n",
              "2023-06-09  13.830000  431.989990  102.269997  14.140000  428.869995  ...   \n",
              "2023-06-12  15.010000  433.880005  102.300003  15.020000  430.170013  ...   \n",
              "2023-06-13  14.610000  437.329987  102.330002  15.060000  434.630005  ...   \n",
              "2023-06-14  13.880000  439.059998  102.290001  14.730000  433.589996  ...   \n",
              "2023-06-15  14.500000  443.899994  103.629997  14.520000  436.230011  ...   \n",
              "2023-06-16  13.540000  443.609985  102.830002  14.540000  438.970001  ...   \n",
              "2023-06-20  13.880000  438.369995  103.660004  14.670000  435.029999  ...   \n",
              "2023-06-21  13.200000  436.989990  103.650002  13.890000  434.329987  ...   \n",
              "2023-06-22  12.910000  436.619995  103.250000  13.980000  433.600006  ...   \n",
              "2023-06-23  13.440000  435.059998  103.949997  13.800000  432.470001  ...   \n",
              "2023-06-26  14.250000  434.609985  103.800003  14.710000  431.190002  ...   \n",
              "2023-06-27  13.740000  436.809998  103.949997  14.340000  431.880005  ...   \n",
              "2023-06-28  13.430000  437.440002  103.839996  13.960000  434.410004  ...   \n",
              "2023-06-29  13.540000  438.279999  102.339996  13.850000  435.540009  ...   \n",
              "2023-06-30  13.590000  444.299988  103.059998  13.590000  441.109985  ...   \n",
              "2023-07-03  13.570000  444.079987  103.260002  13.850000  442.630005  ...   \n",
              "2023-07-05  14.180000  443.890015  102.000000  14.740000  441.899994  ...   \n",
              "2023-07-06  15.440000  440.100006  100.379997  17.080000  437.059998  ...   \n",
              "2023-07-07  14.830000  442.640015   99.599998  16.059999  438.299988  ...   \n",
              "2023-07-10  15.070000  439.839996   99.529999  16.209999  437.589996  ...   \n",
              "2023-07-11  14.840000  442.970001   99.970001  15.250000  439.440002  ...   \n",
              "2023-07-12  13.540000  447.480011  101.120003  14.820000  444.910004  ...   \n",
              "2023-07-13  13.610000  450.380005  101.970001  13.610000  447.450012  ...   \n",
              "2023-07-14  13.340000  451.359985  101.940002  13.760000  448.489990  ...   \n",
              "\n",
              "                             Open                            Volume            \\\n",
              "                 ^VIX         SPY         TLT       ^VIX        SPY       TLT   \n",
              "Date                                                                            \n",
              "2023-05-05  16.690001  408.910004  104.349998  19.500000   87844000  15090900   \n",
              "2023-05-08  16.830000  412.970001  103.519997  17.730000   50046800  20587000   \n",
              "2023-05-09  17.219999  411.130005  103.500000  17.290001   49220100  19182500   \n",
              "2023-05-10  16.360001  413.880005  103.669998  17.580000   96142900  22886800   \n",
              "2023-05-11  16.629999  411.950012  105.300003  16.799999   70157100  19147200   \n",
              "2023-05-12  16.379999  413.420013  105.050003  16.830000   70439400  14195900   \n",
              "2023-05-15  17.080000  412.220001  103.389999  17.440001   54289400  20085300   \n",
              "2023-05-16  17.260000  411.859985  102.400002  17.540001   57705500  29251700   \n",
              "2023-05-17  16.680000  412.350006  103.080002  17.959999   87287000  21340900   \n",
              "2023-05-18  16.049999  414.899994  102.199997  16.920000   97177200  25536600   \n",
              "2023-05-19  15.850000  420.170013  101.260002  16.129999  103679700  29032300   \n",
              "2023-05-22  16.820000  418.640015  101.250000  17.450001   60745400  20131100   \n",
              "2023-05-23  17.299999  417.079987  100.430000  17.350000   86383500  21749500   \n",
              "2023-05-24  18.799999  412.420013  101.279999  18.799999   89213700  18473400   \n",
              "2023-05-25  18.700001  414.739990  100.699997  19.540001   90961600  22492800   \n",
              "2023-05-26  17.270000  415.329987  100.120003  19.070000   93830000  17030300   \n",
              "2023-05-30  16.980000  422.029999  101.400002  17.559999   72216000  23125200   \n",
              "2023-05-31  17.120001  418.279999  101.989998  18.040001  110811800  23787000   \n",
              "2023-06-01  15.580000  418.089996  103.279999  17.240000   88865000  21040400   \n",
              "2023-06-02  14.420000  424.500000  103.000000  15.650000   91366700  19122100   \n",
              "2023-06-05  14.660000  428.279999  101.349998  15.280000   65460200  14433200   \n",
              "2023-06-06  13.950000  426.670013  101.839996  14.910000   64022200  14332100   \n",
              "2023-06-07  13.770000  428.440002  102.169998  14.140000   85373300  25251100   \n",
              "2023-06-08  13.530000  426.619995  100.870003  14.140000   61952800  23845100   \n",
              "2023-06-09  13.500000  429.959991  101.599998  13.780000   85742800  22147400   \n",
              "2023-06-12  14.320000  430.920013  102.239998  14.440000   76104300  19010300   \n",
              "2023-06-13  14.470000  435.320007  102.110001  14.990000   95899700  25910800   \n",
              "2023-06-14  13.830000  437.010010  101.629997  14.480000  100612100  29094200   \n",
              "2023-06-15  13.790000  436.329987  103.029999  14.090000  110303100  25732000   \n",
              "2023-06-16  13.480000  443.019989  102.440002  14.490000  114121300  16758200   \n",
              "2023-06-20  13.860000  437.450012  103.110001  14.360000   76160400  17162900   \n",
              "2023-06-21  13.100000  436.160004  102.809998  13.880000   76982300  19720100   \n",
              "2023-06-22  12.730000  433.950012  102.800003  13.880000   70637200  23630700   \n",
              "2023-06-23  12.880000  432.929993  103.830002  13.240000   92074500  22896800   \n",
              "2023-06-26  13.780000  432.619995  103.620003  14.430000   72823600  12894900   \n",
              "2023-06-27  13.590000  432.350006  103.589996  14.110000   72813700  18105700   \n",
              "2023-06-28  13.360000  435.049988  103.410004  13.900000   75636000  23826800   \n",
              "2023-06-29  13.410000  435.959991  102.169998  13.640000   67882300  41091600   \n",
              "2023-06-30  12.960000  441.440002  102.059998  13.510000  104921500  32018800   \n",
              "2023-07-03  13.470000  442.920013  102.839996  13.850000   32793400  16011800   \n",
              "2023-07-05  14.050000  441.910004  101.889999  14.190000   58418400  28170300   \n",
              "2023-07-06  14.790000  439.420013  100.199997  14.850000   80658300  41375700   \n",
              "2023-07-07  14.330000  438.630005   99.180000  15.970000   86076100  28979600   \n",
              "2023-07-10  15.040000  438.179993   98.860001  16.080000   62443500  24665200   \n",
              "2023-07-11  14.630000  440.450012   99.570000  15.020000   64463800  20491100   \n",
              "2023-07-12  13.510000  446.390015  100.099998  14.820000   91924500  31928000   \n",
              "2023-07-13  13.120000  447.899994  101.309998  13.440000   72425200  32441500   \n",
              "2023-07-14  13.220000  450.480011  101.720001  13.720000   69761800  18566200   \n",
              "\n",
              "                      Ret                      \n",
              "           ^VIX       SPY      ^VIX       TLT  \n",
              "Date                                           \n",
              "2023-05-05    0  1.018513  0.855650  0.996674  \n",
              "2023-05-08    0  1.000266  0.987784  0.985985  \n",
              "2023-05-09    0  0.995615  1.042992  0.996422  \n",
              "2023-05-10    0  1.004672  0.956522  1.009704  \n",
              "2023-05-11    0  0.998256  0.999410  1.010572  \n",
              "2023-05-12    0  0.998690  1.005907  0.991631  \n",
              "2023-05-15    0  1.003450  1.005285  0.989642  \n",
              "2023-05-16    0  0.993317  1.050818  0.996996  \n",
              "2023-05-17    0  1.012139  0.937743  0.997084  \n",
              "2023-05-18    0  1.009633  0.951393  0.992591  \n",
              "2023-05-19    0  0.998545  1.047352  0.992929  \n",
              "2023-05-22    0  1.000406  1.023795  0.996439  \n",
              "2023-05-23    0  0.988777  1.076700  1.002879  \n",
              "2023-05-24    0  0.992755  1.080950  0.995051  \n",
              "2023-05-25    0  1.008660  0.955567  0.997513  \n",
              "2023-05-26    0  1.012951  0.937827  1.008077  \n",
              "2023-05-30    0  1.000381  0.972702  1.009991  \n",
              "2023-05-31    0  0.994455  1.027491  1.008717  \n",
              "2023-06-01    0  1.009501  0.872352  1.003923  \n",
              "2023-06-02    0  1.014461  0.932907  0.989042  \n",
              "2023-06-05    0  0.998084  1.008904  0.998137  \n",
              "2023-06-06    0  1.002177  0.947726  1.005894  \n",
              "2023-06-07    0  0.996542  0.998567  0.985156  \n",
              "2023-06-08    0  1.006049  0.979197  1.011697  \n",
              "2023-06-09    0  1.001794  1.013187  0.998628  \n",
              "2023-06-12    0  1.009072  1.085322  1.002944  \n",
              "2023-06-13    0  1.006593  0.973351  0.990119  \n",
              "2023-06-14    0  1.001191  0.950034  1.008003  \n",
              "2023-06-15    0  1.012398  1.044669  1.009606  \n",
              "2023-06-16    0  0.996594  0.933793  0.996117  \n",
              "2023-06-20    0  0.994812  1.025111  1.006920  \n",
              "2023-06-21    0  0.994876  0.951009  1.002420  \n",
              "2023-06-22    0  1.003610  0.978030  0.987930  \n",
              "2023-06-23    0  0.992440  1.041053  1.009970  \n",
              "2023-06-26    0  0.995914  1.060268  1.001065  \n",
              "2023-06-27    0  1.010963  0.964211  0.997390  \n",
              "2023-06-28    0  1.000504  0.977438  1.004265  \n",
              "2023-06-29    0  1.003941  1.008191  0.981952  \n",
              "2023-06-30    0  1.011801  1.003693  1.011795  \n",
              "2023-07-03    0  1.001151  0.998528  0.994331  \n",
              "2023-07-05    0  0.998513  1.044952  0.990498  \n",
              "2023-07-06    0  0.992169  1.088857  0.985857  \n",
              "2023-07-07    0  0.997475  0.960492  0.993981  \n",
              "2023-07-10    0  1.002531  1.016183  1.001312  \n",
              "2023-07-11    0  1.006369  0.984738  1.005141  \n",
              "2023-07-12    0  1.008046  0.912399  1.011131  \n",
              "2023-07-13    0  1.007937  1.005170  1.010513  \n",
              "2023-07-14    0  0.999377  0.980162  0.994111  \n",
              "\n",
              "[48 rows x 21 columns]"
            ]
          },
          "execution_count": 549,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test\n",
        "data.loc[d + pd.offsets.BDay(-(50)) : d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlnvkTlQnKLK"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "start = datetime(2019, 1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdKo5ISJnKLK"
      },
      "outputs": [],
      "source": [
        "def prepTrainigSetAtDate(\n",
        "    t0, # date where we fit and make predictions\n",
        "    data,\n",
        "    s0 = 'SPY',\n",
        "    assets = ('SPY', '^VIX'),\n",
        "    features = ('Ret',),\n",
        "    hrzn = 5,\n",
        "    lookback = 50,\n",
        "    batch_size = 100\n",
        "):\n",
        "    d = pd.Timestamp(t0)\n",
        "    # this is for training\n",
        "    df = data.loc[d + pd.offsets.BDay(-(lookback + batch_size + hrzn)) : d + pd.offsets.BDay(-hrzn)].copy()\n",
        "    df[('hh', s0)] = np.log(df[('Adj Close', s0)].rolling(hrzn).max().shift(-hrzn)/df[('Adj Close', s0)])\n",
        "    df[('ll', s0)] = np.log(df[('Adj Close', s0)].rolling(hrzn).min().shift(-hrzn)/df[('Adj Close', s0)])\n",
        "    clmns_ftr = [(j, i) for i in assets for j in features]\n",
        "    clmns_trg = [('hh', s0), ('ll', s0)]\n",
        "    clmns = clmns_ftr + clmns_trg\n",
        "    df = df.loc[:, clmns].dropna()\n",
        "    l_obs = []\n",
        "    l_trg = []\n",
        "    for i in range(len(df) - lookback + 1):\n",
        "        obs = df.iloc[i : i + lookback][clmns_ftr]\n",
        "        trg = df.iloc[i + lookback - 1][clmns_trg]\n",
        "        l_obs.append(jnp.array(obs))\n",
        "        l_trg.append(jnp.array(trg))\n",
        "    # test\n",
        "    df = data.loc[d + pd.offsets.BDay(-lookback - 5) : d, clmns_ftr].copy()\n",
        "    test_x = df.tail(lookback).loc[:, clmns_ftr]\n",
        "    return (jnp.array(l_obs), jnp.array(l_trg)), jnp.array(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEtC2o0onKLK"
      },
      "outputs": [],
      "source": [
        "dset_trainTS, test_x = prepTrainigSetAtDate('2023-07-14', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8acbcUKBnKLK",
        "outputId": "c9273eee-c92d-42f3-eb6d-d4828b51521f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((89, 50, 2), (89, 2))"
            ]
          },
          "execution_count": 688,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(dset_trainTS[0].shape, dset_trainTS[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRsLsafPnKLK",
        "outputId": "eaecc553-5612-4186-fde5-e3534886277c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 2)"
            ]
          },
          "execution_count": 559,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhF6LOernKLK",
        "outputId": "e2cbd628-76e3-41b7-a463-d9660e8d26d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[0.993136  , 1.031496  ],\n",
              "       [0.992917  , 1.0954199 ],\n",
              "       [1.0185126 , 0.8556496 ],\n",
              "       [1.0002666 , 0.98778355],\n",
              "       [0.9956147 , 1.0429918 ],\n",
              "       [1.0046724 , 0.9565218 ],\n",
              "       [0.998256  , 0.9994097 ],\n",
              "       [0.9986898 , 1.0059067 ],\n",
              "       [1.00345   , 1.0052848 ],\n",
              "       [0.99331737, 1.0508177 ],\n",
              "       [1.012139  , 0.93774325],\n",
              "       [1.0096332 , 0.9513929 ],\n",
              "       [0.99854493, 1.0473521 ],\n",
              "       [1.0004061 , 1.0237954 ],\n",
              "       [0.98877716, 1.0766997 ],\n",
              "       [0.9927551 , 1.0809498 ],\n",
              "       [1.00866   , 0.9555666 ],\n",
              "       [1.0129507 , 0.93782663],\n",
              "       [1.000381  , 0.97270185],\n",
              "       [0.9944548 , 1.0274915 ],\n",
              "       [1.009501  , 0.87235224],\n",
              "       [1.0144612 , 0.9329074 ],\n",
              "       [0.9980838 , 1.0089041 ],\n",
              "       [1.0021775 , 0.9477258 ],\n",
              "       [0.9965422 , 0.9985673 ],\n",
              "       [1.0060487 , 0.97919655],\n",
              "       [1.0017942 , 1.0131868 ],\n",
              "       [1.0090718 , 1.0853218 ],\n",
              "       [1.0065929 , 0.97335106],\n",
              "       [1.0011908 , 0.95003426],\n",
              "       [1.0123976 , 1.0446686 ],\n",
              "       [0.9965938 , 0.9337931 ],\n",
              "       [0.99481183, 1.0251108 ],\n",
              "       [0.99487627, 0.9510086 ],\n",
              "       [1.0036097 , 0.9780303 ],\n",
              "       [0.99244   , 1.0410534 ],\n",
              "       [0.9959142 , 1.0602679 ],\n",
              "       [1.0109633 , 0.9642105 ],\n",
              "       [1.0005044 , 0.97743815],\n",
              "       [1.0039414 , 1.0081906 ],\n",
              "       [1.0118008 , 1.0036927 ],\n",
              "       [1.0011505 , 0.9985283 ],\n",
              "       [0.9985128 , 1.0449522 ],\n",
              "       [0.9921693 , 1.0888575 ],\n",
              "       [0.99747527, 0.96049225],\n",
              "       [1.002531  , 1.0161834 ],\n",
              "       [1.0063685 , 0.98473793],\n",
              "       [1.0080459 , 0.91239893],\n",
              "       [1.0079368 , 1.0051699 ],\n",
              "       [0.9993772 , 0.98016167]], dtype=float32)"
            ]
          },
          "execution_count": 560,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GluT4VVynKLK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPDz9LcLnKLK"
      },
      "source": [
        "#### Prepare data frame with X and y and use a generic dataloader to iterate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esB5z7NynKLK"
      },
      "outputs": [],
      "source": [
        "# predict hh & ll in the next N days\n",
        "# predict hh - ll\n",
        "# predict TS for the next N periods\n",
        "def prepDataHHLLPred(df,\n",
        "                     s0 = 'SPY',\n",
        "                     assets = ('SPY', '^VIX'),\n",
        "                     features = ('Close',),\n",
        "                     hrzn = 5):\n",
        "    df[('hh', s0)] = df[('Close', s0)].rolling(hrzn).max().shift(-hrzn)\n",
        "    df[('ll', s0)] = df[('Close', s0)].rolling(hrzn).min().shift(-hrzn)\n",
        "    clmns = [(j, i) for i in assets for j in features]\n",
        "    clmns += [('hh', s0), ('ll', s0)]\n",
        "#     print(clmns)\n",
        "    return df.loc[:, clmns].dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLcOOaSOnKLK"
      },
      "outputs": [],
      "source": [
        "def prepDataSetHHLLPred(df,\n",
        "                     s0 = 'SPY',\n",
        "                     assets = ('SPY', '^VIX'),\n",
        "                     features = ('Close',),\n",
        "                     hrzn = 5,\n",
        "                     lookback = 50,\n",
        "                     ):\n",
        "    df[('hh', s0)] = df[('Close', s0)].rolling(hrzn).max().shift(-hrzn)\n",
        "    df[('ll', s0)] = df[('Close', s0)].rolling(hrzn).min().shift(-hrzn)\n",
        "    clmns_ftr = [(j, i) for i in assets for j in features]\n",
        "    clmns_trg = [('hh', s0), ('ll', s0)]\n",
        "    clmns = clmns_ftr + clmns_trg\n",
        "    df = df.loc[:, clmns].dropna()\n",
        "    l_obs = []\n",
        "    l_trg = []\n",
        "    for i in range(len(df) - lookback + 1):\n",
        "        obs = df.iloc[i : i + lookback][clmns_ftr]\n",
        "        trg = df.iloc[i + lookback - 1][clmns_trg]\n",
        "        l_obs.append(jnp.ravel(jnp.array(obs), order='F'))\n",
        "        l_trg.append(jnp.array(trg))\n",
        "    return [jnp.array(l_obs), jnp.array(l_trg)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVcJHWCfnKLK"
      },
      "outputs": [],
      "source": [
        "def prepDataSetHHLLPred111(df,\n",
        "                     s0 = 'SPY',\n",
        "                     assets = ('SPY', '^VIX'),\n",
        "                     features = ('Ret',),\n",
        "                     hrzn = 5,\n",
        "                     lookback = 50):\n",
        "    df[('hh', s0)] = df[('Adj Close', s0)].rolling(hrzn).max().shift(-hrzn)/df[('Adj Close', s0)]\n",
        "    df[('ll', s0)] = df[('Adj Close', s0)].rolling(hrzn).min().shift(-hrzn)/df[('Adj Close', s0)]\n",
        "    clmns_ftr = [(j, i) for i in assets for j in features]\n",
        "    clmns_trg = [('hh', s0), ('ll', s0)]\n",
        "    clmns = clmns_ftr + clmns_trg\n",
        "    df = df.loc[:, clmns].dropna()\n",
        "    l_obs = []\n",
        "    l_trg = []\n",
        "    for i in range(len(df) - lookback + 1):\n",
        "        obs = df.iloc[i : i + lookback][clmns_ftr]\n",
        "        trg = df.iloc[i + lookback - 1][clmns_trg]\n",
        "        l_obs.append(jnp.array(obs))\n",
        "        l_trg.append(jnp.array(trg))\n",
        "    return (jnp.array(l_obs), jnp.array(l_trg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ_9BWYcnKLK"
      },
      "outputs": [],
      "source": [
        "datasetHL111 = prepDataSetHHLLPred111(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTe5hgTZnKLL",
        "outputId": "babb3af1-edd3-4c07-dcdf-01ce70b1a1ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1336, 50, 2), (1336, 2))"
            ]
          },
          "execution_count": 473,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(datasetHL111[0].shape, datasetHL111[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcEoHHOTnKLL",
        "outputId": "8906a294-07b8-4248-cb6d-6b393cd8f7e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[1.0063251 , 0.93654037],\n",
              "       [1.0042149 , 1.0076504 ],\n",
              "       [1.0066643 , 1.        ],\n",
              "       [1.0018287 , 1.0325379 ],\n",
              "       [1.0022633 , 1.0588235 ],\n",
              "       [0.9984701 , 0.9742063 ],\n",
              "       [1.0072961 , 1.0061101 ],\n",
              "       [1.006519  , 1.0283401 ],\n",
              "       [0.9965815 , 1.1476378 ],\n",
              "       [1.0095315 , 1.0214409 ],\n",
              "       [0.9983195 , 1.0260286 ],\n",
              "       [1.0045494 , 0.9222586 ],\n",
              "       [1.008131  , 0.97870445],\n",
              "       [1.0021223 , 1.0063463 ],\n",
              "       [0.9996117 , 1.0333333 ],\n",
              "       [1.000424  , 1.0095901 ],\n",
              "       [1.0115777 , 0.9568221 ],\n",
              "       [0.99336976, 1.2490975 ],\n",
              "       [0.98974353, 1.0686417 ],\n",
              "       [1.0004969 , 0.9154834 ],\n",
              "       [0.998865  , 0.99483013],\n",
              "       [0.97822976, 1.2850779 ],\n",
              "       [0.9581777 , 2.1559792 ],\n",
              "       [1.0197022 , 0.8033226 ],\n",
              "       [0.99457526, 0.92494994],\n",
              "       [0.962491  , 1.2066354 ],\n",
              "       [1.0150216 , 0.8684997 ],\n",
              "       [1.0146844 , 0.8812801 ],\n",
              "       [1.0024873 , 0.97500974],\n",
              "       [1.0134964 , 0.77132565],\n",
              "       [1.01276   , 0.9932502 ],\n",
              "       [1.0002931 , 1.0172504 ],\n",
              "       [0.99373895, 1.0585818 ],\n",
              "       [0.9950254 , 0.9718447 ],\n",
              "       [1.0012963 , 0.93506485],\n",
              "       [1.0159391 , 0.88087606],\n",
              "       [1.0116125 , 0.95815647],\n",
              "       [0.9875134 , 1.1765822 ],\n",
              "       [0.9898698 , 1.0677783 ],\n",
              "       [0.98545945, 1.1319898 ],\n",
              "       [1.0051547 , 0.87182915],\n",
              "       [1.0115579 , 0.95610005],\n",
              "       [1.0025353 , 0.98024565],\n",
              "       [0.9996332 , 0.96732026],\n",
              "       [1.0048395 , 0.93130636],\n",
              "       [1.017402  , 0.88512695],\n",
              "       [0.99874496, 1.0778688 ],\n",
              "       [0.9935372 , 1.0361217 ],\n",
              "       [0.99486864, 1.0538226 ],\n",
              "       [0.9989102 , 0.9628555 ]], dtype=float32)"
            ]
          },
          "execution_count": 474,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL111[0][0, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDuwBrXXnKLL",
        "outputId": "89c6ed82-148f-48bf-a552-539f728359b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1.0010846, 0.9626402], dtype=float32)"
            ]
          },
          "execution_count": 476,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL111[1][0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KGMaCiHnKLL"
      },
      "outputs": [],
      "source": [
        "datasetHL = prepDataSetHHLLPred(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOBIa051nKLL",
        "outputId": "4268e37b-680e-47b3-cc23-f8cdb58b7751"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((826, 100), (826, 2))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(datasetHL[0].shape, datasetHL[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXqU0eVfnKLL"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "class DataLoader:\n",
        "    def __init__(self, data, batch_size):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = data.shape[0]\n",
        "        self.num_batches = (self.num_samples + self.batch_size - 1) // self.batch_size\n",
        "        self.current_batch = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current_batch >= self.num_batches:\n",
        "            raise StopIteration\n",
        "        start = self.current_batch * self.batch_size\n",
        "        end = min(start + self.batch_size, self.num_samples)\n",
        "        batch = self.data[start:end]\n",
        "        self.current_batch += 1\n",
        "        return jnp.array(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyRScp0AnKLL"
      },
      "outputs": [],
      "source": [
        "class DataLoaderXY:\n",
        "    def __init__(self, xs, ys, batch_size):\n",
        "        assert xs.shape[0] == ys.shape[0]\n",
        "        self.X = xs\n",
        "        self.y = ys\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = xs.shape[0]\n",
        "        self.num_batches = (self.num_samples + self.batch_size - 1) // self.batch_size\n",
        "        self.current_batch = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current_batch >= self.num_batches:\n",
        "            raise StopIteration\n",
        "        start = self.current_batch * self.batch_size\n",
        "        end = min(start + self.batch_size, self.num_samples)\n",
        "        X = self.X[start:end]\n",
        "        y = self.y[start:end]\n",
        "        self.current_batch += 1\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu6qK82pnKLL"
      },
      "outputs": [],
      "source": [
        "# df = prepDataHHLLPred(data)\n",
        "\n",
        "# data_loader = DataLoader(df, batch_size=100)\n",
        "\n",
        "# for batch in data_loader:\n",
        "#     # Process the batch using JAX\n",
        "#     # processed_batch = jax_function(batch)\n",
        "#     print(batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lWJfN0HnKLL",
        "outputId": "5ad0bcd4-09cf-4c48-81eb-7a32ae4f3292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(26, 100) (26, 2)\n"
          ]
        }
      ],
      "source": [
        "# datasetHL = prepDataSetHHLLPred(data)\n",
        "data_loader = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=100)\n",
        "\n",
        "for batch in data_loader:\n",
        "    # Process the batch using JAX\n",
        "    # processed_batch = jax_function(batch)\n",
        "    print(batch[0].shape, batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTZQF2sWnKLL",
        "outputId": "471d4033-1308-4076-cbd2-ecebd8f16c9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Array([[398.92, 391.56, 385.91, ...,  17.12,  17.99,  16.87],\n",
              "        [391.56, 385.91, 385.36, ...,  17.99,  16.87,  16.05],\n",
              "        [385.91, 385.36, 391.73, ...,  16.87,  16.05,  16.81],\n",
              "        ...,\n",
              "        [409.72, 408.05, 413.47, ...,  13.54,  13.88,  13.2 ],\n",
              "        [408.05, 413.47, 412.46, ...,  13.88,  13.2 ,  12.91],\n",
              "        [413.47, 412.46, 413.94, ...,  13.2 ,  12.91,  13.44]],      dtype=float32),\n",
              " Array([[419.23, 411.09],\n",
              "        [418.79, 411.09],\n",
              "        [420.02, 411.09],\n",
              "        [420.18, 411.09],\n",
              "        [420.18, 411.09],\n",
              "        [421.82, 414.65],\n",
              "        [427.92, 417.85],\n",
              "        [427.92, 417.85],\n",
              "        [428.03, 417.85],\n",
              "        [428.03, 421.82],\n",
              "        [429.13, 426.55],\n",
              "        [429.9 , 426.55],\n",
              "        [433.8 , 426.55],\n",
              "        [436.66, 426.55],\n",
              "        [437.18, 429.13],\n",
              "        [442.6 , 429.9 ],\n",
              "        [442.6 , 433.8 ],\n",
              "        [442.6 , 436.66],\n",
              "        [442.6 , 434.94],\n",
              "        [442.6 , 434.94],\n",
              "        [439.46, 433.21],\n",
              "        [437.18, 431.44],\n",
              "        [436.51, 431.44],\n",
              "        [436.51, 431.44],\n",
              "        [438.11, 431.44],\n",
              "        [443.28, 431.44]], dtype=float32))"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nAdevYgnKLL",
        "outputId": "a183fbad-483d-4c56-833e-fd056e730b0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26, 100)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXlZgjPGnKLL"
      },
      "outputs": [],
      "source": [
        "class LSTMjax:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def initialize_params(self, rng):\n",
        "        k1, k2, k3, k4, k5, k6, k7, k8, k9, k10, k11, k12, k13, k14, k15, k16, k17, k18 = random.split(rng, 18)\n",
        "\n",
        "        self.params = dict()\n",
        "        # forget gate\n",
        "        self.params['Wxf'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k1, (self.input_size, self.hidden_size))\n",
        "        self.params['Bxf'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k2, (self.hidden_size,))\n",
        "        self.params['Whf'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k3, (self.hidden_size, self.hidden_size))\n",
        "        self.params['Bhf'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k4, (self.hidden_size,))\n",
        "\n",
        "        # input gate\n",
        "        # input\n",
        "        self.params['Wxi'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k5, (self.input_size, self.hidden_size))\n",
        "        self.params['Bxi'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k6, (self.hidden_size,))\n",
        "        self.params['Whi'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k7, (self.hidden_size, self.hidden_size))\n",
        "        self.params['Bhi'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k8, (self.hidden_size,))\n",
        "        # learn\n",
        "        self.params['Wxl'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k9, (self.input_size, self.hidden_size))\n",
        "        self.params['Bxl'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k10, (self.hidden_size,))\n",
        "        self.params['Whl'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k11, (self.hidden_size, self.hidden_size))\n",
        "        self.params['Bhl'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k12, (self.hidden_size,))\n",
        "\n",
        "        # output gate\n",
        "        self.params['Wxo'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k13, (self.input_size, self.hidden_size))\n",
        "        self.params['Bxo'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k14, (self.hidden_size,))\n",
        "        self.params['Who'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k15, (self.hidden_size, self.hidden_size))\n",
        "        self.params['Bho'] = np.sqrt(1.0 / self.hidden_size) * random.normal(k16, (self.hidden_size,))\n",
        "\n",
        "        # final output\n",
        "        self.params['Wo'] = np.sqrt(1.0 / self.hidden_size) *\\\n",
        "            random.normal(k17, (self.hidden_size, self.output_size))\n",
        "        self.params['Bo'] = np.sqrt(1.0 / self.output_size) * random.normal(k18, (self.output_size,))\n",
        "\n",
        "        return self.params\n",
        "#         return self.Wxf, self.Bxf, self.Whf, self.Bhf, self.Wxi, self.Bxi, self.Whi, self.Bhi,\\\n",
        "#                 self.Wxl, self.Bxl, self.Whl, self.Bhl, self.Wxo, self.Bxo, self.Who, self.Bho, self.Wo, self.Bo\n",
        "\n",
        "    def forget_gate(self, x, h, c):\n",
        "        forget_eventx  = jnp.dot(x, self.params['Wxf']) + self.params['Bxf']\n",
        "        forget_hidden  = h @ self.params['Whf'] + self.params['Bhf']\n",
        "        return jnp.multiply(jax.nn.sigmoid(forget_eventx + forget_hidden), c)\n",
        "\n",
        "    def input_gate(self, x, h):\n",
        "        ignore_eventx  = x @ self.params['Wxi'] + self.params['Bxi']\n",
        "        ignore_hidden  = h @ self.params['Whi'] + self.params['Bhi']\n",
        "        learn_eventx  = x @ self.params['Wxl'] + self.params['Bxl']\n",
        "        learn_hidden  = h @ self.params['Whl'] + self.params['Bhl']\n",
        "        return jnp.multiply(jax.nn.sigmoid(ignore_eventx + ignore_hidden),\n",
        "                            jax.nn.tanh(learn_eventx + learn_hidden))\n",
        "\n",
        "    def cell_state(self, forget_gate_output, input_gate_output):\n",
        "        return forget_gate_output + input_gate_output\n",
        "\n",
        "    def output_gate(self, x, h, new_c):\n",
        "        out_eventx  = x @ self.params['Wxo'] + self.params['Bxo']\n",
        "        out_hidden  = h @ self.params['Who'] + self.params['Bho']\n",
        "        return jnp.multiply(jax.nn.sigmoid(out_eventx + out_hidden), jax.nn.tanh(new_c) )\n",
        "\n",
        "    def lstm_cell(self, carry, x):\n",
        "        h, c = carry\n",
        "#        print('h dim', h.shape)\n",
        "#        print('c dim', c.shape)\n",
        "        forget_gate = self.forget_gate(x, h, c)\n",
        "        input_gate = self.input_gate(x, h)\n",
        "        new_c = self.cell_state(forget_gate, input_gate)\n",
        "        new_h = self.output_gate(x, h, new_c)\n",
        "#        print('new h dim', new_h.shape)\n",
        "#        print('new c dim', new_c.shape)\n",
        "        return (new_h, new_c), new_h\n",
        "\n",
        "    def forward(self, inputs, params):\n",
        "#         self.Wxf, self.Bxf, self.Whf, self.Bhf, self.Wxi, self.Bxi, self.Whi, self.Bhi,\\\n",
        "#             self.Wxl, self.Bxl, self.Whl, self.Bhl, self.Wxo, self.Bxo, self.Who,\\\n",
        "#             self.Bho, self.Wo, self.Bo = params\n",
        "        self.params = params.copy()\n",
        "        self.final_state , self.hstate = jax.lax.scan(self.lstm_cell, (jnp.zeros((self.hidden_size,)),\n",
        "                                                       jnp.zeros((self.hidden_size,))),\n",
        "                                      inputs)\n",
        "#         self.hstate = hstate\n",
        "#         self.final_state = final_state\n",
        "#        print(self.params['Wo'].shape, self.final_state[0].shape)\n",
        "#        print((self.final_state[0] @ self.params['Wo']).shape)\n",
        "#         return self.final_state[0] @ self.params['Wo'] + self.params['Bo']\n",
        "        return self.hstate @ self.params['Wo'] + self.params['Bo']\n",
        "\n",
        "#     def loss(self, inputs, targets, params):\n",
        "#         predictions = self.forward(inputs, params)\n",
        "#         return jnp.mean((predictions - targets) ** 2)\n",
        "\n",
        "#     def update(self, inputs, targets, params, opt_state):\n",
        "#         loss_value, grads = jax.value_and_grad(self.loss)(inputs, targets, params)\n",
        "#         updates, new_opt_state = opt_update(grads, opt_state)\n",
        "#         new_params = optax.apply_updates(params, updates)\n",
        "#         return loss_value, new_params, new_opt_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eiia_IRmnKLL",
        "outputId": "b5c85980-ff56-43ab-c136-9db871d41d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wxf (100, 50)\n",
            "Bxf (50,)\n",
            "Whf (50, 50)\n",
            "Bhf (50,)\n",
            "Wxi (100, 50)\n",
            "Bxi (50,)\n",
            "Whi (50, 50)\n",
            "Bhi (50,)\n",
            "Wxl (100, 50)\n",
            "Bxl (50,)\n",
            "Whl (50, 50)\n",
            "Bhl (50,)\n",
            "Wxo (100, 50)\n",
            "Bxo (50,)\n",
            "Who (50, 50)\n",
            "Bho (50,)\n",
            "Wo (50, 2)\n",
            "Bo (2,)\n"
          ]
        }
      ],
      "source": [
        "data_key, model_key = random.split(jax.random.PRNGKey(212), 2)\n",
        "lstmj = LSTMjax(100, 50, 2)\n",
        "params = lstmj.initialize_params(model_key)\n",
        "for i in params.keys():\n",
        "    print(i, params[i].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfBVrZiwnKLL",
        "outputId": "d705ae80-50c0-4603-bb26-49aba3e3d018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h dim (50,)\n",
            "c dim (50,)\n",
            "new h dim (50,)\n",
            "new c dim (50,)\n",
            "(50, 2) (50,)\n",
            "(2,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Array([[ 1.7456347 , -0.01571721],\n",
              "       [ 1.8657119 , -0.06756604],\n",
              "       [ 1.9162483 , -0.08986092],\n",
              "       [ 1.9219131 , -0.09163332],\n",
              "       [ 1.9240918 , -0.09185678],\n",
              "       [ 1.9242189 , -0.09188944],\n",
              "       [ 1.9242373 , -0.09189367],\n",
              "       [ 1.924238  , -0.09189409],\n",
              "       [ 1.924237  , -0.09189337],\n",
              "       [ 1.9242384 , -0.09190923],\n",
              "       [ 1.9242272 , -0.09188932],\n",
              "       [ 1.9239314 , -0.09186059],\n",
              "       [ 1.9266841 , -0.10038698],\n",
              "       [ 1.9355528 , -0.11548036],\n",
              "       [ 1.9257171 , -0.09520149],\n",
              "       [ 1.9242027 , -0.09225202],\n",
              "       [ 1.9242957 , -0.09210289],\n",
              "       [ 1.8964727 , -0.10703206],\n",
              "       [ 1.9276764 , -0.09941584],\n",
              "       [ 1.9247558 , -0.09296155],\n",
              "       [ 1.9243131 , -0.09204644],\n",
              "       [ 1.9313369 , -0.10656542],\n",
              "       [ 1.9444609 , -0.13369304],\n",
              "       [ 1.9355354 , -0.11608052],\n",
              "       [ 1.92892   , -0.10958755],\n",
              "       [ 1.9252188 , -0.09457952]], dtype=float32)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmj.forward(batch[0], params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_8_xswonKLL",
        "outputId": "7cc7087f-48ad-41b6-a3b7-b4780755231e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmj.final_state[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmoPpZwNnKLL",
        "outputId": "6253203f-a8ac-4515-df56-3df3ff1e0bdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26, 50)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmj.hstate.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0rovgOvnKLM",
        "outputId": "34c89cfc-22ad-4e52-a8a0-02fa1f7bba18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optax.l2_loss(batch[1], batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8o6p2uJnKLM",
        "outputId": "42728f99-8658-4ca4-9f2e-8b12b83ff310"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[1] -batch[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH4GmvjPnKLM",
        "outputId": "addae79a-0ef1-4c30-bd44-ff646c1836bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[252.8 , 228.8 ],\n",
              "       [252.8 , 222.95],\n",
              "       [243.15, 222.95],\n",
              "       [246.79, 222.95],\n",
              "       [261.2 , 222.95],\n",
              "       [261.2 , 222.95],\n",
              "       [261.65, 243.15],\n",
              "       [261.65, 246.79],\n",
              "       [261.65, 246.15],\n",
              "       [261.65, 246.15]], dtype=float32)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL[1][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zONZndnGnKLM",
        "outputId": "e3862925-25be-49b9-cf75-7c9242197e81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([286.64, 275.66], dtype=float32)"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL[1][10:20][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhDeCRZHnKLM",
        "outputId": "fac14370-c85c-4107-b7a2-7a511f7df233"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(574.84155, dtype=float32)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jnp.mean((datasetHL[1][:10] - datasetHL[1][10:20])**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW87FtdznKLM"
      },
      "outputs": [],
      "source": [
        "data_loader = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zen13g0nKLM",
        "outputId": "38f4f201-a98b-4b4d-dd3f-4f041afcdfc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(50, 100) (50, 2)\n",
            "(26, 100) (26, 2)\n"
          ]
        }
      ],
      "source": [
        "for batch in data_loader:\n",
        "    print(batch[0].shape, batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN6cetJfnKLM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcOrnxPGnKLM",
        "outputId": "8e2d8169-89a5-456b-dd00-a1b2e0f84d5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(826, 100)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAH6TsxbnKLM",
        "outputId": "7fdb4bbe-8896-4afe-c5c6-1dd201deb484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wxf (100, 500)\n",
            "Bxf (500,)\n",
            "Whf (500, 500)\n",
            "Bhf (500,)\n",
            "Wxi (100, 500)\n",
            "Bxi (500,)\n",
            "Whi (500, 500)\n",
            "Bhi (500,)\n",
            "Wxl (100, 500)\n",
            "Bxl (500,)\n",
            "Whl (500, 500)\n",
            "Bhl (500,)\n",
            "Wxo (100, 500)\n",
            "Bxo (500,)\n",
            "Who (500, 500)\n",
            "Bho (500,)\n",
            "Wo (500, 2)\n",
            "Bo (2,)\n",
            "epoch 0, loss: 187166.84375\n",
            "epoch 10, loss: 176610.3125\n",
            "epoch 20, loss: 166487.234375\n",
            "epoch 30, loss: 156699.671875\n",
            "epoch 40, loss: 147408.171875\n",
            "epoch 50, loss: 138555.9375\n",
            "epoch 60, loss: 129954.5\n",
            "epoch 70, loss: 121615.109375\n",
            "epoch 80, loss: 113759.953125\n",
            "epoch 90, loss: 106334.2734375\n",
            "epoch 100, loss: 99298.25\n",
            "epoch 110, loss: 92628.8671875\n",
            "epoch 120, loss: 86308.484375\n",
            "epoch 130, loss: 80322.09375\n",
            "epoch 140, loss: 74656.15625\n",
            "epoch 150, loss: 69298.171875\n",
            "epoch 160, loss: 64236.3359375\n",
            "epoch 170, loss: 59459.359375\n",
            "epoch 180, loss: 54956.453125\n",
            "epoch 190, loss: 50717.15625\n",
            "epoch 200, loss: 46731.390625\n",
            "epoch 210, loss: 42989.3125\n",
            "epoch 220, loss: 39481.30859375\n",
            "epoch 230, loss: 36197.99609375\n",
            "epoch 240, loss: 33130.1640625\n",
            "epoch 250, loss: 30268.810546875\n",
            "epoch 260, loss: 27605.083984375\n",
            "epoch 270, loss: 25130.2265625\n",
            "epoch 280, loss: 22835.638671875\n",
            "epoch 290, loss: 20712.849609375\n",
            "epoch 300, loss: 18753.54296875\n",
            "epoch 310, loss: 16949.40625\n",
            "epoch 320, loss: 15292.3359375\n",
            "epoch 330, loss: 13774.3154296875\n",
            "epoch 340, loss: 12387.4296875\n",
            "epoch 350, loss: 11123.9248046875\n",
            "epoch 360, loss: 9976.15625\n",
            "epoch 370, loss: 8936.630859375\n",
            "epoch 380, loss: 7998.0322265625\n",
            "epoch 390, loss: 7153.22802734375\n",
            "epoch 400, loss: 6395.2841796875\n",
            "epoch 410, loss: 5717.447265625\n",
            "epoch 420, loss: 5113.259765625\n",
            "epoch 430, loss: 4576.501953125\n",
            "epoch 440, loss: 4101.18896484375\n",
            "epoch 450, loss: 3681.708740234375\n",
            "epoch 460, loss: 3312.709716796875\n",
            "epoch 470, loss: 2989.16357421875\n",
            "epoch 480, loss: 2706.40185546875\n",
            "epoch 490, loss: 2460.06787109375\n"
          ]
        }
      ],
      "source": [
        "data_key, model_key = random.split(jax.random.PRNGKey(212), 2)\n",
        "lstmj = LSTMjax(100, 500, 2)\n",
        "params = lstmj.initialize_params(model_key)\n",
        "for i in params.keys():\n",
        "    print(i, params[i].shape)\n",
        "\n",
        "# optimizer\n",
        "# import optax\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "#data_loader = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)\n",
        "\n",
        "# train_size = X_train.shape[0]\n",
        "num_epochs = 500\n",
        "def fit(params: optax.Params, optimizer: optax.GradientTransformation) -> optax.Params:\n",
        "    opt_state = optimizer.init(params)\n",
        "\n",
        "    def l2_loss(params, x, y):\n",
        "        y_pred = lstmj.forward(x, params)\n",
        "        l2 = jnp.mean((y_pred[-3:] - y[-3:])**2)\n",
        "        return l2\n",
        "\n",
        "    @jax.jit\n",
        "    def run_batch(params, opt_state, batch_x, batch_y):\n",
        "        loss_value, grads = jax.value_and_grad(l2_loss)(params, batch_x, batch_y)\n",
        "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "        params = optax.apply_updates(params, updates)\n",
        "        return params, opt_state, loss_value\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        data_loader = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)\n",
        "        j = 0\n",
        "        for batch in data_loader:\n",
        "            params, opt_state, loss_value = run_batch(params, opt_state, batch[0], batch[1])\n",
        "#             if j % 2 == 0:\n",
        "#                 print(f'batch {j}, loss: {loss_value}')\n",
        "#             j += 1\n",
        "        if i % 10 == 0: print(f'epoch {i}, loss: {loss_value}')\n",
        "        i += 1\n",
        "\n",
        "    return params\n",
        "\n",
        "# Fit our parametrized function using the Adam optimizer\n",
        "\n",
        "optimizer = optax.adam(learning_rate=learning_rate)\n",
        "params = fit(params, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO7KGi6anKLM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U8wJZK8nKLM",
        "outputId": "b0f5941e-3673-4450-91ce-20461dad4d97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Bhf': Array([-9.52478051e-02,  9.87952761e-03,  1.88455675e-02,  7.45466277e-02,\n",
              "        -1.38312019e-02,  9.16572735e-02, -8.00402090e-02,  2.30532195e-02,\n",
              "         3.25846374e-02,  7.53044933e-02,  1.95374954e-02, -5.68133704e-02,\n",
              "        -4.82216403e-02, -1.28017901e-03,  4.31282297e-02,  5.16417474e-02,\n",
              "         1.82083137e-02,  2.71509010e-02, -8.06970224e-02, -5.82590327e-02,\n",
              "        -5.22065461e-02, -3.40457112e-02, -7.95596186e-03,  2.18360182e-02,\n",
              "         3.90631109e-02,  7.60116577e-02,  2.16217916e-02, -2.89709680e-02,\n",
              "         3.72436494e-02, -2.18782481e-02, -2.37498321e-02,  2.30067479e-03,\n",
              "        -2.88653243e-02, -6.83590621e-02,  1.03904698e-02,  4.50549349e-02,\n",
              "        -4.67866845e-02, -3.19389328e-02,  4.55142418e-03,  8.79394473e-04,\n",
              "        -3.83563451e-02,  1.49417073e-02,  6.74083307e-02,  7.37768412e-02,\n",
              "        -1.59983169e-02, -4.18795869e-02,  8.03379491e-02, -7.41228238e-02,\n",
              "        -7.66770691e-02, -3.45280729e-02, -4.67522815e-02,  6.40554801e-02,\n",
              "        -5.23989275e-02,  2.27461960e-02, -9.00417380e-03,  2.61106566e-02,\n",
              "         2.17362996e-02, -2.79909596e-02, -2.28524245e-02,  2.02424265e-02,\n",
              "        -4.61695194e-02,  1.81997623e-02,  4.61685471e-02,  1.53924832e-02,\n",
              "         4.38052900e-02, -6.61310703e-02, -1.45250838e-02,  4.01076600e-02,\n",
              "        -2.70089898e-02,  8.59974846e-02,  3.03748008e-02, -2.85425805e-03,\n",
              "         6.07792623e-02, -3.34459879e-02,  4.48203599e-03,  2.39394233e-02,\n",
              "        -8.23339075e-02,  3.82206850e-02, -8.56265798e-03, -5.64409420e-02,\n",
              "        -2.57344525e-02,  3.10827959e-02,  3.89867015e-02, -1.08952178e-02,\n",
              "         4.25708806e-03,  1.89890787e-02, -2.33032927e-02, -9.58457217e-03,\n",
              "         3.78729515e-02,  1.39613375e-02,  1.95483323e-02, -9.58699267e-03,\n",
              "         5.51920906e-02,  2.24674530e-02,  2.50123162e-02,  6.42080605e-03,\n",
              "        -2.46975031e-02,  2.02631969e-02, -4.24039289e-02,  3.75181884e-02,\n",
              "         3.89274061e-02,  1.83701646e-02,  1.03114620e-02,  1.51340989e-03,\n",
              "        -8.48930981e-03,  7.38973767e-02,  7.45971277e-02,  2.07742341e-02,\n",
              "        -8.55621765e-05, -2.32683532e-02,  3.83025594e-02,  9.64389089e-03,\n",
              "         3.98188690e-03, -1.88821927e-02,  3.95797566e-02, -3.29953507e-02,\n",
              "        -1.64426602e-02, -9.53331590e-03, -3.80951585e-03,  7.91049525e-02,\n",
              "        -7.21921846e-02, -4.17763963e-02,  1.76070929e-02,  3.41382027e-02,\n",
              "        -5.69217987e-02,  1.18256621e-01, -1.64625514e-02,  9.44295079e-02,\n",
              "        -3.27620506e-02, -3.09226831e-04, -3.45716700e-02,  6.67843968e-02,\n",
              "        -1.05404526e-01, -5.72325289e-02,  5.14230132e-02, -2.20736768e-02,\n",
              "         3.84430364e-02, -3.16983089e-02, -8.66361894e-03,  3.75226550e-02,\n",
              "         4.29730751e-02,  1.05662802e-02, -1.78824328e-02, -5.16011156e-02,\n",
              "         5.91970384e-02,  6.90435320e-02,  8.47294703e-02,  2.07187422e-02,\n",
              "         6.38953410e-03,  1.19996769e-02,  1.32143963e-02, -6.53560013e-02,\n",
              "        -1.13012027e-02, -2.60213055e-02,  7.31064007e-02, -5.91950305e-03,\n",
              "         5.36238886e-02,  5.64389974e-02, -2.39756564e-03, -9.68526751e-02,\n",
              "         8.40064604e-03, -4.97814454e-02, -1.05271064e-01, -7.60411620e-02,\n",
              "         8.00593477e-03, -5.45547456e-02,  9.69549194e-02, -4.28365432e-02,\n",
              "         4.73004431e-02, -9.35651883e-02, -4.33895290e-02, -2.28789374e-02,\n",
              "         4.20008078e-02,  5.90020157e-02, -7.65427649e-02,  7.97118898e-03,\n",
              "        -4.56864946e-02, -2.22457834e-02,  1.22144977e-02, -1.80848688e-02,\n",
              "         2.72677578e-02,  8.28478038e-02, -1.12817183e-01, -2.16247272e-02,\n",
              "         4.28841673e-02,  1.07346997e-02, -5.40211573e-02,  1.27658442e-01,\n",
              "        -3.77870575e-02,  1.07636871e-02, -1.84042077e-03,  4.91120741e-02,\n",
              "        -6.21869881e-03,  1.89928208e-02,  5.90284020e-02, -3.77395861e-02,\n",
              "        -9.78229567e-02,  4.99391146e-02, -8.43965821e-03, -4.09678146e-02,\n",
              "        -6.11010566e-02, -4.32656892e-02, -2.64211535e-03, -3.78694460e-02,\n",
              "        -1.23618692e-02, -2.42089177e-03, -4.84719723e-02,  4.96689603e-02,\n",
              "         6.53887317e-02, -5.11127040e-02,  1.59488861e-02,  1.14287762e-02,\n",
              "        -3.54008423e-03, -1.82864852e-02,  2.45888662e-02,  4.48337756e-02,\n",
              "         3.58737353e-03, -2.49378663e-02, -6.12837635e-02,  9.39638317e-02,\n",
              "         1.58829559e-02, -3.36836185e-03,  1.21400403e-02, -2.84777489e-02,\n",
              "        -5.14373109e-02, -9.93263721e-03,  6.03992958e-03, -1.70389283e-03,\n",
              "        -2.45210547e-02, -2.86824871e-02,  1.25029674e-02, -4.56507653e-02,\n",
              "        -2.09591072e-02,  8.81118758e-04, -2.72183437e-02,  4.10555258e-05,\n",
              "         6.62247743e-03,  1.46285733e-02,  8.26145783e-02,  4.07838784e-02,\n",
              "         3.04321330e-02,  3.37967686e-02, -4.83565032e-02,  4.99458518e-03,\n",
              "        -3.51155326e-02,  2.24045403e-02,  3.32870968e-02,  7.66014233e-02,\n",
              "         3.13351862e-02, -4.70804647e-02, -5.40707819e-02,  6.48266524e-02,\n",
              "         2.67954879e-02,  3.20440158e-02,  5.71497418e-02, -2.51781307e-02,\n",
              "        -5.21959551e-02, -5.74914925e-02,  5.36824539e-02,  3.44596687e-03,\n",
              "         1.52242323e-02,  2.44124923e-02,  4.79719862e-02,  8.16236064e-02,\n",
              "         1.06490403e-01,  5.91820246e-03,  7.75621533e-02,  2.30053086e-02,\n",
              "        -2.35676020e-02, -8.64776596e-03,  9.02750064e-03,  4.28169556e-02,\n",
              "         4.41093631e-02,  3.19039598e-02, -4.72114757e-02, -2.77830511e-02,\n",
              "        -1.52658643e-02,  5.07063642e-02,  2.80975597e-03, -3.39255035e-02,\n",
              "        -7.14126751e-02,  2.58306134e-02, -5.58342934e-02, -1.29968429e-03,\n",
              "        -5.38908765e-02, -4.77330312e-02,  7.36442581e-02, -3.56832854e-02,\n",
              "         2.53906529e-02, -4.92609963e-02,  5.70982099e-02,  8.91289711e-02,\n",
              "        -3.38997804e-02,  1.12127103e-02, -1.63590461e-02,  1.68719236e-02,\n",
              "         3.07502281e-02,  2.76501179e-02,  8.96222740e-02,  7.14025646e-03,\n",
              "         3.77218388e-02, -2.35938607e-03,  9.10693705e-02,  7.40292147e-02,\n",
              "        -3.18047702e-02, -2.13383529e-02, -8.06947872e-02,  2.19340492e-02,\n",
              "         9.97079089e-02,  1.42922858e-03, -1.58750359e-02, -3.59497070e-02,\n",
              "        -2.91887131e-02, -1.19454287e-01, -4.11999263e-02,  9.34146345e-03,\n",
              "        -5.06811216e-02,  1.50835793e-02, -1.97004825e-02,  9.93101299e-02,\n",
              "        -2.89876834e-02,  5.16565070e-02,  1.88874453e-02, -3.26613486e-02,\n",
              "        -1.18310712e-01, -4.66659153e-03, -7.16475025e-02, -1.12486994e-02,\n",
              "         1.72254944e-03,  1.03523560e-01,  7.93866143e-02, -1.96308400e-02,\n",
              "        -9.26953405e-02,  2.98137474e-03,  7.19912490e-03,  1.37556181e-03,\n",
              "        -3.14027555e-02,  6.12079687e-02,  1.12618819e-01, -6.20365664e-02,\n",
              "         9.19788145e-03,  6.28055632e-02, -5.60029298e-02, -3.69364920e-04,\n",
              "        -5.50598046e-03,  1.73664391e-02,  4.10256302e-03,  2.32726466e-02,\n",
              "         6.63478449e-02,  4.70623188e-02,  6.61472902e-02,  4.55682166e-02,\n",
              "         1.98840089e-02, -2.37926487e-02,  2.91457865e-02, -2.19641142e-02,\n",
              "         1.58875361e-02, -2.51580421e-02,  2.38619335e-02,  2.89927348e-02,\n",
              "         2.79346062e-03, -2.36124918e-02, -3.53062712e-02, -2.50842981e-02,\n",
              "        -1.36662868e-03, -1.19270934e-02, -7.49124736e-02, -4.43991125e-02,\n",
              "         5.53491823e-02,  3.47603559e-02,  6.53366223e-02,  4.49405424e-02,\n",
              "        -3.18770185e-02,  1.86943039e-02, -5.94840124e-02,  4.59348187e-02,\n",
              "        -7.90152848e-02, -1.11610396e-02, -2.78920047e-02, -3.55497673e-02,\n",
              "         4.15730067e-02, -2.39926353e-02,  4.14852705e-03, -1.52364525e-03,\n",
              "         3.90929915e-02, -5.89297079e-02, -3.72033156e-02,  2.74131112e-02,\n",
              "         3.54750152e-03,  5.13362363e-02, -1.22524332e-02,  5.84899522e-02,\n",
              "        -2.92922817e-02, -1.15327304e-02, -1.18211284e-02,  1.45117799e-02,\n",
              "        -2.61262525e-03,  6.03017993e-02, -4.76326756e-02, -6.91580996e-02,\n",
              "         3.33942968e-04, -6.91000596e-02, -7.32723549e-02,  2.79728118e-02,\n",
              "        -4.43642810e-02, -6.58142194e-02, -7.14183152e-02,  5.88433556e-02,\n",
              "         3.40315439e-02, -5.95296547e-02, -3.11811212e-02,  4.66376245e-02,\n",
              "        -2.09598094e-02,  5.06792159e-04, -3.14952992e-02,  3.58524621e-02,\n",
              "        -7.98191875e-03,  3.41088511e-02,  1.02923876e-02, -1.15153929e-02,\n",
              "         2.53318213e-02,  1.72813348e-02,  5.95746487e-02, -2.87694205e-03,\n",
              "         3.25552039e-02,  5.14902212e-02,  3.65047604e-02,  1.68279912e-02,\n",
              "        -3.83503474e-02,  5.41338697e-04,  6.12790026e-02,  1.17075234e-03,\n",
              "        -1.29312754e-01, -1.28382875e-03,  1.48136241e-04,  6.75258692e-03,\n",
              "         3.61240543e-02, -2.90704165e-02, -3.13495621e-02, -2.08810344e-02,\n",
              "        -1.30958296e-02,  1.91456974e-02, -2.98041571e-02, -4.91293110e-02,\n",
              "         4.02764678e-02, -6.39780378e-03, -5.47871888e-02,  6.21681176e-02,\n",
              "         7.43660936e-03,  3.92480418e-02, -3.38203423e-02, -7.71183847e-03,\n",
              "        -1.88128799e-02, -6.12088740e-02, -1.65031422e-02, -2.60077771e-02,\n",
              "        -2.94338427e-02, -4.98344041e-02, -3.30836587e-02, -7.70715326e-02,\n",
              "        -7.72081837e-02,  5.00605740e-02, -5.83876409e-02, -1.33078219e-02,\n",
              "        -8.55234079e-03,  1.61107369e-02, -5.59021235e-02, -6.06967025e-02,\n",
              "        -1.63447317e-02,  2.72286274e-02, -5.88309877e-02,  6.98179286e-03,\n",
              "         2.43494827e-02,  3.32477503e-02, -3.47157493e-02,  5.78415543e-02,\n",
              "         3.06132287e-02, -8.51943437e-03, -2.07408592e-02,  4.31374647e-02,\n",
              "         4.80342796e-03,  4.52459976e-03,  1.38157876e-02, -7.62970001e-02,\n",
              "        -7.37782791e-02, -5.64199947e-02, -2.24565174e-02,  1.41762691e-02,\n",
              "        -1.04724035e-01, -1.41385226e-02, -1.42033845e-02, -5.85163338e-03,\n",
              "         7.81538244e-03, -2.44557224e-02,  3.13743316e-02,  1.75358504e-02,\n",
              "         7.88832679e-02, -1.44872656e-02, -2.45991405e-02, -1.80405155e-02],      dtype=float32),\n",
              " 'Bhi': Array([-1.03200190e-02,  8.37259591e-02,  3.36254425e-02,  1.96487140e-02,\n",
              "         1.90259647e-02,  3.02540548e-02,  7.80143067e-02, -5.36483191e-02,\n",
              "        -1.65542960e-02,  1.38513818e-02, -7.02398270e-03,  4.66406830e-02,\n",
              "         8.60206317e-03,  2.68006232e-02,  1.38495583e-02,  9.65430122e-03,\n",
              "         8.99591744e-02, -4.19933386e-02,  5.39585017e-02, -1.24859279e-02,\n",
              "         2.61942148e-02, -8.46841261e-02,  1.27404062e-02, -1.33343235e-01,\n",
              "        -3.02783540e-03, -5.96601609e-03, -5.68215922e-03,  8.58191121e-03,\n",
              "        -3.97230014e-02,  1.11988887e-01,  3.39906961e-02, -9.86647010e-02,\n",
              "        -7.15571791e-02, -3.11326589e-02, -6.33691400e-02, -3.37486155e-02,\n",
              "        -5.15327137e-03, -4.64216024e-02, -2.52999160e-02, -8.91020671e-02,\n",
              "         7.17216507e-02,  3.87177430e-02,  4.07487899e-02, -2.96507888e-02,\n",
              "        -7.30511500e-04, -3.79780754e-02, -1.28102489e-02, -6.23254366e-02,\n",
              "        -3.87981050e-02, -8.68536830e-02, -4.19627577e-02,  2.00161245e-02,\n",
              "        -2.80277058e-02,  7.52942543e-03, -1.03829941e-02,  8.68333951e-02,\n",
              "        -3.75252813e-02, -5.66160306e-03,  1.40898209e-02, -5.86497691e-03,\n",
              "         3.75118814e-02, -3.77018414e-02,  2.34952886e-02, -2.14751977e-02,\n",
              "         5.46403276e-03, -2.38575656e-02, -3.28724418e-04,  6.63544312e-02,\n",
              "         9.23560467e-04,  3.51518057e-02, -4.26523127e-02, -1.34657240e-02,\n",
              "        -1.13168089e-02, -4.69987690e-02, -3.14425901e-02,  6.57036677e-02,\n",
              "        -4.74201106e-02,  3.73344570e-02, -4.59740013e-02,  6.22988604e-02,\n",
              "         3.31216268e-02,  4.52537201e-02, -5.14506772e-02, -3.97063605e-02,\n",
              "        -1.71703007e-02, -4.81845848e-02, -1.03689637e-02, -3.36544663e-02,\n",
              "        -5.97972795e-03,  3.79984304e-02,  8.85080267e-03,  6.53344160e-03,\n",
              "        -4.59288955e-02, -4.84049274e-03, -4.48408443e-03,  1.88581105e-02,\n",
              "        -4.77668419e-02, -4.59185503e-02,  1.20561123e-01,  3.16036725e-03,\n",
              "         8.83195084e-03, -8.37757811e-02, -2.87315138e-02, -6.91039935e-02,\n",
              "        -3.45203057e-02, -2.05856152e-02, -2.97805835e-02,  1.75842643e-02,\n",
              "         5.69565129e-03,  5.35603017e-02, -4.96561453e-02,  2.27931887e-03,\n",
              "         5.66295236e-02, -2.43779197e-02, -7.54253641e-02, -7.23240525e-02,\n",
              "        -4.98815812e-02, -3.11267674e-02,  3.17685376e-03, -5.18993400e-02,\n",
              "        -7.79659078e-02,  1.53981689e-02,  3.32225710e-02,  4.25025001e-02,\n",
              "        -4.09994945e-02, -3.92982215e-02,  4.44748998e-02,  1.76375210e-02,\n",
              "         2.02444158e-02, -4.86485958e-02, -9.30869300e-03, -2.25039590e-02,\n",
              "         1.09105967e-01,  8.90337117e-03,  8.53565931e-02,  6.87577482e-03,\n",
              "         4.57026288e-02,  2.50112935e-04,  5.07426448e-02, -8.57609138e-03,\n",
              "         3.96743417e-02, -1.65027827e-02,  1.75847970e-02, -8.48824009e-02,\n",
              "        -3.48687731e-02,  2.71537760e-03,  8.39732811e-02,  3.28561924e-02,\n",
              "        -6.21807994e-03,  2.21308358e-02,  3.18900347e-02,  3.32317650e-02,\n",
              "         2.40518916e-02, -1.02541812e-01,  3.20908166e-02, -2.30816063e-02,\n",
              "         1.81476604e-02, -1.11119412e-02, -8.90782103e-03,  5.54829352e-02,\n",
              "         8.98245722e-02,  7.08142936e-04, -1.57352630e-02, -2.83711823e-03,\n",
              "        -7.36937150e-02,  7.12034628e-02,  3.37873921e-02,  7.99576472e-03,\n",
              "        -5.06723151e-02, -3.06341075e-03,  4.73630754e-03,  2.13648956e-02,\n",
              "        -8.22389573e-02, -3.35602164e-02, -5.95849864e-02,  5.27290776e-02,\n",
              "         6.24157414e-02, -1.53208645e-02, -4.38177362e-02,  2.25908104e-02,\n",
              "         4.75656465e-02, -6.55901581e-02,  1.09477649e-02, -7.07361090e-04,\n",
              "         8.31841398e-03, -3.22607644e-02,  7.02862218e-02,  6.71430603e-02,\n",
              "        -8.71859863e-02,  3.65207829e-02,  6.35061460e-03, -2.36078668e-02,\n",
              "        -8.29105265e-03,  2.30303444e-02,  3.34837399e-02,  3.84582616e-02,\n",
              "         3.23352888e-02, -6.64258189e-03, -1.45899570e-02, -3.53753706e-03,\n",
              "         1.57906301e-03,  1.85526758e-02,  5.12687415e-02,  1.75988080e-03,\n",
              "         5.20402491e-02,  1.70745160e-02,  4.16737348e-02,  8.26392509e-03,\n",
              "        -3.56399268e-02, -1.05958767e-02,  4.91483929e-03, -5.33572724e-03,\n",
              "         1.54513618e-05,  2.10572891e-02,  5.70633495e-03, -3.47761512e-02,\n",
              "        -3.86622399e-02, -3.80991660e-02,  7.64364004e-02, -1.00315558e-02,\n",
              "        -1.80220064e-02,  1.65643319e-02,  3.32656093e-02, -2.34018620e-02,\n",
              "        -2.34031472e-02,  1.18539240e-02,  2.79456954e-02, -1.10327797e-02,\n",
              "         8.75593442e-03, -3.25290114e-02, -3.10300142e-02,  4.46198620e-02,\n",
              "        -7.25737214e-02, -4.57478091e-02,  4.76207137e-02,  3.75662521e-02,\n",
              "         3.29715423e-02, -2.27458943e-02,  7.35677704e-02, -1.33820530e-02,\n",
              "        -1.09194908e-02, -8.37163553e-02, -3.47250514e-02, -4.32056114e-02,\n",
              "        -4.14881334e-02,  8.45896751e-02, -3.07850484e-02,  5.76830329e-03,\n",
              "         3.45419757e-02, -3.73269506e-02, -1.22251488e-01, -5.98447844e-02,\n",
              "         1.57024488e-02,  4.74878661e-02,  2.97486805e-03, -5.00545613e-02,\n",
              "        -2.93096229e-02, -3.49968206e-03, -1.15224235e-02,  2.64925719e-03,\n",
              "         7.92465806e-02, -7.58494670e-03, -3.90765443e-02,  1.21538453e-01,\n",
              "         1.91599801e-02, -3.37052271e-02, -2.05476973e-02, -2.80869007e-03,\n",
              "        -1.21257678e-02,  5.62102394e-03, -8.67316425e-02,  4.49001417e-03,\n",
              "        -7.00423270e-02, -4.04747166e-02,  4.23875041e-02, -2.31264085e-02,\n",
              "        -4.67778184e-02,  3.22839394e-02, -1.89015828e-02, -3.06346919e-02,\n",
              "        -3.68843158e-03,  3.22679691e-02, -3.69229130e-02,  8.24648514e-03,\n",
              "         2.44989004e-02, -7.57397478e-03,  3.48339491e-02,  4.13501859e-02,\n",
              "        -4.88491245e-02,  2.15239562e-02, -1.75027910e-03, -4.20980155e-02,\n",
              "        -1.40158655e-02, -8.04554671e-02, -2.70813238e-02, -2.82408930e-02,\n",
              "         1.19656287e-02, -5.29244728e-03, -2.27559060e-02, -1.14073884e-02,\n",
              "         1.58280004e-02, -2.74594990e-03, -9.77453403e-03,  4.72798310e-02,\n",
              "         1.80952437e-02,  3.72487530e-02, -4.13409173e-02, -1.14695504e-01,\n",
              "        -1.83101642e-04,  1.09800119e-02, -1.08682376e-03, -2.59654745e-02,\n",
              "         1.05528282e-02,  1.14646696e-01, -4.24349830e-02,  2.53095068e-02,\n",
              "         1.97989447e-03, -6.39480946e-04, -3.08423303e-03,  1.18828245e-01,\n",
              "         2.79183593e-02,  2.18686461e-02,  7.50136981e-03, -2.07060222e-02,\n",
              "        -4.68037538e-02, -1.83724556e-02,  3.12707499e-02, -9.20465961e-03,\n",
              "         3.73817757e-02,  1.58495381e-02,  7.11323810e-04, -3.07171177e-02,\n",
              "         2.32999027e-02, -1.49564035e-02,  4.58881445e-02,  3.76526378e-02,\n",
              "         2.23373771e-02, -1.27861919e-02,  3.78574245e-02, -7.14044496e-02,\n",
              "        -3.75744477e-02,  3.61789651e-02, -6.05989189e-04,  1.77206397e-02,\n",
              "        -4.63947207e-02, -6.98435819e-03, -2.22215429e-02, -3.11644562e-02,\n",
              "         1.03133120e-01, -2.22759116e-02, -5.85304759e-02,  5.36798276e-02,\n",
              "        -5.29932976e-02, -6.28056899e-02, -6.05352037e-02, -4.05059010e-02,\n",
              "         6.05102144e-02,  3.80683541e-02,  7.41285784e-03, -3.39682512e-02,\n",
              "        -1.23520400e-02,  8.62005875e-02, -4.72011864e-02, -3.27871647e-03,\n",
              "         1.21235009e-02,  5.80858774e-02,  5.92106096e-02,  2.36856062e-02,\n",
              "         4.00803797e-02, -3.04723978e-02,  2.64616273e-02, -4.27168757e-02,\n",
              "        -5.28003387e-02,  7.12064877e-02, -4.94466117e-03, -4.37730961e-02,\n",
              "        -2.60753985e-02, -4.25341949e-02,  4.67834510e-02, -6.13379106e-02,\n",
              "         6.44358248e-02, -1.95201412e-02, -3.53826433e-02, -6.10857224e-03,\n",
              "        -3.87462564e-02, -5.32282144e-03, -4.39137481e-02, -1.67884678e-02,\n",
              "         1.04486477e-02, -2.71847732e-02,  2.47991830e-02, -9.49232280e-03,\n",
              "         5.08934744e-02, -1.78738795e-02,  2.98222899e-02, -3.21865454e-02,\n",
              "         2.99431779e-03, -1.83899496e-02, -3.60636115e-02, -9.63834953e-03,\n",
              "        -2.10172031e-02, -2.45179906e-02,  4.53543141e-02,  1.68637708e-02,\n",
              "         6.71062171e-02,  2.73200944e-02, -5.31723583e-03, -6.26369715e-02,\n",
              "        -1.77460480e-02, -6.21085949e-02,  7.98015017e-03, -1.09965608e-01,\n",
              "        -7.51520395e-02,  7.98259396e-03,  1.95058212e-02,  4.45405468e-02,\n",
              "         1.00752581e-02, -1.01538058e-02, -6.35463139e-03, -4.38674092e-02,\n",
              "        -1.19465054e-04, -1.79579444e-02,  7.15908334e-02,  6.34011701e-02,\n",
              "         4.03826050e-02,  3.88409682e-02,  4.07140516e-02, -6.48578256e-02,\n",
              "        -4.20450345e-02, -2.49433815e-02, -4.63849716e-02, -1.25849545e-02,\n",
              "         2.49537081e-02, -2.64254548e-02, -1.73225477e-02, -2.07463205e-02,\n",
              "        -3.08947321e-02, -1.35660265e-02, -7.73565248e-02,  3.96762490e-02,\n",
              "        -5.48113883e-02,  4.65926453e-02, -1.76091902e-02, -3.84368002e-02,\n",
              "        -4.29712748e-03,  9.64440703e-02,  4.08758968e-02,  1.46479411e-02,\n",
              "        -2.71059331e-02, -7.90129509e-03, -6.04164880e-03,  5.26848920e-02,\n",
              "         6.27018437e-02,  7.18532354e-02,  6.79200292e-02,  1.35412831e-02,\n",
              "         3.34797986e-02,  3.79706696e-02, -7.72575475e-03, -4.46621627e-02,\n",
              "         5.41849434e-02, -1.92723814e-02, -2.24041864e-02,  7.23760054e-02,\n",
              "        -1.04904911e-02, -1.09786186e-02,  7.49068037e-02, -9.27445292e-02,\n",
              "         4.68052551e-02,  2.24725585e-02, -2.79723816e-02, -1.36490853e-03,\n",
              "        -4.10933085e-02,  7.32660964e-02, -6.22072257e-03, -2.33660936e-02,\n",
              "        -1.91903412e-02, -2.94097792e-02, -1.48152253e-02, -2.15086667e-03,\n",
              "         1.45440977e-02,  1.76225286e-02,  1.03524052e-01,  5.43345474e-02,\n",
              "         4.01612557e-02, -2.57119834e-02, -6.80642053e-02,  5.24903461e-02,\n",
              "        -2.15624850e-02, -1.04389591e-02, -2.51806639e-02, -2.07493827e-03,\n",
              "         7.11814407e-03,  6.84395656e-02, -4.73077670e-02,  2.36725397e-02,\n",
              "        -2.69492455e-02, -5.92076182e-02, -4.49810363e-02, -1.03155458e-02],      dtype=float32),\n",
              " 'Bhl': Array([-0.0518325 , -0.00254878, -0.0104192 ,  0.00290345,  0.03380278,\n",
              "        -0.07728022,  0.06602838,  0.0519497 , -0.00694344,  0.03123034,\n",
              "        -0.0260879 , -0.02288022,  0.04282226,  0.05041742,  0.00482851,\n",
              "        -0.0007245 ,  0.01288415, -0.01703883,  0.00102344,  0.01068917,\n",
              "         0.00164293, -0.0612621 , -0.02854194,  0.01599333, -0.03260069,\n",
              "         0.04784553, -0.02552552, -0.04548349, -0.01726608,  0.01406777,\n",
              "         0.06478434, -0.00776864,  0.05273855, -0.00017602, -0.04683848,\n",
              "        -0.01320011,  0.0420268 ,  0.03941067,  0.07082711, -0.00902095,\n",
              "        -0.04301713, -0.05540396, -0.03088783,  0.02082137, -0.10903653,\n",
              "        -0.03668   , -0.01065544, -0.0262638 , -0.0180013 , -0.03424142,\n",
              "         0.01541103,  0.01482391, -0.00045982, -0.05648725,  0.02928194,\n",
              "        -0.04461947, -0.08320812,  0.01223897, -0.00795621,  0.09202816,\n",
              "         0.01694497,  0.03327333,  0.02254561,  0.02347161, -0.01079851,\n",
              "         0.0138308 ,  0.06000178,  0.04269929,  0.00702483,  0.05198384,\n",
              "         0.09979893,  0.01740189, -0.03338584, -0.03689279,  0.01589393,\n",
              "        -0.00281737, -0.01554822, -0.01483685,  0.01590321,  0.0305568 ,\n",
              "         0.05560309, -0.02700646, -0.02642407, -0.08043755,  0.04668214,\n",
              "         0.00625457, -0.06744075, -0.03321096,  0.02013169,  0.02437229,\n",
              "        -0.00655976, -0.02946083,  0.03509317, -0.05673237, -0.00202473,\n",
              "        -0.00411046, -0.01702703, -0.00048535, -0.0134147 ,  0.0390972 ,\n",
              "         0.02692388, -0.05718365,  0.0521197 , -0.02838977, -0.05014243,\n",
              "         0.00512917,  0.00304362,  0.01723856,  0.05818371, -0.06758609,\n",
              "         0.03621269, -0.05252076,  0.05755156,  0.06234151,  0.0556059 ,\n",
              "         0.06019701, -0.00993584, -0.04720629,  0.06103025, -0.00318214,\n",
              "         0.00884857, -0.02285421, -0.0600213 ,  0.02353044, -0.00610867,\n",
              "         0.02798011,  0.0298463 ,  0.07438631,  0.00987459,  0.02578574,\n",
              "        -0.03945987, -0.03701958,  0.00902119,  0.07555754, -0.01247113,\n",
              "        -0.06722646, -0.0050953 , -0.03543191,  0.00527044,  0.00881342,\n",
              "         0.03792771, -0.04106668, -0.00916556, -0.09713601, -0.01699751,\n",
              "         0.04162435,  0.10146377,  0.03422358,  0.00389461, -0.03969918,\n",
              "        -0.02500683,  0.05668303,  0.00354911,  0.01621129, -0.01508478,\n",
              "         0.11713544,  0.07179195, -0.0847074 , -0.01968857, -0.00500182,\n",
              "         0.02394298, -0.08719506,  0.04790341,  0.01863015,  0.04844956,\n",
              "         0.02745618,  0.00020621,  0.09198512,  0.01645834,  0.03858338,\n",
              "         0.00773858,  0.10330337,  0.05925074, -0.07292689,  0.11022887,\n",
              "        -0.00280139, -0.01964178, -0.01034568,  0.05771279, -0.01575956,\n",
              "         0.04970049, -0.01619658, -0.06152386, -0.01336133, -0.04014363,\n",
              "        -0.01118911,  0.00885691,  0.00033973, -0.07264281,  0.02308457,\n",
              "         0.09218361, -0.00538531,  0.03170103, -0.03500854, -0.03698253,\n",
              "         0.0221051 , -0.05954282,  0.01013709, -0.01663374, -0.08213972,\n",
              "         0.00646995,  0.00616762,  0.07500676, -0.01465069, -0.02934642,\n",
              "        -0.03489095, -0.07669857,  0.0247033 ,  0.0378072 , -0.00235079,\n",
              "        -0.00253978,  0.02454866, -0.07812435, -0.02703169, -0.00019795,\n",
              "         0.06083044, -0.01795566, -0.02803496, -0.04426189,  0.03027996,\n",
              "        -0.02974015, -0.0044833 ,  0.07209554, -0.04799774, -0.03032646,\n",
              "         0.04624216, -0.00307532, -0.08460782, -0.03275658,  0.02642211,\n",
              "         0.04268946, -0.05253989, -0.06717444, -0.00921802,  0.01830721,\n",
              "         0.02186476, -0.07135721, -0.11460871, -0.0418908 ,  0.02573875,\n",
              "         0.03504452,  0.00517309,  0.00359629,  0.04513341,  0.05104662,\n",
              "        -0.05832529,  0.05140006,  0.04619038, -0.07680458, -0.08273077,\n",
              "        -0.0892226 , -0.01774029,  0.05803801,  0.01824515, -0.01583989,\n",
              "        -0.02439426,  0.03705959,  0.02014714, -0.05594678, -0.00775293,\n",
              "         0.11546259,  0.04462969, -0.00687409,  0.02580671,  0.04862085,\n",
              "        -0.05255651, -0.0360481 , -0.05917649, -0.0166816 , -0.06516846,\n",
              "         0.04380196, -0.04690381,  0.04895914,  0.05718977, -0.00698372,\n",
              "         0.0373374 ,  0.01430776, -0.04431244,  0.00557127,  0.05621159,\n",
              "         0.0042245 ,  0.00249004, -0.07899639, -0.02150529, -0.04159643,\n",
              "         0.04141002, -0.0284905 , -0.00241309, -0.03159411, -0.04501989,\n",
              "         0.02837892, -0.05547638, -0.02206125,  0.01353562, -0.01698052,\n",
              "         0.02887083, -0.0546227 ,  0.01275313, -0.08148243,  0.03449973,\n",
              "         0.02816222,  0.02690555,  0.03889835, -0.00697174, -0.05161652,\n",
              "        -0.00365086,  0.00631077, -0.02598705, -0.02690941,  0.03986994,\n",
              "         0.01602162, -0.03052025, -0.01441792,  0.01856655,  0.11315178,\n",
              "        -0.03550959, -0.00626296, -0.01005926,  0.0846632 ,  0.00033258,\n",
              "         0.03639432,  0.00828089,  0.01866023,  0.04715814,  0.04363605,\n",
              "        -0.00831811,  0.0012298 , -0.06507451, -0.00652389, -0.09040035,\n",
              "        -0.07400296, -0.0777098 , -0.02433891,  0.01859559, -0.06961213,\n",
              "        -0.01886361, -0.01912354,  0.02647766,  0.05897576, -0.00182572,\n",
              "        -0.08432746, -0.07633943,  0.0117363 ,  0.04001156, -0.01303746,\n",
              "         0.01098076, -0.00582367,  0.03233374, -0.0112619 ,  0.02990957,\n",
              "        -0.03653122,  0.03349793,  0.00135104,  0.05334957, -0.02309985,\n",
              "        -0.06089237,  0.01573568, -0.08389109, -0.01670461,  0.00564116,\n",
              "        -0.05396303, -0.02326048,  0.01431081, -0.00876708, -0.07946078,\n",
              "        -0.00727166, -0.03817729,  0.00035125, -0.12114157,  0.00561495,\n",
              "        -0.00657288,  0.02561884, -0.02999984,  0.06871483, -0.01875656,\n",
              "         0.01825721,  0.03462421,  0.00753878, -0.01689852, -0.04436203,\n",
              "         0.00228256, -0.02548134,  0.04197438,  0.04409524, -0.06823956,\n",
              "         0.02262932,  0.06923169,  0.01576777,  0.0297066 , -0.04324843,\n",
              "        -0.01901739, -0.09386793, -0.03808882, -0.04466388, -0.02375219,\n",
              "         0.02712762,  0.01514534,  0.02378408, -0.02520496,  0.03616262,\n",
              "         0.09780171, -0.01312613, -0.01736161,  0.05395175,  0.01541215,\n",
              "        -0.02901052,  0.04226497, -0.02637101,  0.04405002,  0.02148833,\n",
              "         0.08812409, -0.02728301, -0.00069179,  0.00088199, -0.03159713,\n",
              "         0.01013293,  0.10315412, -0.00559783,  0.01559759, -0.01841203,\n",
              "         0.02375126, -0.02657038,  0.0526282 ,  0.02208713, -0.1345214 ,\n",
              "        -0.04511675, -0.06956273, -0.04395   , -0.00768096, -0.06416101,\n",
              "        -0.02200038,  0.05355143, -0.03430096, -0.00865219,  0.01959111,\n",
              "        -0.09129328,  0.04423863,  0.02024395,  0.05667822,  0.01107978,\n",
              "         0.00133243,  0.02198769,  0.01050934,  0.07814097,  0.01453567,\n",
              "        -0.01333362,  0.02794276,  0.06910843,  0.05767372,  0.05614064,\n",
              "        -0.03652586,  0.01104563,  0.07958172,  0.06272031,  0.10246705,\n",
              "        -0.01761713,  0.01186202, -0.01426443,  0.00393177,  0.04067726,\n",
              "         0.02295084,  0.03413615,  0.06045344, -0.00595559, -0.03616172,\n",
              "        -0.04984902,  0.00671824,  0.00818349, -0.06194729, -0.03399161,\n",
              "        -0.03938879,  0.02328908,  0.00225629, -0.00439162,  0.03084596,\n",
              "        -0.04862726, -0.01450708,  0.00446673, -0.07389949,  0.06198515,\n",
              "        -0.03943244, -0.00936532, -0.04870751, -0.01153176,  0.00684314,\n",
              "        -0.0605125 ,  0.02091948,  0.01856966,  0.00038473, -0.00929483,\n",
              "        -0.05778235,  0.00549572, -0.00939232, -0.00381972,  0.01698944,\n",
              "         0.04689822, -0.07742695,  0.03838415, -0.03342392,  0.00628618],      dtype=float32),\n",
              " 'Bho': Array([-2.58616544e-02, -1.16807505e-01, -2.14246493e-02,  6.97630048e-02,\n",
              "        -1.84232555e-02, -4.08797413e-02,  5.79380877e-02,  4.72385399e-02,\n",
              "         2.91978456e-02,  1.15808202e-02, -7.71845728e-02, -3.28244194e-02,\n",
              "         4.36532684e-02, -1.48192272e-02,  2.24132836e-02, -9.04172584e-02,\n",
              "        -4.46046181e-02,  2.94575468e-02,  1.06974347e-02,  3.48882005e-02,\n",
              "        -1.60763192e-03, -4.07707021e-02,  6.07943423e-02,  7.74403289e-03,\n",
              "         1.25921695e-02,  6.34282231e-02, -6.12031445e-02,  1.44432141e-02,\n",
              "         4.99340193e-03,  3.08223087e-02,  3.13512795e-02,  9.45909396e-02,\n",
              "         3.54993008e-02, -1.39296688e-02,  7.46001825e-02, -3.65680293e-03,\n",
              "         1.10997641e-02, -4.80207503e-02,  2.07440201e-02, -1.88493878e-02,\n",
              "         3.73085425e-03, -2.92808060e-02, -1.89079978e-02,  8.45237635e-03,\n",
              "        -5.08555099e-02,  6.50289729e-02, -2.50410177e-02, -9.88361612e-03,\n",
              "         4.06134836e-02,  4.79714870e-02,  5.16235977e-02, -6.48802519e-02,\n",
              "         1.28307380e-02,  2.18507294e-02,  1.00869566e-01,  2.36692801e-02,\n",
              "        -5.76225296e-02, -4.91837636e-02,  5.64483851e-02,  6.50075683e-03,\n",
              "         3.22488323e-02,  1.85212642e-02,  5.04775671e-03, -9.06395912e-02,\n",
              "        -2.92600878e-03,  1.66188441e-02,  4.23781611e-02, -4.46821675e-02,\n",
              "         8.56117904e-02,  4.20127288e-02,  1.99818909e-02, -4.35076915e-02,\n",
              "         4.69096154e-02, -2.39513516e-02,  5.67265507e-03,  9.48178843e-02,\n",
              "        -4.84409854e-02, -3.80926579e-02, -2.62413044e-02, -1.73459214e-03,\n",
              "        -3.27002853e-02,  4.04824503e-02,  4.31990437e-02, -1.71611011e-02,\n",
              "        -2.26238780e-02,  3.63797590e-04, -3.25393192e-02,  2.87886541e-02,\n",
              "         6.22272789e-02,  2.78899465e-02,  8.07414204e-02, -6.52859062e-02,\n",
              "        -4.68176976e-02,  1.93544794e-02, -7.62939081e-02, -6.23281971e-02,\n",
              "         1.50973434e-02,  7.34649459e-03, -1.58935934e-02, -1.80495903e-02,\n",
              "         3.31652649e-02, -1.60196740e-02,  2.43302099e-02, -1.83828808e-02,\n",
              "        -4.34593968e-02,  7.33103752e-02,  1.31004313e-02,  7.25530903e-04,\n",
              "         2.90667173e-02,  2.76363045e-02,  7.48368502e-02, -9.81442854e-02,\n",
              "        -2.75934767e-02,  2.50884797e-02, -3.05459127e-02,  2.60192920e-02,\n",
              "         2.89241131e-02,  5.18882722e-02, -1.76771693e-02,  4.35150005e-02,\n",
              "         6.30928874e-02,  3.37140472e-03,  3.61611210e-02,  7.59583339e-02,\n",
              "        -6.76569063e-03,  6.70858622e-02,  7.55415931e-02, -5.43310121e-02,\n",
              "         1.91349275e-02, -6.31981343e-02,  5.30369915e-02, -1.06893694e-02,\n",
              "        -1.08488621e-02, -8.97977054e-02, -1.01571411e-01, -3.37441042e-02,\n",
              "        -4.27109078e-02,  3.73175927e-02, -3.56560647e-02,  4.08230834e-02,\n",
              "        -1.69506595e-02,  1.11221606e-02,  2.57492415e-03, -3.06149740e-02,\n",
              "         4.09739651e-03,  3.66904475e-02, -7.70919351e-03, -1.25464899e-02,\n",
              "        -2.53038555e-02, -5.88560142e-02,  5.11145331e-02,  4.06968594e-03,\n",
              "         3.29994485e-02,  3.70816491e-03,  9.11014993e-03, -2.54398007e-02,\n",
              "         4.54825088e-02, -5.99261895e-02, -4.53196699e-03, -1.23017905e-02,\n",
              "        -2.80256271e-02,  3.84520628e-02, -8.93582217e-03, -1.66618917e-03,\n",
              "        -2.66804988e-03,  1.91665422e-02,  5.56405038e-02, -4.72468585e-02,\n",
              "         4.92543690e-02,  7.18732039e-03, -2.94178743e-02, -4.09792848e-02,\n",
              "         2.40115672e-02,  5.78174926e-02, -9.87737160e-03,  2.34808517e-03,\n",
              "         1.06350712e-01, -6.84012175e-02, -9.73474309e-02, -7.26660565e-02,\n",
              "         6.74241558e-02,  6.03521541e-02,  1.19872214e-02, -1.42156975e-02,\n",
              "        -2.74152644e-02, -4.48186807e-02, -7.56754950e-02, -4.07873914e-02,\n",
              "         3.54773225e-03, -3.86986881e-02, -6.38418272e-02,  6.26370823e-03,\n",
              "         2.76028458e-02,  9.45715047e-03, -2.46051326e-02, -5.76262549e-02,\n",
              "        -3.18366960e-02, -9.10382867e-02, -4.05511595e-02,  3.29190791e-02,\n",
              "         2.28196029e-02,  8.04981962e-03,  7.17801675e-02,  7.84397647e-02,\n",
              "         3.39372531e-02, -2.42723264e-02,  7.79952779e-02,  1.24308513e-02,\n",
              "         2.12250440e-03,  2.66529396e-02, -3.92205007e-02, -1.02357089e-03,\n",
              "         2.72428654e-02,  1.94478855e-02,  4.07882333e-02,  3.14383619e-02,\n",
              "        -1.39080989e-03,  1.51541699e-02, -5.17482832e-02, -3.77659798e-02,\n",
              "         6.66757375e-02, -1.38547985e-04, -7.97575805e-03,  6.67687356e-02,\n",
              "         5.63993156e-02, -1.12338774e-01, -4.22784500e-03, -7.32564274e-03,\n",
              "         1.49182510e-02,  1.04987398e-01, -6.10766783e-02, -4.11027670e-02,\n",
              "        -5.82511686e-02, -1.02519738e-02,  8.12134221e-02, -8.54307264e-02,\n",
              "        -2.15614829e-02,  4.96134646e-02,  2.44272081e-03,  5.96749177e-03,\n",
              "        -2.54896991e-02,  4.37150262e-02, -4.25095782e-02,  9.04723071e-04,\n",
              "         6.37417585e-02,  2.83698514e-02,  4.03286563e-03, -2.31215525e-02,\n",
              "        -4.54339348e-02,  8.83190259e-02, -4.91063185e-02, -5.40569378e-03,\n",
              "         3.62185948e-02, -3.77516858e-02,  2.51092035e-02, -1.83463879e-02,\n",
              "        -9.61656682e-04,  4.51591685e-02, -5.15406504e-02, -4.85253371e-02,\n",
              "         1.67428367e-02,  1.80024188e-02,  4.60820785e-03,  1.90800615e-02,\n",
              "        -5.89914061e-02, -8.33533611e-03,  9.45586786e-02, -2.73033101e-02,\n",
              "         1.35781365e-02,  9.32096411e-03,  9.11808852e-03,  7.07371011e-02,\n",
              "         7.76679604e-04,  2.32763495e-02,  1.65626705e-02, -1.01336138e-02,\n",
              "         7.33763725e-02,  2.34046131e-02,  1.07229449e-01,  5.05773649e-02,\n",
              "         1.81641858e-02,  2.41139177e-02,  1.91268809e-02,  2.79766682e-04,\n",
              "         3.84230241e-02,  1.07169487e-02, -1.02796957e-01, -5.31013720e-02,\n",
              "         1.42118618e-01,  2.73211114e-02, -4.82740067e-03, -3.85378636e-02,\n",
              "         5.46128266e-02, -1.27288356e-01, -7.39703625e-02, -6.63028006e-03,\n",
              "        -4.98011010e-03,  3.14733386e-02, -9.25748888e-03, -4.02642749e-02,\n",
              "        -4.29459708e-03,  4.70362380e-02, -4.21672463e-02, -2.84509435e-02,\n",
              "        -9.71831232e-02,  4.09969054e-02, -3.42335962e-02, -2.83375103e-02,\n",
              "         3.82049344e-02,  4.13688645e-02, -4.19367366e-02,  1.43640991e-02,\n",
              "        -2.62221321e-02, -7.45653117e-04,  2.42362525e-02,  1.97759341e-03,\n",
              "         1.40544502e-02, -1.05899796e-02, -5.94361946e-02,  1.61067341e-02,\n",
              "        -1.50563745e-02,  4.28576255e-03,  4.53755893e-02,  9.85132996e-04,\n",
              "         7.52774775e-02,  5.48103899e-02,  3.91704962e-02,  1.31156705e-02,\n",
              "        -6.66022161e-03,  3.28941494e-02,  4.09506857e-02, -1.33575741e-02,\n",
              "        -1.09295556e-02,  8.70645642e-02,  1.14711458e-02, -2.38494296e-02,\n",
              "         1.66654754e-02, -7.81388301e-03,  3.24560069e-02,  1.07613660e-03,\n",
              "        -8.55439715e-03, -6.93925247e-02, -2.53205709e-02,  6.10586740e-02,\n",
              "        -3.34782526e-02,  2.48144120e-02,  2.90260855e-02, -4.90806997e-03,\n",
              "         4.61646579e-02, -5.66161200e-02,  7.85711035e-03,  7.35223070e-02,\n",
              "         2.70930659e-02, -6.65454566e-02, -4.70556319e-02,  3.48671563e-02,\n",
              "         2.54421663e-02, -6.92781946e-03, -5.66215487e-03, -2.29065139e-02,\n",
              "        -2.34539788e-02, -3.20525803e-02,  2.38123648e-02,  4.15953174e-02,\n",
              "         7.33436197e-02,  2.41841115e-02,  3.21292575e-03,  2.00476148e-03,\n",
              "         9.26884189e-02,  2.27359924e-02, -4.72350642e-02, -5.29507957e-02,\n",
              "        -5.07134106e-03,  5.44366054e-02, -4.39438708e-02,  1.26274694e-02,\n",
              "         1.12477705e-01, -2.42606495e-02, -2.41329856e-02,  2.32428163e-02,\n",
              "        -3.53112854e-02,  4.37396765e-02,  6.42298087e-02, -1.00532975e-02,\n",
              "        -2.75455303e-02,  4.47689965e-02, -8.30168463e-03, -2.95365416e-02,\n",
              "        -2.99301650e-02, -1.43054863e-02, -3.42128575e-02, -4.64759395e-02,\n",
              "         3.27889062e-02,  2.98631061e-02,  1.71805564e-02, -2.63421554e-02,\n",
              "         4.91027981e-02,  1.81570314e-02, -2.24663713e-03,  2.72050556e-02,\n",
              "         5.29721938e-02, -1.16276175e-01, -3.49441282e-02,  5.52341938e-02,\n",
              "        -2.99491156e-02,  1.43813749e-03, -1.21309301e-02,  3.91328819e-02,\n",
              "        -1.98080745e-02,  9.61216632e-03, -4.04529385e-02,  4.02538441e-02,\n",
              "         3.30530889e-02, -6.94599003e-02,  2.13117898e-02, -1.93411596e-02,\n",
              "        -9.32908151e-03,  7.70401955e-03, -2.10446063e-02, -9.03090015e-02,\n",
              "         5.13128489e-02,  2.86033358e-02,  5.30535914e-03, -5.34542836e-03,\n",
              "         4.96982923e-03, -2.01682281e-02,  6.20927736e-02, -9.75685194e-03,\n",
              "         8.72851443e-03,  6.29751533e-02,  2.67857499e-03, -4.05986384e-02,\n",
              "         9.19984840e-03,  5.51973321e-02,  1.03035159e-02,  1.01775005e-02,\n",
              "         3.86382006e-02,  3.83121781e-02,  2.80648991e-02,  8.67541414e-03,\n",
              "        -6.39930591e-02,  3.01072225e-02, -9.37336311e-03, -7.32789636e-02,\n",
              "         3.31285559e-02,  3.77780409e-03, -6.18404932e-02, -2.39699706e-02,\n",
              "        -8.20930600e-02,  3.64378057e-02, -3.14629031e-03, -2.78130285e-02,\n",
              "         5.30414693e-02, -8.95373523e-02, -1.63839497e-02, -8.60610697e-03,\n",
              "         1.21215452e-02, -6.13620330e-04, -3.42946150e-03,  7.94143304e-02,\n",
              "         3.59998792e-02, -2.66002808e-02,  4.22724262e-02,  5.63120171e-02,\n",
              "         3.36016691e-03, -3.62778567e-02, -3.21908779e-02, -4.11133096e-02,\n",
              "         4.44237851e-02, -7.24159554e-02, -7.29061514e-02,  2.12129857e-02,\n",
              "         5.27335843e-03,  1.32052116e-02, -3.73991951e-02, -1.63939036e-02,\n",
              "        -3.69229494e-03, -5.22296652e-02, -1.70452204e-02, -6.99635735e-03,\n",
              "         6.94039091e-03,  9.92903579e-03, -5.93761355e-02, -3.27442773e-02,\n",
              "        -2.95966212e-02,  1.32264569e-03, -2.64889579e-02, -7.05415830e-02,\n",
              "         5.36837466e-02,  6.65381923e-02,  1.24145886e-02, -2.37656198e-02,\n",
              "        -1.47171849e-02,  4.84863110e-03,  3.90020828e-03,  3.77114341e-02,\n",
              "        -2.97788829e-02,  4.99458201e-02,  5.59177995e-03, -4.85319309e-02],      dtype=float32),\n",
              " 'Bo': Array([3.53165  , 3.2140222], dtype=float32),\n",
              " 'Bxf': Array([ 1.65688545e-02, -2.06920635e-02, -5.75393401e-02,  6.39427453e-02,\n",
              "        -2.95940042e-02, -3.73975933e-02, -7.27796108e-02, -2.63257865e-02,\n",
              "         1.19028604e-02,  6.02308707e-03,  6.83320090e-02, -1.13525416e-03,\n",
              "         4.44831811e-02, -1.50118470e-02, -3.31046246e-02, -3.65414061e-02,\n",
              "         6.96633235e-02, -3.12777944e-02, -7.27319345e-02, -4.66371290e-02,\n",
              "         1.12805031e-02,  2.62473579e-02, -3.61787751e-02, -3.82668078e-02,\n",
              "        -5.85253686e-02,  7.90328439e-03, -1.13828313e-02,  3.84865999e-02,\n",
              "        -4.19864878e-02, -5.76509126e-02,  7.84898177e-03, -7.15534836e-02,\n",
              "         3.52910794e-02,  2.95335911e-02,  3.30663659e-02,  5.33938296e-02,\n",
              "         2.65726689e-02,  2.11726483e-02,  9.72100049e-02, -2.23376555e-03,\n",
              "         1.03969802e-03, -4.65558581e-02,  3.61983813e-02, -5.35674728e-02,\n",
              "         1.32327387e-03, -3.75969894e-02,  1.09820133e-02,  7.42055550e-02,\n",
              "         3.22625227e-02,  3.04760318e-03,  9.21957940e-02, -1.58506026e-03,\n",
              "        -1.72699112e-02,  6.76133845e-04,  3.14720697e-03,  2.42980774e-02,\n",
              "        -3.79929729e-02,  4.89283688e-02,  1.82214975e-02,  6.21711370e-03,\n",
              "         2.94941608e-02, -1.33996538e-03,  7.80054089e-03,  1.42645016e-02,\n",
              "         1.40420813e-02, -7.91135337e-03,  6.96961135e-02,  9.11271349e-02,\n",
              "         1.12889167e-02,  3.00943162e-02,  1.72019657e-02,  5.10284770e-03,\n",
              "         2.63183694e-02,  2.72077564e-02,  3.95045094e-02,  1.30815580e-01,\n",
              "        -2.02382263e-02, -1.24671003e-02,  5.44354180e-03,  1.36244390e-02,\n",
              "         8.29662755e-02, -5.15846871e-02,  5.67989796e-02,  5.30213118e-02,\n",
              "         4.88819852e-02, -3.40632610e-02, -2.82833651e-02, -1.29682012e-02,\n",
              "         4.56841178e-02,  2.54965127e-02,  3.89902331e-02, -1.62973832e-02,\n",
              "        -6.11289181e-02,  2.55872179e-02, -5.33200838e-02,  2.44531017e-02,\n",
              "        -3.58338654e-02, -1.04165062e-01,  1.29490541e-02, -3.37027423e-02,\n",
              "        -2.73489561e-02,  1.94857903e-02, -5.61601110e-02, -1.49150938e-02,\n",
              "         2.31908709e-02, -5.54990582e-02, -4.61958498e-02, -1.74498372e-02,\n",
              "        -8.28653127e-02, -1.68069024e-02,  1.01950923e-02, -6.17894381e-02,\n",
              "         9.36091691e-02,  2.22515073e-02,  3.25613730e-02, -7.85509497e-03,\n",
              "         1.50816282e-02, -6.58968538e-02, -3.50762568e-02,  6.40081689e-02,\n",
              "         4.78135273e-02,  2.43711062e-02,  4.76001715e-03, -1.84776802e-02,\n",
              "        -3.39778960e-02,  3.07938438e-02, -4.77143767e-04,  1.57228168e-02,\n",
              "        -5.39955609e-02, -1.57700852e-02,  3.38172391e-02,  3.94793078e-02,\n",
              "        -8.07458237e-02, -2.31776922e-03, -1.79573968e-02,  4.03255448e-02,\n",
              "        -3.75257321e-02, -4.03004773e-02, -2.19267476e-02, -1.70553811e-02,\n",
              "        -2.24752985e-02, -4.13453020e-02, -4.24209014e-02,  1.12887025e-01,\n",
              "        -6.44985363e-02,  4.51673381e-02, -8.78088549e-02, -4.75751869e-02,\n",
              "        -1.90555714e-02, -2.08426509e-02, -8.85049477e-02, -1.21454649e-01,\n",
              "        -1.43587738e-02, -4.48699109e-02,  4.94144559e-02, -1.63577672e-04,\n",
              "         2.43389141e-02,  1.18601499e-02, -4.06805165e-02,  7.54495636e-02,\n",
              "         5.66330776e-02,  5.91278896e-02, -1.62028074e-02,  4.43760753e-02,\n",
              "        -1.79965561e-03, -2.41826233e-02,  4.01084833e-02,  1.76252574e-02,\n",
              "        -1.78131962e-03, -3.29100080e-02,  6.97113620e-03, -2.07110122e-02,\n",
              "         2.88824178e-02, -4.43196669e-02, -5.90183958e-02, -3.99783179e-02,\n",
              "         2.03383639e-02,  5.76498508e-02,  6.92310259e-02,  4.01122533e-02,\n",
              "        -8.84659216e-03, -2.07954999e-02, -2.13688128e-02,  5.13172634e-02,\n",
              "         4.18089591e-02,  3.43125425e-02, -5.11529334e-02, -1.73124783e-02,\n",
              "         3.38973105e-02, -8.75437707e-02, -3.47245112e-02,  8.16232786e-02,\n",
              "         4.48244363e-02, -2.72300541e-02,  6.90606087e-02,  3.50518078e-02,\n",
              "         1.26535743e-02,  9.39013250e-03, -2.57318560e-02, -7.48937428e-02,\n",
              "        -8.11475292e-02, -1.63201038e-02,  5.35749719e-02, -2.29241587e-02,\n",
              "        -5.40260077e-02,  2.81932037e-02,  7.69408569e-02, -4.67450805e-02,\n",
              "        -6.08385913e-02,  5.88589832e-02, -2.07471829e-02,  1.56861637e-02,\n",
              "        -4.40091789e-02, -2.69786268e-02, -1.78988781e-02,  4.46010232e-02,\n",
              "         1.24273654e-02, -1.93347670e-02,  4.92645167e-02,  3.07959486e-02,\n",
              "        -4.09618951e-02, -1.03049772e-02, -6.67088255e-02,  1.83512215e-02,\n",
              "        -5.43135172e-03,  6.28023073e-02, -4.09175232e-02,  1.91230308e-02,\n",
              "         1.31394798e-02, -4.76466194e-02,  1.17471004e-02,  4.09320965e-02,\n",
              "         7.91434664e-03,  9.57151875e-02, -1.60605758e-02,  2.12324895e-02,\n",
              "         2.78283451e-02, -3.67928185e-02,  4.96849827e-02,  4.70697647e-03,\n",
              "        -1.10427707e-01,  5.26659302e-02, -2.98820939e-02, -4.14623506e-02,\n",
              "         1.01699699e-02,  9.66090858e-02, -2.40523033e-02, -4.74956967e-02,\n",
              "        -2.07632557e-02,  5.04916832e-02,  2.78463811e-02,  4.57541551e-03,\n",
              "         2.45309696e-02, -5.22217080e-02, -2.61271484e-02,  7.58858994e-02,\n",
              "         8.86143744e-02,  2.82085761e-02,  8.05970654e-02, -3.39889005e-02,\n",
              "         3.29732075e-02, -6.23228513e-02,  4.01675329e-02, -3.20349075e-02,\n",
              "        -1.75060183e-02, -8.40947730e-04,  5.37745981e-03,  3.79395224e-02,\n",
              "         1.66327879e-02,  2.62340754e-02,  8.78512335e-04, -5.34640625e-02,\n",
              "         2.07426678e-02,  7.34980106e-02, -5.42280450e-02,  6.39775246e-02,\n",
              "        -7.40370303e-02,  1.08183883e-02, -4.05959450e-02,  2.20078658e-02,\n",
              "         6.28267080e-02,  8.76456127e-03, -9.74216983e-02,  1.89292673e-02,\n",
              "         3.38739972e-03, -4.17757407e-02, -4.04444113e-02, -3.87802836e-03,\n",
              "        -2.88099349e-02, -5.84053658e-02, -1.21086463e-02,  1.43854897e-02,\n",
              "        -5.10136597e-02,  8.49418715e-03,  1.82689298e-02, -7.86923710e-03,\n",
              "        -7.68260732e-02, -5.96916750e-02, -3.01475916e-02,  3.50620747e-02,\n",
              "        -1.40306624e-02, -5.09561785e-03,  4.60957251e-02,  5.22247888e-02,\n",
              "         8.46600085e-02, -1.39985615e-02,  2.47060414e-03, -2.19754353e-02,\n",
              "         4.06356826e-02, -1.10455919e-02, -4.75344025e-02, -1.28211379e-02,\n",
              "        -3.05033829e-02, -3.42229567e-02,  3.92963216e-02, -2.56058313e-02,\n",
              "        -6.54196590e-02,  3.10697984e-02,  5.88291325e-02, -3.82410474e-02,\n",
              "         6.80890167e-03,  3.21406759e-02,  4.17119591e-03, -2.57724617e-03,\n",
              "         7.13613853e-02, -6.41338388e-03, -6.46417262e-04,  1.73050966e-02,\n",
              "        -2.47310083e-02, -3.92523147e-02,  1.87213141e-02, -1.76426803e-03,\n",
              "         3.25103803e-03, -4.57406882e-03,  3.04396953e-02,  3.00343484e-02,\n",
              "         8.03882536e-03,  2.63218973e-02,  4.18464206e-02,  3.33880610e-03,\n",
              "        -2.13551838e-02, -7.80967101e-02, -2.04202559e-04, -3.12196231e-03,\n",
              "        -2.67437994e-02, -3.70123945e-02, -6.43707812e-02,  5.08946963e-02,\n",
              "         2.68461095e-04, -1.76630821e-02,  6.14297949e-02, -4.17318344e-02,\n",
              "        -3.93724293e-02, -1.17386440e-02, -3.92667726e-02, -6.23194613e-02,\n",
              "        -1.66460592e-02, -1.71101274e-04, -2.91277692e-02, -4.39627916e-02,\n",
              "         9.01878532e-03, -1.99189708e-02, -8.22717033e-04,  8.90935585e-03,\n",
              "        -7.75733544e-03,  2.91783977e-02, -5.24596609e-02, -3.41006704e-02,\n",
              "         4.44747657e-02, -4.30490077e-03, -6.04992434e-02, -2.15011761e-02,\n",
              "        -2.92591676e-02, -2.25619636e-02, -6.77096024e-02,  5.62717877e-02,\n",
              "        -3.42270024e-02, -4.36967649e-02, -2.00628638e-02, -5.80905229e-02,\n",
              "         7.10768020e-03, -3.23437713e-03, -4.32595648e-02,  4.79159355e-02,\n",
              "        -2.95418762e-02, -5.22098504e-02,  3.80949900e-02, -4.35600467e-02,\n",
              "         2.47353315e-02, -2.35297624e-02,  2.86063217e-02,  5.39084226e-02,\n",
              "        -7.32591674e-02,  4.21649689e-04,  6.59148842e-02, -5.88237830e-02,\n",
              "        -2.03146832e-03, -1.38659845e-03, -9.15904250e-03, -1.49358995e-04,\n",
              "         3.90108004e-02, -1.45194782e-02,  7.83298165e-03,  2.50424799e-02,\n",
              "        -8.52375850e-02, -3.34560424e-02, -5.75345419e-02,  2.57863756e-02,\n",
              "         6.93284944e-02,  4.95666079e-02,  8.16869661e-02, -6.75679296e-02,\n",
              "         1.43495370e-02,  9.74325463e-03,  1.22562923e-01, -5.33431284e-02,\n",
              "         4.82760146e-02,  1.55643463e-01,  4.72908877e-02, -3.86153869e-02,\n",
              "        -1.90382861e-02,  9.75395646e-03,  3.00453673e-03,  5.70150316e-02,\n",
              "        -6.77460134e-02, -5.84040768e-02,  4.22811359e-02,  2.33443007e-02,\n",
              "         7.91797705e-04, -7.23942965e-02, -2.73235012e-02,  2.34939102e-02,\n",
              "        -3.24982568e-03,  1.27057713e-02,  1.36996359e-01,  2.21958980e-02,\n",
              "         1.44002680e-02, -2.53458638e-02,  2.78550442e-02, -2.45845187e-02,\n",
              "        -5.94611801e-02, -1.32263117e-02,  4.88089547e-02,  2.68316846e-02,\n",
              "        -6.03497354e-03, -2.15021204e-02, -5.21902256e-02,  5.60386814e-02,\n",
              "        -4.25154604e-02, -4.18694802e-02,  7.65640810e-02, -4.17634333e-03,\n",
              "        -1.00126438e-01,  2.17810497e-02, -1.16651291e-02,  6.20362349e-02,\n",
              "         3.69261242e-02,  4.62830216e-02,  2.77866423e-02,  6.78768307e-02,\n",
              "         3.68223786e-02, -9.32536740e-03, -4.40410301e-02,  4.27869372e-02,\n",
              "        -2.67234612e-02,  4.12085988e-02, -5.63183287e-03, -5.95168173e-02,\n",
              "         6.54643343e-04, -3.70584503e-02,  5.23372106e-02, -1.48472050e-02,\n",
              "        -2.62429398e-02, -3.92995514e-02, -9.43799154e-04,  7.51956739e-03,\n",
              "         5.45337573e-02, -2.30965819e-02, -4.37024496e-02,  3.25621404e-02,\n",
              "        -5.15226182e-03,  3.51971388e-02,  1.22123562e-01, -2.95334663e-02,\n",
              "         3.75404656e-02, -4.33708541e-02,  1.01022804e-02, -8.85469373e-03,\n",
              "        -2.73956079e-02,  5.59854805e-02, -2.28973571e-03,  1.84585880e-02,\n",
              "        -3.62540446e-02, -6.23585172e-02, -3.37100402e-02,  8.60573351e-03,\n",
              "        -2.52088215e-02, -3.95093672e-03, -3.25787887e-02,  7.67875230e-03],      dtype=float32),\n",
              " 'Bxi': Array([-0.00650773, -0.0562463 , -0.04854974, -0.07721154, -0.02930767,\n",
              "        -0.02041949, -0.02267275,  0.02684287, -0.02492509,  0.00210203,\n",
              "        -0.04343103,  0.00894971, -0.03222099,  0.00328995,  0.04742512,\n",
              "         0.0012959 , -0.01284804, -0.04489557,  0.07944552, -0.00708992,\n",
              "        -0.08611685,  0.0163114 ,  0.09245062,  0.05075214, -0.01202067,\n",
              "        -0.04229053, -0.0359585 , -0.0246184 , -0.07436536, -0.01383884,\n",
              "        -0.03299607,  0.0086985 , -0.00501499, -0.02962219,  0.03425872,\n",
              "         0.0457022 ,  0.01404217,  0.01118698, -0.05225825,  0.01349221,\n",
              "         0.01081601,  0.03820616, -0.03486032,  0.02217796,  0.00549238,\n",
              "        -0.00117128,  0.0121601 ,  0.03037795, -0.03648006,  0.06810259,\n",
              "        -0.0448662 , -0.04792983,  0.07491202,  0.09957822, -0.02317131,\n",
              "        -0.04124975, -0.00564838,  0.01140049, -0.01053753, -0.03589379,\n",
              "         0.03601307, -0.01612157,  0.00636559,  0.00588953, -0.07608078,\n",
              "        -0.08975773, -0.04123846, -0.05892407, -0.04424778,  0.07453794,\n",
              "        -0.027689  , -0.0647257 ,  0.00767727, -0.0434197 , -0.0563777 ,\n",
              "         0.05911857,  0.0633548 , -0.0021072 ,  0.12074736, -0.05567973,\n",
              "        -0.02096813, -0.01440849,  0.09453757, -0.11076523, -0.0296853 ,\n",
              "        -0.00028716, -0.00125722, -0.00930809,  0.06234228, -0.04590143,\n",
              "         0.04679104, -0.04492088, -0.04562924, -0.01886797,  0.00231141,\n",
              "         0.0495172 ,  0.03114169,  0.06350713, -0.08832236,  0.01187649,\n",
              "         0.09482735,  0.0131369 ,  0.03614042, -0.02001829, -0.02437167,\n",
              "        -0.00775879, -0.03171733,  0.04595117, -0.03563565, -0.02690108,\n",
              "        -0.03732388, -0.04142722,  0.00524305, -0.00317571, -0.01020211,\n",
              "        -0.04735322,  0.00312998,  0.01678715,  0.05379472, -0.01293035,\n",
              "        -0.04422886,  0.0449547 , -0.01053005, -0.02392375,  0.0744061 ,\n",
              "         0.02004344,  0.06893417,  0.10893902, -0.01692149,  0.01733536,\n",
              "        -0.01247388, -0.02386182, -0.02855573,  0.01939989, -0.03288629,\n",
              "         0.00265869,  0.02795869, -0.05916242,  0.05935062,  0.0911363 ,\n",
              "        -0.03773478, -0.03760976,  0.02168661, -0.01252899,  0.03303112,\n",
              "        -0.0435667 ,  0.02362501,  0.0978561 , -0.04406631,  0.01321812,\n",
              "        -0.02891121,  0.04580427,  0.05494504, -0.00424732,  0.00229647,\n",
              "         0.02812683,  0.0471769 ,  0.02994399,  0.04281432, -0.01469393,\n",
              "         0.1025646 ,  0.02684754, -0.02899733, -0.03855961, -0.04144225,\n",
              "        -0.10182289, -0.01129903,  0.02919398, -0.00183115,  0.03232155,\n",
              "        -0.06417301, -0.01397198,  0.01509275,  0.00188658, -0.01703702,\n",
              "        -0.02066452, -0.10682973, -0.01147908, -0.01189777, -0.01837094,\n",
              "        -0.0212857 , -0.01854574,  0.01987746,  0.01439748,  0.05321869,\n",
              "         0.00896029,  0.07098761,  0.03567933, -0.01602838, -0.04557272,\n",
              "        -0.00223795,  0.03769056,  0.02638466, -0.03285051,  0.02360742,\n",
              "         0.0305443 , -0.07615575,  0.02487453, -0.05106949, -0.09330337,\n",
              "         0.07769677,  0.03043956,  0.02720073,  0.02478356, -0.00436095,\n",
              "         0.00299089, -0.10811498,  0.06864089, -0.01577889, -0.05894442,\n",
              "         0.07578567,  0.03677052, -0.03510388, -0.02466055, -0.04492194,\n",
              "        -0.03606745,  0.07418752, -0.01866108, -0.06638661,  0.01815695,\n",
              "        -0.04691556, -0.01789398, -0.02591164,  0.02104264,  0.00285734,\n",
              "         0.00963288,  0.05372608, -0.05803952, -0.03973228, -0.00901126,\n",
              "         0.05651959, -0.05876787,  0.0634879 , -0.04172018, -0.02904328,\n",
              "         0.02070724, -0.03515119,  0.0121843 , -0.01175687, -0.04472311,\n",
              "        -0.03190955, -0.05472608, -0.09261812,  0.06260846, -0.02171759,\n",
              "         0.00474617,  0.08048147,  0.05757004, -0.05601474,  0.02991019,\n",
              "        -0.02642365, -0.01821841,  0.08207523, -0.01358829,  0.0516612 ,\n",
              "        -0.01818026,  0.00200982, -0.02895841, -0.01993075,  0.06211682,\n",
              "         0.00157696, -0.02609514,  0.05144583,  0.01947164, -0.03564967,\n",
              "        -0.02211936, -0.0408128 ,  0.07541166, -0.01367958,  0.0074865 ,\n",
              "         0.05921839, -0.03010842, -0.01431152,  0.01900152, -0.07267532,\n",
              "        -0.0586465 , -0.02001245,  0.02255575,  0.0381683 ,  0.03985897,\n",
              "        -0.03088887,  0.00322558, -0.03391758, -0.02587229, -0.02930572,\n",
              "         0.0132585 ,  0.01975238, -0.04889734,  0.04218763,  0.03176421,\n",
              "         0.01340735,  0.00119178, -0.05844408,  0.08594526, -0.00096629,\n",
              "         0.02456759, -0.04029474,  0.01531835,  0.06468906,  0.05491952,\n",
              "        -0.04148895, -0.00380143,  0.01381322, -0.01148238,  0.00635552,\n",
              "        -0.01274711,  0.01122803,  0.02113349,  0.08117583, -0.01280989,\n",
              "        -0.03921381, -0.03005934, -0.00846676,  0.00203737,  0.022998  ,\n",
              "         0.03951569, -0.05198418,  0.03292416, -0.05915475, -0.01553526,\n",
              "        -0.01744352, -0.03262292,  0.04070111, -0.00950021, -0.01382739,\n",
              "        -0.03806792, -0.06401604,  0.01069451,  0.06672845, -0.05201528,\n",
              "         0.02989679,  0.02108381,  0.04152239,  0.12499458, -0.01180007,\n",
              "         0.02458327, -0.0933943 , -0.04616594, -0.04349249,  0.04324554,\n",
              "         0.00195687,  0.00092795, -0.09446573, -0.00967188,  0.10027254,\n",
              "        -0.02086878,  0.03777828,  0.00508554,  0.03537099, -0.06568678,\n",
              "         0.07543187, -0.04111415, -0.00700253, -0.04996329,  0.02868768,\n",
              "        -0.03482913, -0.03922068,  0.02481906, -0.10505573,  0.01699825,\n",
              "         0.00259662,  0.03984754,  0.05042219, -0.04380494,  0.01398723,\n",
              "         0.04399811, -0.0620003 , -0.00679515, -0.0420991 ,  0.04404457,\n",
              "        -0.03426923, -0.04172698,  0.02741856, -0.03882006, -0.0078532 ,\n",
              "        -0.05577099,  0.01360269, -0.01360382, -0.07243427, -0.07261772,\n",
              "        -0.03408861, -0.04895996,  0.01430161,  0.07492252, -0.03719495,\n",
              "        -0.00777342,  0.02651348, -0.07601194, -0.00144893,  0.05668117,\n",
              "         0.00205527,  0.01113829, -0.01813688, -0.02019036,  0.01386092,\n",
              "        -0.02688459,  0.05898871,  0.02080257, -0.02409863,  0.04588509,\n",
              "         0.01127162, -0.00726063, -0.05203634,  0.05423511,  0.05220292,\n",
              "        -0.08625508, -0.0604232 ,  0.01522074,  0.01097273,  0.00738331,\n",
              "        -0.03290183, -0.01271049, -0.0420968 , -0.0453511 , -0.04994876,\n",
              "         0.04135616,  0.01624362, -0.04059784,  0.00603529, -0.0039531 ,\n",
              "         0.0806642 , -0.03631318, -0.03701531,  0.02417822, -0.00931956,\n",
              "         0.0199424 , -0.04365848, -0.03422412,  0.00791294,  0.06717764,\n",
              "         0.06851207, -0.06527934, -0.06023558, -0.01471085, -0.01913994,\n",
              "        -0.06401775,  0.03498004,  0.02178541, -0.0346335 , -0.01827222,\n",
              "         0.03696625,  0.02792357, -0.00923031, -0.01593344,  0.03241073,\n",
              "         0.02930225,  0.0362278 , -0.05270595,  0.04111193, -0.02812359,\n",
              "        -0.01359453,  0.01401259, -0.02588147,  0.02229434,  0.01864203,\n",
              "         0.0197017 ,  0.0259875 ,  0.01843075,  0.01466675,  0.02920411,\n",
              "         0.01722135, -0.05953237,  0.0319012 ,  0.03301798,  0.03187792,\n",
              "         0.01536505,  0.07597084,  0.0614607 ,  0.00984826, -0.03200234,\n",
              "         0.14039077, -0.02150396, -0.00670946, -0.03784245,  0.14598624,\n",
              "        -0.02934624,  0.03328122, -0.05115242,  0.04611959, -0.07604315,\n",
              "         0.01869131,  0.03076694,  0.04803915,  0.07409725, -0.02753182,\n",
              "        -0.04642618,  0.00852874, -0.03059578, -0.04582761, -0.04430151,\n",
              "         0.01850522, -0.03510876, -0.00229413,  0.0135539 ,  0.04513228,\n",
              "        -0.10093371,  0.02361145,  0.01956586,  0.04366463,  0.03467464],      dtype=float32),\n",
              " 'Bxl': Array([ 1.26728579e-01,  1.04082152e-02, -6.89944476e-02, -1.53940357e-02,\n",
              "         1.71620566e-02,  1.93988532e-02, -7.54168537e-03, -4.54235449e-02,\n",
              "        -2.20930465e-02,  2.24216143e-03, -1.02418624e-02, -4.19635288e-02,\n",
              "         5.10321446e-02,  3.68965119e-02,  6.42493814e-02, -2.02368270e-03,\n",
              "         1.10684289e-02,  2.76301093e-02, -6.95287362e-02,  5.33826873e-02,\n",
              "        -1.93725602e-04,  1.49263050e-02,  9.03791711e-02,  5.15538920e-03,\n",
              "        -9.08940658e-03,  2.43495312e-02, -4.69073094e-02, -5.35220020e-02,\n",
              "        -1.77888721e-02, -7.21146315e-02,  4.73705195e-02, -8.89936015e-02,\n",
              "         2.94520725e-02, -3.37986834e-02, -3.37814912e-02, -4.23154458e-02,\n",
              "        -6.21676445e-02, -6.17723987e-02,  4.27287035e-02, -9.84108075e-02,\n",
              "         4.00340334e-02,  2.43377965e-02,  2.66953763e-02,  6.91672089e-03,\n",
              "        -6.34488314e-02,  1.34182051e-02, -3.82544361e-02, -4.12664041e-02,\n",
              "        -5.49352588e-03, -8.32353346e-03, -2.64807278e-03, -1.49944155e-02,\n",
              "        -2.39822152e-03,  4.88604493e-02,  4.44422401e-02,  1.83810038e-03,\n",
              "         2.12592594e-02,  6.80586472e-02, -5.00439890e-02,  4.44845408e-02,\n",
              "         3.25951949e-02, -2.64919996e-02, -2.26255618e-02,  3.75821046e-03,\n",
              "         1.10507645e-02,  4.27085049e-02,  1.24285463e-02,  9.90943704e-03,\n",
              "         2.63291635e-02, -5.15867174e-02,  4.59872074e-02,  1.75510179e-02,\n",
              "        -1.60214845e-02,  1.09102775e-03,  3.29726301e-02, -1.00597804e-02,\n",
              "        -3.44308056e-02,  1.25114601e-02, -2.54702084e-02, -5.77334315e-02,\n",
              "        -2.35033389e-02,  4.15517204e-02,  3.11061461e-02,  7.99618736e-02,\n",
              "        -1.62693243e-02,  1.17268516e-02, -9.57997795e-03,  4.90270741e-02,\n",
              "        -1.95453539e-02, -1.81677043e-02, -5.11791632e-02,  1.33144381e-02,\n",
              "        -6.54185712e-02,  2.17743274e-02,  1.24990633e-02, -3.09135672e-02,\n",
              "         4.35802266e-02, -2.77415551e-02,  2.87305079e-02, -1.34308236e-02,\n",
              "         7.08565488e-02, -3.40283178e-02, -1.07372642e-01, -2.80414824e-04,\n",
              "         7.11886436e-02,  3.13943662e-02,  1.89671554e-02, -3.46934870e-02,\n",
              "         1.64466705e-02, -1.90131199e-02,  4.78094183e-02, -6.59814896e-06,\n",
              "         5.92186907e-03,  5.84694333e-02, -4.47274838e-03,  1.82542875e-02,\n",
              "        -1.97279397e-02,  4.41677198e-02,  6.26844494e-03,  5.24707921e-02,\n",
              "        -8.47802311e-02,  1.06849400e-02, -3.79458107e-02, -4.44626212e-02,\n",
              "        -2.58782003e-02, -4.77349199e-02, -3.27008814e-02, -7.11496621e-02,\n",
              "        -3.16432007e-02,  3.27935023e-03, -2.50397213e-02,  3.12494114e-02,\n",
              "        -4.90205642e-03,  1.75475271e-03, -2.45258329e-03,  1.08053032e-02,\n",
              "         5.56132644e-02, -2.73372605e-03, -3.47745158e-02, -4.11697812e-02,\n",
              "         3.30805555e-02, -4.59454060e-02,  1.19737625e-01, -6.37648478e-02,\n",
              "        -3.55031416e-02, -6.65697157e-02,  4.36189957e-02, -3.53796631e-02,\n",
              "         1.72018539e-02,  4.41380218e-02,  7.41127953e-02, -5.14827995e-03,\n",
              "        -7.41882324e-02, -5.30406088e-03, -4.01976369e-02,  4.97444719e-02,\n",
              "        -1.05102304e-02, -1.74965113e-02,  2.11367942e-02, -1.32629527e-02,\n",
              "        -2.77655330e-02,  2.85757836e-02,  3.09131923e-03, -6.00591749e-02,\n",
              "         1.74634848e-02, -1.60136204e-02, -2.71224268e-02, -2.93863304e-02,\n",
              "         1.99529398e-02,  4.18850929e-02, -4.37749140e-02, -1.12287421e-02,\n",
              "        -1.74461156e-02,  9.58340336e-03, -3.07479165e-02,  6.31549046e-04,\n",
              "        -1.55973928e-02, -5.01346476e-02,  5.00744805e-02,  1.78897493e-02,\n",
              "         3.46267968e-02, -3.60903926e-02,  2.47811843e-02, -5.42820850e-03,\n",
              "        -4.60509816e-03,  3.34441848e-02, -8.21944177e-02,  5.26997931e-02,\n",
              "        -2.03602165e-02, -3.01807746e-02,  3.83528359e-02, -1.08994022e-02,\n",
              "         3.99585842e-04,  4.24558436e-03, -1.11825606e-02,  4.84094694e-02,\n",
              "        -9.18975845e-02, -9.01144277e-03,  5.56767546e-02, -7.98241496e-02,\n",
              "        -1.19290873e-02, -3.37351859e-02, -3.15338895e-02, -5.17635792e-02,\n",
              "         2.11278466e-03, -7.99783617e-02,  5.45029156e-02,  4.34019305e-02,\n",
              "         8.02571625e-02,  1.88025963e-02, -4.86876592e-02,  6.98209479e-02,\n",
              "         3.72123177e-04,  3.82113047e-02,  7.79864788e-02,  5.09225242e-02,\n",
              "         1.37774181e-02,  3.92732024e-02,  1.83911920e-02, -2.81260498e-02,\n",
              "        -5.62514588e-02, -6.42716140e-02,  2.38349251e-02, -2.14132667e-02,\n",
              "         1.05729215e-01, -6.16701506e-02, -1.09185418e-02,  7.10687414e-02,\n",
              "         4.28398550e-02,  5.42460121e-02,  7.74025247e-02,  5.85735627e-02,\n",
              "         4.61656302e-02,  3.68090272e-02,  1.18604759e-02, -5.66270165e-02,\n",
              "         3.59834544e-02,  3.27843465e-02,  3.01992591e-03, -8.20694212e-03,\n",
              "         4.97407317e-02, -6.54132739e-02,  9.55360532e-02, -6.05803281e-02,\n",
              "         1.33313974e-02,  1.96137801e-02,  3.45688835e-02,  3.30384006e-03,\n",
              "        -1.20492838e-02, -1.12438746e-01, -8.39831010e-02, -2.61976011e-03,\n",
              "        -4.44744667e-03,  1.15389526e-02, -7.67720416e-02,  4.87495065e-02,\n",
              "         1.26659973e-02,  3.27712521e-02,  5.28388955e-02,  2.95221712e-02,\n",
              "        -1.27269570e-02, -1.74495485e-02, -6.81406409e-02,  3.43577377e-03,\n",
              "        -2.99207103e-02,  2.53040977e-02,  5.83627000e-02,  5.44680767e-02,\n",
              "        -3.55247930e-02,  7.67420158e-02,  9.95692834e-02, -5.41332625e-02,\n",
              "        -6.17466718e-02, -7.51259848e-02, -1.30088478e-02, -1.52262137e-03,\n",
              "        -1.56400003e-03,  5.64385839e-02, -2.34594680e-02, -9.54205077e-03,\n",
              "        -1.18057013e-01,  3.21066715e-02, -2.45201662e-02, -7.69732567e-03,\n",
              "        -1.17033310e-01,  3.62090617e-02,  3.72525938e-02, -4.44517136e-02,\n",
              "        -5.26135825e-02,  2.75382530e-02,  6.13829009e-02, -2.07924787e-02,\n",
              "         6.05172254e-02, -2.18353290e-02,  3.91535349e-02,  8.75813980e-03,\n",
              "        -2.70647891e-02, -2.39584632e-02, -3.28453109e-02,  4.37127762e-02,\n",
              "         2.00991295e-02, -2.24024914e-02,  3.44554409e-02,  1.18963104e-02,\n",
              "        -3.00801322e-02, -4.85616620e-04,  9.66845825e-02, -4.70502069e-03,\n",
              "        -4.17867340e-02, -4.41929176e-02, -5.19729368e-02, -3.84510532e-02,\n",
              "         4.00708094e-02, -1.83236860e-02,  1.18876966e-02, -1.10352859e-02,\n",
              "         1.35153197e-02, -6.21629059e-02,  7.13657821e-03,  7.05992281e-02,\n",
              "        -2.92526986e-02,  1.59485023e-02,  8.16885978e-02,  2.59694364e-03,\n",
              "         2.01203004e-02,  1.70561634e-02, -7.00724777e-03, -9.69390944e-03,\n",
              "         6.86520012e-03, -1.40691986e-02, -5.30292420e-03,  7.56744761e-03,\n",
              "        -3.13347876e-02, -1.52131664e-02, -3.59138511e-02, -1.01544648e-01,\n",
              "         8.34657997e-02, -1.55498870e-02, -5.59302457e-02, -3.93175296e-02,\n",
              "        -5.07063530e-02, -2.58008414e-03, -2.73398664e-02, -9.27667134e-03,\n",
              "         7.43330196e-02, -4.21384946e-02,  4.75487597e-02,  5.86429462e-02,\n",
              "        -3.35754454e-02,  3.72000635e-02,  2.46452186e-02, -2.65966915e-02,\n",
              "        -1.49526214e-02,  6.41985312e-02,  1.04504880e-02,  4.38893959e-02,\n",
              "         1.47531554e-02, -8.12562332e-02, -1.63139068e-02,  2.72795241e-02,\n",
              "         7.95929879e-02, -4.23982330e-02, -4.13822709e-03, -1.16225658e-02,\n",
              "         3.09340935e-02, -2.59008873e-02,  4.37224917e-02,  4.82226461e-02,\n",
              "         3.60891805e-03, -3.35759036e-02,  2.41701920e-02, -7.37604648e-02,\n",
              "         1.61395445e-02,  4.04513702e-02,  4.85865511e-02,  8.65956619e-02,\n",
              "        -2.21534260e-02, -1.06720300e-02,  1.90507360e-02,  3.96407992e-02,\n",
              "         3.60945449e-03, -3.12206317e-02, -3.41153927e-02,  2.50534546e-02,\n",
              "        -3.26667912e-02, -4.65097837e-03,  1.87502876e-02, -2.23584240e-03,\n",
              "         3.36506069e-02, -5.09997308e-02,  1.65480878e-02, -8.99589527e-03,\n",
              "         7.73459375e-02,  8.91341595e-04,  1.68360397e-02,  3.88562726e-03,\n",
              "         6.87517896e-02,  3.43999788e-02, -2.20101252e-02,  1.60979154e-03,\n",
              "        -6.04526373e-03,  5.77941015e-02,  9.47178714e-03, -1.87636912e-02,\n",
              "         7.82543942e-02, -1.07757160e-02, -4.82734628e-02, -6.24338805e-04,\n",
              "        -1.81902312e-02, -1.82928275e-02, -5.56496205e-03,  7.59781478e-03,\n",
              "         8.83024707e-02,  5.46452589e-02,  1.25750080e-02,  4.85648736e-02,\n",
              "         3.05243526e-02, -7.00866745e-04,  3.87215912e-02, -8.71404484e-02,\n",
              "        -5.13726696e-02,  3.34633552e-02, -5.20836236e-03,  4.35963273e-03,\n",
              "        -1.48957685e-01,  1.11039812e-02,  3.66179161e-02,  2.84914300e-02,\n",
              "         1.56260259e-03,  7.75366724e-02,  7.58671109e-03,  2.36883145e-02,\n",
              "        -9.76775866e-03, -3.95871811e-02,  4.82493788e-02,  4.43741903e-02,\n",
              "         8.73379875e-04,  1.37330741e-02,  1.51252868e-02,  4.80181724e-02,\n",
              "         5.07094376e-02, -6.41848445e-02,  1.06969187e-02,  3.89526552e-03,\n",
              "        -2.96122208e-02, -6.32618591e-02, -1.31923622e-02, -3.85741405e-02,\n",
              "         5.00967763e-02, -6.96570948e-02, -3.72679788e-03, -2.62342412e-02,\n",
              "         2.85345744e-02, -6.02536164e-02, -4.05167090e-03,  4.48213443e-02,\n",
              "         5.20867808e-03,  3.39711569e-02, -3.94631214e-02,  4.44840686e-03,\n",
              "         1.26329586e-02,  3.38763259e-02, -3.73393786e-03, -2.17770860e-02,\n",
              "         3.17254812e-02,  4.99725826e-02,  1.13080931e-03, -3.84912752e-02,\n",
              "        -2.89094299e-02,  5.24760000e-02,  2.66100969e-02,  3.13956365e-02,\n",
              "        -5.74231744e-02,  3.32997702e-02, -9.13849007e-03, -8.21575522e-02,\n",
              "        -1.23605365e-02, -2.09570746e-03, -5.07361442e-03, -2.73376107e-02,\n",
              "         1.72657296e-02,  1.29594132e-02,  1.97011940e-02,  2.68449169e-02,\n",
              "         2.15278361e-02, -5.01955636e-02,  2.59414278e-02, -5.88590354e-02,\n",
              "        -2.92378347e-02,  3.15227103e-03, -9.66319814e-03, -1.60906129e-02,\n",
              "        -6.06492627e-03, -4.45832387e-02, -4.18528058e-02, -1.32155493e-02,\n",
              "         6.62005171e-02,  5.88785335e-02, -8.12593289e-03, -2.41066013e-02],      dtype=float32),\n",
              " 'Bxo': Array([-0.06900465, -0.02460501, -0.06304984, -0.00750309, -0.05387436,\n",
              "        -0.01692455,  0.05127503,  0.02112334, -0.01767769, -0.00921659,\n",
              "         0.02178666,  0.04580904,  0.01155321,  0.01629812,  0.03896798,\n",
              "         0.04008559, -0.09168048, -0.03521951, -0.00436373, -0.09553008,\n",
              "        -0.05855155, -0.03141632, -0.00808613, -0.10378917,  0.02348922,\n",
              "         0.00196614,  0.04321663,  0.04306164, -0.02625904, -0.02071525,\n",
              "        -0.02052085, -0.02336128, -0.09816183, -0.06152727, -0.01583259,\n",
              "         0.03464475,  0.00799409,  0.00751761,  0.01670942, -0.05915415,\n",
              "         0.03741207, -0.03203689, -0.05350478,  0.00218383,  0.02042472,\n",
              "         0.03334041, -0.05009706, -0.02904832, -0.04519492, -0.01035566,\n",
              "        -0.05079612,  0.05179199, -0.06471454, -0.06011893, -0.06083572,\n",
              "         0.00116407,  0.05598397,  0.02618103, -0.02939152, -0.05651852,\n",
              "        -0.03339627, -0.04924938, -0.06501891,  0.02215912,  0.01123156,\n",
              "        -0.00162107, -0.04685046, -0.00073016, -0.02652184,  0.09009022,\n",
              "        -0.0542008 ,  0.03715241, -0.00088873, -0.09508986, -0.04971555,\n",
              "        -0.00820583, -0.0235426 , -0.02230378,  0.03185966, -0.02452711,\n",
              "        -0.00936367,  0.02983932, -0.0950982 ,  0.04918786, -0.00256432,\n",
              "         0.04005732,  0.0131167 ,  0.00908066,  0.02799639, -0.02139078,\n",
              "        -0.02909999,  0.01289858,  0.10881377,  0.04935211,  0.0668242 ,\n",
              "        -0.02884468, -0.00725147,  0.02747138, -0.02109844, -0.024723  ,\n",
              "         0.00513157, -0.10003655, -0.01781201, -0.01321224,  0.07444872,\n",
              "         0.04435306, -0.08385037,  0.00532427, -0.10131491, -0.0081926 ,\n",
              "         0.02755271,  0.06256061,  0.00642545,  0.00453168,  0.02889669,\n",
              "        -0.05126783, -0.05508519, -0.04920187,  0.05388939, -0.02371757,\n",
              "        -0.00076394,  0.00038676,  0.0048032 , -0.01970598, -0.02367501,\n",
              "        -0.02646366,  0.00966122,  0.07260936,  0.06021115, -0.02864734,\n",
              "        -0.06567259, -0.00521888,  0.03255756,  0.0157071 , -0.07344013,\n",
              "         0.02473147, -0.03383791, -0.03403628,  0.0342232 , -0.01345017,\n",
              "         0.00355312, -0.02103546, -0.02591946, -0.02795547, -0.04142494,\n",
              "        -0.06430924,  0.02619702,  0.03611959,  0.00815445,  0.03050442,\n",
              "         0.02745584, -0.00557386,  0.03608714, -0.09310842, -0.02828691,\n",
              "         0.00660319, -0.01447421, -0.02136807,  0.08956978, -0.01443187,\n",
              "         0.01774447,  0.00506838,  0.01001807,  0.06321774, -0.09450039,\n",
              "         0.04104542, -0.08268484, -0.01228075, -0.01398769, -0.01039858,\n",
              "         0.00816884,  0.02925055, -0.00993441,  0.0052935 , -0.01275799,\n",
              "         0.01683664, -0.01777649,  0.04250907,  0.00102427, -0.02419638,\n",
              "         0.0414047 , -0.03239521,  0.02376726,  0.01399172, -0.00664553,\n",
              "        -0.02864271,  0.04080275, -0.03642423, -0.0085362 , -0.04861213,\n",
              "        -0.07249311, -0.01070326,  0.00069736,  0.04611027, -0.08301926,\n",
              "        -0.03019198, -0.003014  , -0.03928046,  0.00210608, -0.00928948,\n",
              "        -0.00225497, -0.00199067, -0.02198834,  0.05280842,  0.05610757,\n",
              "         0.00447383, -0.01297467,  0.02251047,  0.0129896 ,  0.07993796,\n",
              "         0.05367652,  0.08133283, -0.09050802,  0.06911354,  0.02322952,\n",
              "         0.00388085,  0.01356815,  0.08133662,  0.03040556, -0.00669092,\n",
              "         0.00192275, -0.04260652, -0.02105495, -0.01157597,  0.03972805,\n",
              "         0.01175998,  0.00397056, -0.04322499, -0.05675645,  0.08361091,\n",
              "         0.03637699,  0.05077458, -0.01945799,  0.07013695,  0.01521194,\n",
              "         0.04768384,  0.06240397, -0.00959674, -0.00835393,  0.02511265,\n",
              "        -0.00303021, -0.05883041,  0.02942468, -0.02817576,  0.00494438,\n",
              "         0.01704388,  0.02394496,  0.08550075, -0.00139188,  0.08446847,\n",
              "         0.01588503, -0.06073402, -0.06180714,  0.04624971,  0.01813588,\n",
              "        -0.04016719,  0.05127946,  0.02121137, -0.00202113,  0.03506146,\n",
              "         0.03340684, -0.0168114 , -0.0345355 , -0.01486039,  0.07664202,\n",
              "        -0.010514  ,  0.04518768,  0.01911015, -0.00856933,  0.01950254,\n",
              "         0.0227794 ,  0.0374969 ,  0.02325554, -0.02508685,  0.07945213,\n",
              "        -0.00438793,  0.03461091, -0.05539671,  0.02619237, -0.01435422,\n",
              "         0.08003958,  0.02104835, -0.04993367,  0.04579992, -0.01445526,\n",
              "         0.01377289, -0.02047643, -0.05644716,  0.10656042,  0.00653148,\n",
              "        -0.00553692,  0.04229024, -0.04823539,  0.03215832,  0.10280569,\n",
              "        -0.05416436, -0.04709216, -0.01366926,  0.029349  ,  0.02801405,\n",
              "        -0.00960037, -0.01649482, -0.04511613,  0.04034451, -0.00126001,\n",
              "        -0.00645952, -0.00385117,  0.12078623, -0.00142357, -0.0006615 ,\n",
              "         0.00261585, -0.00859823, -0.0109852 , -0.00606281, -0.02130565,\n",
              "         0.02194258, -0.03868667, -0.04373697,  0.02159988, -0.01642177,\n",
              "         0.06590926, -0.02070286,  0.0303867 , -0.04001032,  0.00448029,\n",
              "        -0.03810409,  0.06767185, -0.04051985,  0.03773847, -0.0217142 ,\n",
              "         0.04996745, -0.05082172, -0.03855141,  0.0654465 , -0.04975315,\n",
              "        -0.08691765, -0.0373689 ,  0.03354492, -0.03971438,  0.01967109,\n",
              "         0.04554188, -0.00964998, -0.00084811,  0.05181656,  0.02829495,\n",
              "        -0.03043125,  0.100229  , -0.01090351, -0.06568796,  0.01700398,\n",
              "         0.0272192 ,  0.01983027, -0.05567677, -0.00517314, -0.01394663,\n",
              "         0.08754228, -0.0599076 ,  0.03177512, -0.02081393,  0.02944811,\n",
              "        -0.00772958,  0.00842724,  0.00643711, -0.01161209,  0.03630602,\n",
              "        -0.07294685, -0.06031251, -0.02992748,  0.00357863,  0.04132407,\n",
              "        -0.00729145,  0.05321164, -0.00497275,  0.07837243,  0.0051904 ,\n",
              "        -0.08282102, -0.02478046, -0.08275073,  0.01482685, -0.02123769,\n",
              "        -0.03285702,  0.002528  ,  0.03989793, -0.06150011, -0.05624333,\n",
              "         0.03799133, -0.02227198, -0.01170421,  0.02785361, -0.00604645,\n",
              "        -0.05353502,  0.03311219,  0.07356855,  0.02247246,  0.03014274,\n",
              "        -0.02676215, -0.03776516,  0.06330588,  0.05030204,  0.05289273,\n",
              "        -0.026151  , -0.04537785,  0.02283442, -0.0593631 ,  0.01457438,\n",
              "        -0.02259513, -0.0705254 , -0.06786507,  0.03843432,  0.03979627,\n",
              "         0.02646647, -0.05102375, -0.02908367, -0.04015245,  0.02773663,\n",
              "        -0.0109374 , -0.05292486,  0.02705506,  0.04525232, -0.04819784,\n",
              "         0.0783526 ,  0.01316853,  0.04006628, -0.04392465,  0.08490089,\n",
              "        -0.07141428,  0.06878481, -0.00945272, -0.05981451,  0.02449165,\n",
              "         0.04228458, -0.02906021, -0.00702299,  0.0154109 , -0.00666215,\n",
              "        -0.02313968,  0.016498  ,  0.02233154, -0.08736537,  0.01763073,\n",
              "        -0.01698457, -0.09616469,  0.00083311, -0.04695828,  0.00410279,\n",
              "         0.08699441, -0.02882538, -0.03467494, -0.00078942, -0.00422391,\n",
              "         0.05055347, -0.07103761,  0.01867182,  0.02112963, -0.05085834,\n",
              "         0.0469707 , -0.05838891, -0.02258065, -0.00663508, -0.05461515,\n",
              "        -0.01074307, -0.01669382, -0.00413146,  0.03004103, -0.01208834,\n",
              "         0.01101597, -0.06631519, -0.04672169, -0.04657769,  0.04190125,\n",
              "         0.00789647, -0.05728706,  0.03751736,  0.01139591,  0.00448206,\n",
              "         0.0387447 ,  0.00535325,  0.01508277, -0.03576446,  0.01590781,\n",
              "        -0.00891475,  0.14037599,  0.00315893,  0.04777057, -0.02406081,\n",
              "        -0.01412668,  0.00878366,  0.02987171,  0.00611268, -0.04924456,\n",
              "        -0.00916839, -0.00829595, -0.05724856, -0.09614338,  0.0527423 ,\n",
              "        -0.01929964,  0.0017281 , -0.04200622, -0.04510986, -0.05444012],      dtype=float32),\n",
              " 'Whf': Array([[ 0.02255801,  0.03909981, -0.06568062, ...,  0.09334379,\n",
              "          0.03933955, -0.03434366],\n",
              "        [ 0.04505613, -0.05471627,  0.01679029, ...,  0.00604874,\n",
              "         -0.02909117,  0.00111763],\n",
              "        [ 0.052728  , -0.03349284, -0.04714375, ..., -0.06301502,\n",
              "          0.01684468, -0.00879402],\n",
              "        ...,\n",
              "        [ 0.01031222,  0.04956075,  0.06255961, ...,  0.05245353,\n",
              "          0.07782231,  0.06679744],\n",
              "        [ 0.07360627,  0.03140295, -0.00673877, ...,  0.01296008,\n",
              "          0.00090303,  0.01399409],\n",
              "        [-0.03503645,  0.02486435,  0.02182924, ...,  0.05638455,\n",
              "         -0.04064064,  0.02543653]], dtype=float32),\n",
              " 'Whi': Array([[ 0.03223892, -0.04045479, -0.02229597, ..., -0.00676078,\n",
              "         -0.05025728, -0.03889189],\n",
              "        [ 0.10758127, -0.05294433,  0.05951301, ...,  0.07446606,\n",
              "         -0.0248858 , -0.01471486],\n",
              "        [ 0.02959677, -0.03666576,  0.03501888, ...,  0.01043836,\n",
              "          0.04001718, -0.00449851],\n",
              "        ...,\n",
              "        [-0.06418686,  0.00849065, -0.04797739, ...,  0.06807678,\n",
              "          0.01108251,  0.03714534],\n",
              "        [ 0.07816166, -0.05982968, -0.03588017, ..., -0.05499857,\n",
              "         -0.05676668,  0.00984433],\n",
              "        [-0.01654882,  0.03115861, -0.09795946, ..., -0.09385415,\n",
              "         -0.06712636, -0.02152192]], dtype=float32),\n",
              " 'Whl': Array([[ 0.02256291,  0.09790932, -0.03624684, ...,  0.02457391,\n",
              "         -0.17017367, -0.02487899],\n",
              "        [-0.02809867,  0.07339869,  0.02434837, ...,  0.00811342,\n",
              "         -0.01213801,  0.03401021],\n",
              "        [-0.00033587,  0.00330027, -0.04021539, ...,  0.00913475,\n",
              "         -0.02365407, -0.03445768],\n",
              "        ...,\n",
              "        [ 0.0325701 , -0.02668206,  0.02782528, ...,  0.09253568,\n",
              "          0.07000498,  0.03820507],\n",
              "        [-0.06251412, -0.06846453, -0.03643664, ...,  0.03724428,\n",
              "          0.01585266, -0.04925157],\n",
              "        [ 0.00648107, -0.10854567, -0.01835988, ..., -0.01172184,\n",
              "         -0.0058358 ,  0.00766622]], dtype=float32),\n",
              " 'Who': Array([[ 0.04215911, -0.07251932, -0.00564185, ...,  0.04498255,\n",
              "         -0.04921803, -0.02749795],\n",
              "        [-0.05208546,  0.07194784,  0.02736374, ..., -0.00361817,\n",
              "         -0.02085288, -0.00665775],\n",
              "        [-0.05630329,  0.05788441, -0.00167403, ..., -0.03560608,\n",
              "         -0.05507813,  0.01288559],\n",
              "        ...,\n",
              "        [ 0.00232159, -0.05715163,  0.02285126, ...,  0.00554929,\n",
              "          0.00456796,  0.06925885],\n",
              "        [-0.05198052,  0.01327686,  0.05829554, ...,  0.10219105,\n",
              "          0.02455869, -0.00910685],\n",
              "        [ 0.03274193,  0.04365191, -0.06278323, ..., -0.02537287,\n",
              "          0.04046727,  0.00311211]], dtype=float32),\n",
              " 'Wo': Array([[-2.98579093e-02,  2.83402973e-03],\n",
              "        [-2.76743841e+00, -2.69855142e+00],\n",
              "        [-6.35226667e-02,  2.58240066e-02],\n",
              "        [ 6.28292933e-02, -2.06170641e-02],\n",
              "        [ 3.43357213e-02, -1.33416029e-02],\n",
              "        [ 8.16355795e-02,  3.56632546e-02],\n",
              "        [-2.11162437e-02,  2.67886017e-02],\n",
              "        [-3.72214802e-02,  3.17525491e-02],\n",
              "        [ 4.98025902e-02, -2.52529513e-02],\n",
              "        [-2.73228955e+00, -2.66275597e+00],\n",
              "        [ 2.85783768e+00,  2.65968370e+00],\n",
              "        [ 6.63884506e-02,  1.26769710e-02],\n",
              "        [-8.86388589e-03, -1.01395316e-01],\n",
              "        [ 4.63906415e-02, -5.07291555e-02],\n",
              "        [-3.73961888e-02,  1.85491201e-02],\n",
              "        [-2.75131440e+00, -2.69000363e+00],\n",
              "        [ 2.73816085e+00,  2.70250034e+00],\n",
              "        [-2.75451875e+00, -2.74639988e+00],\n",
              "        [ 2.74109864e+00,  2.63633370e+00],\n",
              "        [ 4.11317125e-02, -9.45913717e-02],\n",
              "        [-4.98521738e-02,  1.32032866e-02],\n",
              "        [-5.35853095e-02, -1.19840726e-01],\n",
              "        [ 5.93773238e-02,  6.30891994e-02],\n",
              "        [ 2.73941326e+00,  2.70898843e+00],\n",
              "        [-2.72061396e+00, -2.65844274e+00],\n",
              "        [-7.65502732e-03,  8.75074491e-02],\n",
              "        [-4.31079268e-02, -1.01693058e-02],\n",
              "        [ 7.82209914e-03, -1.37257408e-02],\n",
              "        [-6.68379664e-02, -4.70064320e-02],\n",
              "        [ 2.67878556e+00,  2.69403601e+00],\n",
              "        [-7.97707736e-02,  3.83330323e-02],\n",
              "        [-1.60354506e-02,  9.90748871e-04],\n",
              "        [-1.15872756e-01, -2.32134759e-02],\n",
              "        [ 2.10765507e-02,  9.35871340e-03],\n",
              "        [-2.75230813e+00, -2.69572592e+00],\n",
              "        [ 1.83309000e-02,  3.93212922e-02],\n",
              "        [-5.70453629e-02, -5.97508922e-02],\n",
              "        [ 5.82752973e-02, -1.37045337e-02],\n",
              "        [-8.72330624e-04,  2.38092244e-02],\n",
              "        [ 3.82059924e-02, -1.07370904e-02],\n",
              "        [ 3.18570100e-02, -5.10623045e-02],\n",
              "        [-3.92824039e-03,  3.76911089e-02],\n",
              "        [-5.77793419e-02, -5.63186780e-02],\n",
              "        [-2.81420350e+00, -2.70584822e+00],\n",
              "        [ 2.30173040e-02, -7.46487360e-03],\n",
              "        [ 3.04033589e+00,  2.97831821e+00],\n",
              "        [ 4.55944091e-02, -1.09724417e-01],\n",
              "        [-3.88683081e-02,  4.10277769e-02],\n",
              "        [-2.69784665e+00, -2.75844240e+00],\n",
              "        [-2.71690512e+00, -2.67068839e+00],\n",
              "        [-1.10476995e-02,  5.73168099e-02],\n",
              "        [ 3.68745402e-02, -6.57683983e-02],\n",
              "        [ 2.71418595e+00,  2.69674301e+00],\n",
              "        [-1.27978297e-02,  3.04401349e-02],\n",
              "        [-8.78289863e-02,  1.46491705e-02],\n",
              "        [-8.80331472e-02,  1.51803130e-02],\n",
              "        [ 2.76732635e+00,  2.74503517e+00],\n",
              "        [-6.64094836e-02,  1.41941076e-02],\n",
              "        [ 3.01368143e-02, -9.70791932e-03],\n",
              "        [ 1.31863551e-02,  4.24760394e-02],\n",
              "        [ 8.04071967e-03, -7.28625432e-03],\n",
              "        [-1.66485202e-03,  5.36293797e-02],\n",
              "        [ 2.82457304e+00,  2.77252722e+00],\n",
              "        [ 1.12081788e-01,  4.00497206e-03],\n",
              "        [ 5.93586601e-02, -3.07116527e-02],\n",
              "        [-4.76490241e-03,  6.40328601e-02],\n",
              "        [-8.01034048e-02,  2.41350941e-02],\n",
              "        [ 4.91141528e-02,  2.57098489e-02],\n",
              "        [ 5.92380725e-02, -1.03244763e-02],\n",
              "        [-6.83085015e-03,  8.55847523e-02],\n",
              "        [-2.70868897e+00, -2.64527965e+00],\n",
              "        [-2.79899502e+00, -2.75303960e+00],\n",
              "        [-3.42344902e-02,  9.04328097e-03],\n",
              "        [ 3.33496220e-02, -2.32285401e-03],\n",
              "        [ 2.15260405e-02,  4.63008359e-02],\n",
              "        [-4.74342033e-02, -2.05458067e-02],\n",
              "        [ 5.34929242e-03, -6.87659439e-03],\n",
              "        [-1.72925461e-02, -2.16466319e-02],\n",
              "        [ 1.37193175e-02, -3.70101556e-02],\n",
              "        [ 2.75891256e+00,  2.65504384e+00],\n",
              "        [ 2.74437547e+00,  2.70469737e+00],\n",
              "        [-3.01120430e-02,  4.49973717e-02],\n",
              "        [-3.86092649e-03, -4.06237766e-02],\n",
              "        [-5.51551022e-02, -5.70787340e-02],\n",
              "        [-4.22400571e-02,  6.01230375e-02],\n",
              "        [-3.12216207e-03, -8.49446561e-03],\n",
              "        [-2.74912953e+00, -2.63849759e+00],\n",
              "        [ 2.74541593e+00,  2.77709365e+00],\n",
              "        [ 2.73215532e+00,  2.75680614e+00],\n",
              "        [-3.08315866e-02, -6.79845586e-02],\n",
              "        [-2.63342522e-02,  2.95174718e-02],\n",
              "        [ 1.98164266e-02,  3.57938595e-02],\n",
              "        [ 5.90316914e-02, -7.07818568e-03],\n",
              "        [-3.19837686e-03,  3.27636153e-02],\n",
              "        [-2.16468852e-02, -5.69899604e-02],\n",
              "        [-1.74054597e-02,  3.55995782e-02],\n",
              "        [-6.08502282e-03, -3.19106020e-02],\n",
              "        [-6.23263493e-02, -9.32134837e-02],\n",
              "        [-2.94729567e+00, -2.81891680e+00],\n",
              "        [ 4.46485765e-02,  2.28962991e-02],\n",
              "        [-3.37603465e-02,  5.82394786e-02],\n",
              "        [-3.88259441e-02, -6.93258690e-03],\n",
              "        [-2.78531051e+00, -2.71076488e+00],\n",
              "        [-3.32737081e-02, -1.67384855e-02],\n",
              "        [ 2.69894767e+00,  2.77886200e+00],\n",
              "        [ 3.14397598e-03,  1.13722540e-01],\n",
              "        [-8.51012766e-03,  3.74863967e-02],\n",
              "        [-4.69298102e-02, -3.64327729e-02],\n",
              "        [ 1.31994300e-02,  3.02560511e-03],\n",
              "        [ 2.72646427e+00,  2.65580797e+00],\n",
              "        [-2.81972599e+00, -2.71554112e+00],\n",
              "        [-5.29951043e-02,  6.21427372e-02],\n",
              "        [ 3.95073779e-02,  1.41339805e-02],\n",
              "        [ 2.02991441e-02,  1.79039240e-02],\n",
              "        [-7.96868354e-02,  5.44871157e-03],\n",
              "        [ 2.74836087e+00,  2.65423775e+00],\n",
              "        [-6.20971583e-02,  6.74236193e-02],\n",
              "        [-4.68454659e-02, -2.39501968e-02],\n",
              "        [ 7.66174197e-02, -2.23140772e-02],\n",
              "        [-1.59589183e-02, -3.09985541e-02],\n",
              "        [ 7.90622924e-03,  1.90288876e-03],\n",
              "        [-3.38843744e-03, -7.03433752e-02],\n",
              "        [ 3.49182822e-02, -3.81068699e-02],\n",
              "        [ 2.76329994e+00,  2.72627783e+00],\n",
              "        [-1.41206831e-02, -4.90654893e-02],\n",
              "        [ 1.77239589e-02, -6.47430569e-02],\n",
              "        [ 9.46727209e-03,  1.88124292e-02],\n",
              "        [ 3.73055339e-02, -8.17690883e-03],\n",
              "        [-2.73077583e+00, -2.69989157e+00],\n",
              "        [-4.78823408e-02, -3.78793702e-02],\n",
              "        [-2.25652251e-02,  1.42303213e-01],\n",
              "        [ 3.03201918e-02,  6.06305525e-02],\n",
              "        [ 2.75881600e+00,  2.73476839e+00],\n",
              "        [-9.82355475e-02, -3.06339003e-02],\n",
              "        [ 2.67650509e+00,  2.69714165e+00],\n",
              "        [ 4.87981886e-02,  3.00538745e-02],\n",
              "        [ 2.75482702e+00,  2.66827774e+00],\n",
              "        [ 2.79067039e+00,  2.67559028e+00],\n",
              "        [ 2.68623185e+00,  2.80669498e+00],\n",
              "        [ 8.06593150e-02,  4.48312331e-03],\n",
              "        [-4.26754206e-02, -2.50659678e-02],\n",
              "        [-3.24419178e-02, -2.09047757e-02],\n",
              "        [ 6.52531022e-03, -1.77163712e-03],\n",
              "        [ 2.74020958e+00,  2.75014687e+00],\n",
              "        [-6.05849363e-03,  3.94557305e-02],\n",
              "        [ 8.84067193e-02, -3.14812455e-03],\n",
              "        [-2.74358797e+00, -2.76096010e+00],\n",
              "        [ 1.44988503e-02, -3.13356169e-04],\n",
              "        [ 2.78305364e+00,  2.73202944e+00],\n",
              "        [-1.06964242e-02,  7.48625621e-02],\n",
              "        [ 2.68238163e+00,  2.59257388e+00],\n",
              "        [-2.34970935e-02, -4.28410526e-03],\n",
              "        [-2.06123888e-02, -5.36944792e-02],\n",
              "        [-5.51054534e-03, -2.72990745e-02],\n",
              "        [ 7.43311569e-02,  4.28665779e-04],\n",
              "        [-2.75435662e+00, -2.73588133e+00],\n",
              "        [-4.48227040e-02,  1.62316747e-02],\n",
              "        [ 2.22139303e-02, -9.51964855e-02],\n",
              "        [ 6.46422207e-02,  2.48373244e-02],\n",
              "        [ 2.73175693e+00,  2.67392468e+00],\n",
              "        [ 2.76827860e+00,  2.72329903e+00],\n",
              "        [ 2.78246856e+00,  2.75352311e+00],\n",
              "        [-5.76865338e-02,  6.54609278e-02],\n",
              "        [-9.28433239e-03, -1.13347247e-01],\n",
              "        [-2.76493597e+00, -2.80978966e+00],\n",
              "        [ 2.79509926e+00,  2.65542197e+00],\n",
              "        [-2.72036958e+00, -2.66748691e+00],\n",
              "        [-1.12329699e-01, -5.72659411e-02],\n",
              "        [ 3.94106796e-03,  3.58840227e-02],\n",
              "        [-2.66213012e+00, -2.77034831e+00],\n",
              "        [-3.79072130e-02,  3.95463370e-02],\n",
              "        [ 6.78905845e-03,  2.35462897e-02],\n",
              "        [ 7.10179582e-02, -4.22750972e-03],\n",
              "        [ 2.76719308e+00,  2.67380786e+00],\n",
              "        [ 2.75091839e+00,  2.79533601e+00],\n",
              "        [-1.83782727e-02, -3.86868864e-02],\n",
              "        [ 3.55400071e-02,  3.62793617e-02],\n",
              "        [ 2.31787805e-02, -4.95592356e-02],\n",
              "        [ 5.59164174e-02, -2.47424543e-02],\n",
              "        [ 1.72707234e-02, -4.88820449e-02],\n",
              "        [ 2.80216265e+00,  2.71695781e+00],\n",
              "        [-2.75372338e+00, -2.73654962e+00],\n",
              "        [ 2.54064333e-02,  3.02484762e-02],\n",
              "        [-2.66979265e+00, -2.75279832e+00],\n",
              "        [ 1.39823733e-02,  2.37325616e-02],\n",
              "        [ 2.79994988e+00,  2.69534254e+00],\n",
              "        [ 2.45049726e-02,  3.17183621e-02],\n",
              "        [-2.79705115e-02,  5.61515167e-02],\n",
              "        [ 2.53451038e-02,  7.08153248e-02],\n",
              "        [-1.84546672e-02, -4.47178707e-02],\n",
              "        [ 2.51649227e-02,  1.20137921e-02],\n",
              "        [ 2.80902338e+00,  2.69755006e+00],\n",
              "        [ 7.03722099e-03, -3.07385903e-03],\n",
              "        [-1.22074448e-02,  4.92361374e-02],\n",
              "        [-2.74788523e+00, -2.72185588e+00],\n",
              "        [ 7.94012565e-03, -1.91238578e-02],\n",
              "        [ 6.72623739e-02,  1.04037868e-02],\n",
              "        [-1.18407439e-02,  1.27433613e-02],\n",
              "        [-1.09221699e-04, -1.75483897e-02],\n",
              "        [ 2.89421845e-02,  6.47303089e-02],\n",
              "        [-2.76979152e-02,  4.66639511e-02],\n",
              "        [-5.35250828e-02, -3.54956985e-02],\n",
              "        [ 1.30356790e-03, -8.40570927e-02],\n",
              "        [ 2.69515395e+00,  2.77332354e+00],\n",
              "        [-1.60932075e-02,  2.07670294e-02],\n",
              "        [ 3.60962865e-03,  9.26274955e-02],\n",
              "        [ 2.81062245e+00,  2.78241754e+00],\n",
              "        [-1.47582004e-02, -4.49305959e-02],\n",
              "        [ 2.77622819e+00,  2.69251680e+00],\n",
              "        [ 5.25425114e-02, -5.73795587e-02],\n",
              "        [-2.74761081e+00, -2.73542142e+00],\n",
              "        [-5.43962512e-03,  1.58094484e-02],\n",
              "        [ 3.59534548e-04, -1.05256857e-02],\n",
              "        [ 4.80799824e-02, -6.50283918e-02],\n",
              "        [-2.33965591e-02, -3.70906368e-02],\n",
              "        [-5.48449643e-02, -5.22426441e-02],\n",
              "        [ 2.62222067e-02, -6.43735304e-02],\n",
              "        [ 2.77011275e+00,  2.75894332e+00],\n",
              "        [-1.22890798e-02, -1.25671804e-01],\n",
              "        [ 2.70634651e+00,  2.77067733e+00],\n",
              "        [-2.68938160e+00, -2.70919085e+00],\n",
              "        [-2.71407866e+00, -2.69108224e+00],\n",
              "        [-2.70495117e-02,  6.48866966e-03],\n",
              "        [ 1.73069257e-02, -5.17371632e-02],\n",
              "        [-3.18900049e-02,  6.90499786e-03],\n",
              "        [ 2.72577453e+00,  2.66247845e+00],\n",
              "        [-3.94257978e-02, -5.53173311e-02],\n",
              "        [ 2.70486069e+00,  2.78454804e+00],\n",
              "        [ 2.10378524e-02,  4.46863584e-02],\n",
              "        [ 1.17536388e-01, -6.13812022e-02],\n",
              "        [-2.02274648e-03,  4.33167443e-02],\n",
              "        [ 2.80525661e+00,  2.69377375e+00],\n",
              "        [ 2.23145857e-02,  7.76525214e-02],\n",
              "        [-2.65002203e+00, -2.71518826e+00],\n",
              "        [ 2.82915545e+00,  2.70605803e+00],\n",
              "        [ 2.32066400e-02, -2.32479572e-02],\n",
              "        [ 1.49269542e-02,  9.66291875e-03],\n",
              "        [-7.97527730e-02, -5.38079962e-02],\n",
              "        [ 3.18124741e-02, -3.55864577e-02],\n",
              "        [ 1.88181866e-02,  4.80824076e-02],\n",
              "        [-1.31307673e-02,  8.58799554e-03],\n",
              "        [ 1.29400585e-02, -5.18313982e-02],\n",
              "        [-5.74044809e-02, -3.07021127e-03],\n",
              "        [ 3.54261510e-02, -3.18074599e-02],\n",
              "        [ 1.31808417e-02, -3.30918133e-02],\n",
              "        [ 1.98831074e-02, -3.07020266e-02],\n",
              "        [-6.42803265e-03,  2.97829602e-02],\n",
              "        [-6.87265024e-02,  6.51703328e-02],\n",
              "        [ 8.88897553e-02,  4.33642790e-02],\n",
              "        [ 2.77572489e+00,  2.71945930e+00],\n",
              "        [-3.04197241e-02,  3.18075866e-02],\n",
              "        [ 2.85713207e-02,  1.82927977e-02],\n",
              "        [-2.59803820e+00, -2.72890592e+00],\n",
              "        [ 2.34698579e-02,  8.70551169e-02],\n",
              "        [-2.74987984e+00, -2.61770582e+00],\n",
              "        [-2.22999398e-02, -5.94321685e-03],\n",
              "        [-7.04334751e-02, -4.98291478e-02],\n",
              "        [-2.76121616e+00, -2.67866564e+00],\n",
              "        [-5.97991655e-03, -4.01938930e-02],\n",
              "        [ 5.20863533e-02, -1.64099538e-03],\n",
              "        [-4.02196199e-02, -1.41981859e-02],\n",
              "        [ 2.73491096e+00,  2.65332866e+00],\n",
              "        [-9.68736969e-03, -1.05598252e-02],\n",
              "        [ 2.72980142e+00,  2.76565361e+00],\n",
              "        [ 7.39687532e-02, -5.56013994e-02],\n",
              "        [ 2.89066527e-02,  6.72479197e-02],\n",
              "        [ 2.17422619e-02, -7.15390444e-02],\n",
              "        [ 2.65720892e+00,  2.81221890e+00],\n",
              "        [ 7.93994069e-02, -1.11996178e-02],\n",
              "        [ 6.11926317e-02, -5.61147258e-02],\n",
              "        [-2.83613491e+00, -2.70125127e+00],\n",
              "        [ 2.77341151e+00,  2.72122025e+00],\n",
              "        [-4.47907858e-02, -7.32912356e-03],\n",
              "        [ 2.79969978e+00,  2.70137024e+00],\n",
              "        [-2.77060866e+00, -2.72779012e+00],\n",
              "        [-2.74515033e+00, -2.77963877e+00],\n",
              "        [ 9.98124778e-02,  2.19980665e-02],\n",
              "        [ 3.72552536e-02,  1.79190245e-02],\n",
              "        [-2.70075250e+00, -2.73255229e+00],\n",
              "        [ 2.72638440e+00,  2.62931466e+00],\n",
              "        [ 1.68584473e-02, -6.36541285e-03],\n",
              "        [-2.75719857e+00, -2.62850046e+00],\n",
              "        [-3.03458683e-02, -1.79875605e-02],\n",
              "        [-3.54799256e-02, -3.07423510e-02],\n",
              "        [-3.03312279e-02,  2.04380099e-02],\n",
              "        [ 7.11043328e-02,  4.06565815e-02],\n",
              "        [ 2.24425625e-02, -1.81554421e-03],\n",
              "        [-3.66780721e-02, -3.17398235e-02],\n",
              "        [ 3.61048640e-03, -5.68881966e-02],\n",
              "        [-3.63560431e-02,  9.58650261e-02],\n",
              "        [ 2.11655162e-02, -2.95851566e-02],\n",
              "        [ 2.37042289e-02,  5.43363132e-02],\n",
              "        [ 8.84833261e-02, -8.51463825e-02],\n",
              "        [ 2.75569177e+00,  2.67068028e+00],\n",
              "        [ 1.34340860e-02,  2.28196848e-03],\n",
              "        [ 1.10444687e-02,  3.67733352e-02],\n",
              "        [ 2.24646628e-02, -2.23665778e-02],\n",
              "        [-4.29646298e-02,  5.93269393e-02],\n",
              "        [ 2.75200081e+00,  2.64142156e+00],\n",
              "        [ 2.72868204e+00,  2.71481681e+00],\n",
              "        [ 2.76372266e+00,  2.71372676e+00],\n",
              "        [ 4.61401865e-02,  1.45733636e-02],\n",
              "        [-2.00502612e-02, -2.40435153e-02],\n",
              "        [-2.82087851e+00, -2.69009686e+00],\n",
              "        [ 3.38597782e-02,  8.73119310e-02],\n",
              "        [-4.70440229e-03,  4.12501320e-02],\n",
              "        [-2.80484509e+00, -2.67260814e+00],\n",
              "        [ 4.07488272e-02, -2.13956460e-02],\n",
              "        [ 6.07933733e-04,  1.10675223e-01],\n",
              "        [-6.02326430e-02, -5.92738800e-02],\n",
              "        [ 4.44163894e-03, -3.62682319e-03],\n",
              "        [ 6.18517883e-02, -8.41794070e-03],\n",
              "        [-2.81408262e+00, -2.66497660e+00],\n",
              "        [ 2.73998022e+00,  2.75765324e+00],\n",
              "        [-2.79759836e+00, -2.67874336e+00],\n",
              "        [-3.83755714e-02,  1.30242752e-02],\n",
              "        [ 5.13054915e-02,  1.20392546e-01],\n",
              "        [-1.51643832e-03, -2.92064045e-02],\n",
              "        [ 2.75468421e+00,  2.71090126e+00],\n",
              "        [ 2.75352287e+00,  2.73284650e+00],\n",
              "        [ 3.38589400e-02, -4.24529519e-03],\n",
              "        [-2.74386764e+00, -2.74514914e+00],\n",
              "        [ 7.09693239e-04, -6.02056980e-02],\n",
              "        [ 2.82474494e+00,  2.72974730e+00],\n",
              "        [ 3.11757438e-03,  1.27837002e-01],\n",
              "        [ 2.78074408e+00,  2.76205635e+00],\n",
              "        [ 5.35239130e-02,  1.48795662e-03],\n",
              "        [-1.29425861e-02, -1.42483246e-02],\n",
              "        [ 1.26517396e-02, -2.16607247e-02],\n",
              "        [-1.02991033e-02,  4.43385281e-02],\n",
              "        [-2.78161931e+00, -2.64264464e+00],\n",
              "        [-5.62286600e-02,  4.36615720e-02],\n",
              "        [ 3.58500145e-02,  9.61667392e-03],\n",
              "        [ 2.80415082e+00,  2.75166559e+00],\n",
              "        [-1.04799410e-02, -7.00454786e-02],\n",
              "        [-1.68253370e-02,  6.08952492e-02],\n",
              "        [ 1.88369527e-02,  2.07051151e-02],\n",
              "        [ 4.36991230e-02, -1.86141469e-02],\n",
              "        [ 2.70596218e+00,  2.68916512e+00],\n",
              "        [ 1.43215666e-03, -7.11839348e-02],\n",
              "        [ 1.13821886e-02,  4.15511467e-02],\n",
              "        [-2.49466449e-02, -3.43703888e-02],\n",
              "        [ 1.84321068e-02,  6.36296626e-03],\n",
              "        [ 2.80775523e+00,  2.78130722e+00],\n",
              "        [ 4.29921458e-03,  2.12708605e-03],\n",
              "        [ 2.80215955e+00,  2.73517394e+00],\n",
              "        [-4.02309140e-03, -1.84633378e-02],\n",
              "        [ 1.00381739e-01, -5.43156788e-02],\n",
              "        [ 2.73848939e+00,  2.71593022e+00],\n",
              "        [-1.05635583e-01,  4.29881853e-04],\n",
              "        [ 3.15939523e-02,  3.82585712e-02],\n",
              "        [-3.26101594e-02,  3.63254733e-02],\n",
              "        [ 2.78676438e+00,  2.68362522e+00],\n",
              "        [ 6.42876886e-03,  1.21934563e-02],\n",
              "        [-8.33239555e-02, -3.01890163e-04],\n",
              "        [ 2.71157956e+00,  2.71837378e+00],\n",
              "        [ 4.25726315e-03,  8.63301829e-02],\n",
              "        [ 1.19607188e-01, -4.85402794e-04],\n",
              "        [-5.33863530e-03, -6.57054633e-02],\n",
              "        [-1.87384766e-02, -6.06256835e-02],\n",
              "        [-1.44095626e-02,  2.75546331e-02],\n",
              "        [ 1.95620488e-03,  3.04193646e-02],\n",
              "        [-1.21431397e-02, -2.78159473e-02],\n",
              "        [-3.90935503e-02, -4.14470360e-02],\n",
              "        [-1.27882389e-02,  2.01208685e-02],\n",
              "        [ 2.74377179e+00,  2.70041060e+00],\n",
              "        [ 7.20401062e-03,  2.40510236e-02],\n",
              "        [ 2.80382347e+00,  2.67336249e+00],\n",
              "        [ 1.91373806e-02, -5.26269861e-02],\n",
              "        [ 2.05452330e-02, -1.04097668e-02],\n",
              "        [ 2.32700229e-04, -1.80718321e-02],\n",
              "        [-2.71888995e+00, -2.68132973e+00],\n",
              "        [-2.81399465e+00, -2.65443015e+00],\n",
              "        [ 2.69202757e+00,  2.70861244e+00],\n",
              "        [-2.32692491e-02, -3.94608965e-03],\n",
              "        [ 2.87846196e-02,  1.05093427e-01],\n",
              "        [-3.02524660e-02, -4.00776304e-02],\n",
              "        [-7.05229715e-02, -2.82812268e-02],\n",
              "        [-4.73724380e-02,  2.12380644e-02],\n",
              "        [ 3.16165574e-02,  3.30397934e-02],\n",
              "        [-2.53622346e-02, -4.68885303e-02],\n",
              "        [ 3.09469504e-03,  6.79652020e-02],\n",
              "        [-2.75391722e+00, -2.65947461e+00],\n",
              "        [ 1.35064647e-02, -4.36134376e-02],\n",
              "        [ 1.28674898e-02, -7.94188399e-03],\n",
              "        [ 3.38862725e-02,  5.48425503e-03],\n",
              "        [-6.86365226e-03, -1.46688363e-02],\n",
              "        [-2.66892388e-02, -1.90744572e-03],\n",
              "        [ 2.78792071e+00,  2.76988506e+00],\n",
              "        [-1.49484240e-02,  7.40241306e-03],\n",
              "        [ 1.31801432e-02,  3.05576306e-02],\n",
              "        [-7.11999685e-02,  6.05720207e-02],\n",
              "        [ 2.00653244e-02, -4.23272848e-02],\n",
              "        [-2.71702743e+00, -2.74283600e+00],\n",
              "        [-3.77437822e-03,  9.67605188e-02],\n",
              "        [ 5.43592423e-02, -6.95080683e-02],\n",
              "        [ 2.79863644e+00,  2.71687603e+00],\n",
              "        [ 8.54236111e-02, -7.57271051e-02],\n",
              "        [ 2.71947598e+00,  2.70649838e+00],\n",
              "        [ 6.00029267e-02, -3.81882638e-02],\n",
              "        [-6.82490095e-02,  6.02750555e-02],\n",
              "        [ 2.40676459e-02,  2.04076208e-02],\n",
              "        [-3.59254405e-02, -5.32925166e-02],\n",
              "        [-8.72295536e-03,  1.28814867e-02],\n",
              "        [-1.71218459e-02, -2.31294781e-02],\n",
              "        [ 2.78459477e+00,  2.81905246e+00],\n",
              "        [-8.43365956e-03,  9.62560344e-03],\n",
              "        [ 2.72980738e+00,  2.73495460e+00],\n",
              "        [-2.75064468e+00, -2.74291229e+00],\n",
              "        [-4.31816559e-03,  4.91944188e-03],\n",
              "        [ 3.67073976e-02,  3.16676907e-02],\n",
              "        [-1.70776551e-03, -6.19631335e-02],\n",
              "        [ 4.00292426e-02, -4.98618707e-02],\n",
              "        [-2.42792033e-02,  4.36870456e-02],\n",
              "        [ 2.72853899e+00,  2.73219872e+00],\n",
              "        [ 5.29662333e-02,  1.69966128e-02],\n",
              "        [-2.79642773e+00, -2.69609547e+00],\n",
              "        [ 9.20522027e-03, -2.81172264e-02],\n",
              "        [ 7.01176301e-02,  7.77880289e-03],\n",
              "        [-2.73320174e+00, -2.69645929e+00],\n",
              "        [-2.82780218e+00, -2.72189665e+00],\n",
              "        [-1.12821616e-01,  5.14436364e-02],\n",
              "        [-3.32655646e-02, -4.68874648e-02],\n",
              "        [-5.27593261e-03,  2.20288965e-03],\n",
              "        [-2.77356219e+00, -2.75485516e+00],\n",
              "        [ 2.74158144e+00,  2.72078180e+00],\n",
              "        [-2.81624889e+00, -2.77308273e+00],\n",
              "        [ 2.75008965e+00,  2.71334195e+00],\n",
              "        [-3.05991471e-02,  3.39299440e-02],\n",
              "        [ 3.15577872e-02,  5.17133586e-02],\n",
              "        [ 2.35996731e-02,  1.35346232e-02],\n",
              "        [-3.68750431e-02,  7.49388710e-02],\n",
              "        [ 2.74686337e+00,  2.70845437e+00],\n",
              "        [-1.02475584e-01, -7.38107264e-02],\n",
              "        [-1.87302940e-02, -2.81314235e-02],\n",
              "        [ 1.58131099e-03, -5.53033277e-02],\n",
              "        [-8.03556014e-03,  2.60568596e-02],\n",
              "        [-3.82536120e-04,  4.23433110e-02],\n",
              "        [-3.27555500e-02, -5.68946861e-02],\n",
              "        [ 6.42427942e-04,  4.27650809e-02],\n",
              "        [-2.70900106e+00, -2.77327228e+00],\n",
              "        [-1.51394650e-01, -4.91174646e-02],\n",
              "        [ 2.72771645e+00,  2.76036382e+00],\n",
              "        [-2.77938414e+00, -2.78286362e+00],\n",
              "        [ 2.80991077e+00,  2.72749352e+00],\n",
              "        [ 1.00027315e-01, -4.45498060e-03],\n",
              "        [ 2.79428673e+00,  2.66884923e+00],\n",
              "        [ 2.92427111e+00,  2.97230935e+00],\n",
              "        [ 5.64219616e-02, -7.77966483e-03],\n",
              "        [ 2.69251776e+00,  2.75792789e+00],\n",
              "        [-2.70868087e+00, -2.80066442e+00],\n",
              "        [-1.26606168e-03,  6.73968494e-02],\n",
              "        [ 7.75750400e-03,  1.04411636e-02],\n",
              "        [-2.73280454e+00, -2.70068192e+00],\n",
              "        [-2.73467755e+00, -2.75009346e+00],\n",
              "        [ 5.60169406e-02,  1.12444591e-02],\n",
              "        [-4.19320501e-02,  2.14928128e-02],\n",
              "        [ 2.74720359e+00,  2.72857237e+00],\n",
              "        [ 5.78564405e-02, -6.26763701e-02],\n",
              "        [-1.74572486e-02, -6.38852417e-02],\n",
              "        [-2.81643558e+00, -2.72204947e+00],\n",
              "        [ 2.70228434e+00,  2.78352118e+00],\n",
              "        [ 1.42079443e-02, -2.28736326e-02],\n",
              "        [-2.73155761e+00, -2.66948271e+00],\n",
              "        [-1.58013161e-02, -2.36984063e-02],\n",
              "        [-4.96670157e-02, -3.48525159e-02],\n",
              "        [-7.18488470e-02, -4.86450978e-02],\n",
              "        [ 2.16834694e-02,  3.53183784e-02],\n",
              "        [ 2.71985674e+00,  2.76095796e+00],\n",
              "        [-2.78612232e+00, -2.60006523e+00],\n",
              "        [-6.54995143e-02, -1.28826648e-02],\n",
              "        [ 3.87844183e-02,  2.68203244e-02],\n",
              "        [ 1.71923693e-02,  3.58053646e-03],\n",
              "        [ 2.77502036e+00,  2.71047688e+00],\n",
              "        [-6.24743327e-02,  7.80546921e-04],\n",
              "        [-1.25631336e-02,  9.57016891e-04],\n",
              "        [ 2.73165298e+00,  2.67692423e+00],\n",
              "        [ 6.01773076e-02, -4.64620963e-02],\n",
              "        [ 2.75710821e+00,  2.68326306e+00],\n",
              "        [ 1.74176693e-03, -3.29561010e-02],\n",
              "        [-7.09740669e-02,  3.20839696e-02],\n",
              "        [-3.17991525e-03,  1.03119425e-02],\n",
              "        [-2.72635245e+00, -2.81390047e+00],\n",
              "        [-3.08839255e-04,  1.65869496e-04],\n",
              "        [-3.97217693e-04, -5.34086674e-02],\n",
              "        [ 2.88713388e-02,  5.95176406e-02],\n",
              "        [-2.40534469e-02, -1.16485491e-01],\n",
              "        [-6.28490970e-02,  9.09188762e-03],\n",
              "        [-2.73310757e+00, -2.72178650e+00],\n",
              "        [ 2.15660390e-02,  7.05073625e-02],\n",
              "        [-2.70652986e+00, -2.74336624e+00],\n",
              "        [-8.37215781e-02, -5.19671328e-02],\n",
              "        [ 3.15208770e-02, -1.93425417e-02],\n",
              "        [ 1.93667784e-02, -2.72915866e-02],\n",
              "        [-2.77646923e+00, -2.78464651e+00],\n",
              "        [ 3.15599213e-03, -8.03926121e-03],\n",
              "        [-8.75162240e-03, -8.28017220e-02],\n",
              "        [-6.92993328e-02,  3.04396246e-02],\n",
              "        [ 3.70588675e-02,  4.07108814e-02],\n",
              "        [ 2.73786497e+00,  2.65651774e+00]], dtype=float32),\n",
              " 'Wxf': Array([[ 0.06991199, -0.07237202, -0.00281652, ...,  0.03935293,\n",
              "         -0.0097756 , -0.0198767 ],\n",
              "        [-0.00874909,  0.00844568, -0.04652989, ..., -0.01170418,\n",
              "          0.01678223, -0.00753799],\n",
              "        [-0.05143332,  0.03483594,  0.04241041, ..., -0.02058865,\n",
              "          0.12044582,  0.09015934],\n",
              "        ...,\n",
              "        [ 0.01993236,  0.06088675, -0.02071144, ...,  0.07657091,\n",
              "          0.03332299, -0.00725153],\n",
              "        [-0.05668764,  0.05824376, -0.02491815, ..., -0.06549947,\n",
              "         -0.01427052,  0.02387223],\n",
              "        [ 0.0088616 ,  0.01399665,  0.00926176, ..., -0.01168063,\n",
              "          0.12168604,  0.01711103]], dtype=float32),\n",
              " 'Wxi': Array([[ 0.01125911, -0.05028913,  0.09013062, ...,  0.06256311,\n",
              "          0.05431801, -0.01010599],\n",
              "        [-0.07795278,  0.01384453,  0.03492739, ..., -0.00315808,\n",
              "         -0.02126983,  0.01339598],\n",
              "        [ 0.01752377,  0.07068948, -0.00307408, ..., -0.04023956,\n",
              "         -0.01960677,  0.10479124],\n",
              "        ...,\n",
              "        [ 0.0182249 ,  0.02102091, -0.01135571, ...,  0.0475775 ,\n",
              "          0.00535468,  0.00115994],\n",
              "        [-0.01311789, -0.00637546,  0.05454317, ..., -0.05348237,\n",
              "         -0.00834344, -0.05722758],\n",
              "        [ 0.01111596, -0.07274884,  0.06951614, ...,  0.01494725,\n",
              "          0.04463746,  0.07659331]], dtype=float32),\n",
              " 'Wxl': Array([[-0.03383272, -0.01625809, -0.02493486, ...,  0.04967023,\n",
              "          0.09813456, -0.00772156],\n",
              "        [-0.08796008,  0.04277234, -0.03276081, ...,  0.04116818,\n",
              "         -0.0298501 ,  0.04913463],\n",
              "        [ 0.00165445, -0.06564667, -0.00809902, ..., -0.06576174,\n",
              "          0.05787114, -0.01674273],\n",
              "        ...,\n",
              "        [-0.09576523, -0.02935826, -0.02044182, ...,  0.01025883,\n",
              "          0.00067383,  0.04761157],\n",
              "        [ 0.00978674, -0.01381235,  0.04150841, ...,  0.0084755 ,\n",
              "          0.04699036, -0.04197118],\n",
              "        [-0.0334136 ,  0.01137982, -0.0187149 , ..., -0.01579547,\n",
              "          0.0537114 ,  0.10801159]], dtype=float32),\n",
              " 'Wxo': Array([[-6.7926221e-02,  1.5375711e-02, -5.4458633e-02, ...,\n",
              "         -1.4868458e-02, -2.8428381e-02, -4.5972716e-02],\n",
              "        [-2.2671187e-02, -3.3161946e-02, -8.4152244e-02, ...,\n",
              "          2.9941451e-02, -4.1340169e-02, -7.8331955e-02],\n",
              "        [ 1.6785212e-02,  6.4876825e-02, -1.6931230e-02, ...,\n",
              "          2.8172750e-02, -2.7810846e-02, -5.6082617e-02],\n",
              "        ...,\n",
              "        [-1.1492737e-01, -6.7857639e-03, -4.7097255e-02, ...,\n",
              "         -5.1713206e-02,  5.7000609e-04, -5.8031263e-05],\n",
              "        [ 7.0016041e-02,  4.8406400e-02, -4.2190529e-02, ...,\n",
              "          2.1296086e-02,  5.7409960e-03,  4.7633674e-02],\n",
              "        [ 1.5825815e-02,  4.1082124e-03, -1.3430228e-02, ...,\n",
              "          8.8284589e-02,  6.3665219e-02, -7.1695633e-02]], dtype=float32)}"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNNYLXjAnKLM",
        "outputId": "82803e71-860a-4ee1-fc15-071af8cce9d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[326.80344, 322.18808],\n",
              "       [380.99802, 375.59006],\n",
              "       [389.3045 , 383.77505],\n",
              "       [390.44882, 384.90265],\n",
              "       [390.60413, 385.0557 ],\n",
              "       [390.62515, 385.0764 ],\n",
              "       [390.62802, 385.07916],\n",
              "       [390.6284 , 385.07956],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62842, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962],\n",
              "       [390.62845, 385.07962]], dtype=float32)"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmj.forward(datasetHL[0][-100:], params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Ze7scNnKLM",
        "outputId": "ddbb307f-9c16-4254-9e92-ae97ad469d09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[419.23, 411.09],\n",
              "       [418.79, 411.09],\n",
              "       [420.02, 411.09],\n",
              "       [420.18, 411.09],\n",
              "       [420.18, 411.09],\n",
              "       [421.82, 414.65],\n",
              "       [427.92, 417.85],\n",
              "       [427.92, 417.85],\n",
              "       [428.03, 417.85],\n",
              "       [428.03, 421.82],\n",
              "       [429.13, 426.55],\n",
              "       [429.9 , 426.55],\n",
              "       [433.8 , 426.55],\n",
              "       [436.66, 426.55],\n",
              "       [437.18, 429.13],\n",
              "       [442.6 , 429.9 ],\n",
              "       [442.6 , 433.8 ],\n",
              "       [442.6 , 436.66],\n",
              "       [442.6 , 434.94],\n",
              "       [442.6 , 434.94],\n",
              "       [439.46, 433.21],\n",
              "       [437.18, 431.44],\n",
              "       [436.51, 431.44],\n",
              "       [436.51, 431.44],\n",
              "       [438.11, 431.44],\n",
              "       [443.28, 431.44]], dtype=float32)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB3-VRzznKLM",
        "outputId": "a2aa66b9-24d2-40fb-ddd4-00665970b860"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(1279.7205, dtype=float32)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jnp.mean((batch[1] - lstmj.forward(batch[0], params))**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRZgILygnKLN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNqyT7enKLN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EQ1l8ClnKLN",
        "outputId": "c66d86c3-e607-48c0-910c-cf2ecdc8c4d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True], dtype=bool)"
            ]
          },
          "execution_count": 506,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmj.final_state[0] == lstmj.hstate[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrhL4P5anKLN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arvjw3QZnKLN"
      },
      "outputs": [],
      "source": [
        "def cumsum(carry, x):\n",
        "    return carry + x, carry + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRAUpPDXnKLN",
        "outputId": "c9cca8b8-ca0a-4d4f-8006-41a0a1be4d2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Array(45, dtype=int32),\n",
              " Array([ 0,  1,  3,  6, 10, 15, 21, 28, 36, 45], dtype=int32))"
            ]
          },
          "execution_count": 442,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.lax.scan(cumsum, 0, jnp.arange(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7F-FXTKnKLN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVw-Yb1-nKLN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhmyI3ZDnKLN"
      },
      "source": [
        "### LSTM using Equinox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAY97vklnKLN"
      },
      "outputs": [],
      "source": [
        "#let's compare jax only implementation above to equinox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_4vTPginKLN",
        "outputId": "55dc4c6f-fe6a-4010-f758-5ce34a867514"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.4.13'"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knzE2bCenKLN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "# import jax\n",
        "# import jax.lax as lax\n",
        "# import jax.numpy as jnp\n",
        "# import jax.random as jrandom\n",
        "import numpy as np\n",
        "# import optax  # https://github.com/deepmind/optax\n",
        "\n",
        "import equinox as eqx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0IbyYD2nKLN"
      },
      "outputs": [],
      "source": [
        "def dataloader(arrays, batch_size):\n",
        "    dataset_size = arrays[0].shape[0]\n",
        "    assert all(array.shape[0] == dataset_size for array in arrays)\n",
        "    indices = np.arange(dataset_size)\n",
        "    epoch = -1\n",
        "    while True:\n",
        "#         perm = np.random.permutation(indices) # removed shuffling for TS\n",
        "        perm = indices\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        epoch += 1\n",
        "        print(f'starting epoch {epoch}')\n",
        "        while end <= dataset_size:\n",
        "            batch_perm = perm[start:end]\n",
        "            yield tuple(array[batch_perm] for array in arrays)\n",
        "            start = end\n",
        "            end = start + batch_size\n",
        "\n",
        "\n",
        "def get_data(dataset_size, seq_length, *, key):\n",
        "    t = jnp.linspace(0, 2 * math.pi, seq_length)\n",
        "    offset = jax.random.uniform(key, (dataset_size, 1), minval=0, maxval=2 * math.pi)\n",
        "    x1 = jnp.sin(t + offset) / (1 + t)\n",
        "    x2 = jnp.cos(t + offset) / (1 + t)\n",
        "    y = jnp.ones((dataset_size, 1))\n",
        "\n",
        "    half_dataset_size = dataset_size // 2\n",
        "    x1 = x1.at[:half_dataset_size].multiply(-1)\n",
        "    y = y.at[:half_dataset_size].set(0)\n",
        "    x = jnp.stack([x1, x2], axis=-1)\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NQFVC9EnKLN"
      },
      "outputs": [],
      "source": [
        "# spirals curling in oposite direction\n",
        "# think of each spiral as a sequence, or a time series\n",
        "# hence GRU/LSTM for classifying sequences\n",
        "# input dim is 2 in this case, and we are observing\n",
        "# a sequence of (x1, x2) points\n",
        "dataset_size = 2\n",
        "seq_length = 20\n",
        "batch_size = 1\n",
        "data_key, model_key = jax.random.split(jax.random.PRNGKey(212), 2)\n",
        "xs, ys = get_data(dataset_size, seq_length, key=data_key)\n",
        "iter_data = dataloader((xs, ys), batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN8yerg1nKLN",
        "outputId": "6dda0b79-d8c4-4c87-bd2e-551003a71cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 20, 2) (2, 1)\n"
          ]
        }
      ],
      "source": [
        "print(xs.shape, ys.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EPUz5lgnKLN",
        "outputId": "d7895b57-27e2-4de2-d497-4ecf14c0444b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fabddf05450>"
            ]
          },
          "execution_count": 407,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "# df_cl1 = df[df.label == 0]\n",
        "# df_cl2 = df[df.label == 1]\n",
        "for i in range(dataset_size):\n",
        "    if ys[i][0] == 0.:\n",
        "        clr ='b'\n",
        "    else:\n",
        "        clr = 'r'\n",
        "    ax1.scatter(xs[i][:, 0], xs[i][:, 1], s=5, c=clr, marker=\"s\", label=ys[i][0])\n",
        "#     ax1.scatter(df_cl2.x1, df_cl2.x2, s=5, c='r', marker=\"s\", label='class2')\n",
        "fig.tight_layout()\n",
        "plt.title('Two classes')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "# plt.scatter(xs[0][:, 0], xs[0][:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1OzYlBhnKLN"
      },
      "outputs": [],
      "source": [
        "# larger data set\n",
        "dataset_size = 100\n",
        "batch_size = 10\n",
        "seq_length = 20\n",
        "data_key, model_key = jax.random.split(jax.random.PRNGKey(212), 2)\n",
        "xs, ys = get_data(dataset_size, seq_length, key=data_key)\n",
        "iter_data = dataloader((xs, ys), batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQPek1OSnKLN",
        "outputId": "dd0aebfa-e1a6-4bdf-d0a1-343261b1fd76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 20, 2)"
            ]
          },
          "execution_count": 409,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPznBs72nKLN",
        "outputId": "a1794911-d5a0-47e4-eb24-6bd29b623c42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umaiyTyOnKLN"
      },
      "outputs": [],
      "source": [
        "iter_data = dataloader(datasetHL, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U28ULU1lnKLO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gnmhi40nKLO",
        "outputId": "d6f14e6c-4d22-40f2-93dc-f77fda746455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n",
            "(100, 100) (100, 2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[412], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y) \u001b[38;5;129;01min\u001b[39;00m iter_data:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n",
            "Cell \u001b[0;32mIn[404], line 12\u001b[0m, in \u001b[0;36mdataloader\u001b[0;34m(arrays, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m dataset_size:\n\u001b[1;32m     11\u001b[0m     batch_perm \u001b[38;5;241m=\u001b[39m perm[start:end]\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(array[batch_perm] \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m arrays)\n\u001b[1;32m     13\u001b[0m     start \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m     14\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m batch_size\n",
            "Cell \u001b[0;32mIn[404], line 12\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m dataset_size:\n\u001b[1;32m     11\u001b[0m     batch_perm \u001b[38;5;241m=\u001b[39m perm[start:end]\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(array[batch_perm] \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m arrays)\n\u001b[1;32m     13\u001b[0m     start \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m     14\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m batch_size\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/array.py:317\u001b[0m, in \u001b[0;36mArrayImpl.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_numpy\u001b[38;5;241m.\u001b[39m_rewriting_take(\u001b[38;5;28mself\u001b[39m, idx)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_numpy\u001b[38;5;241m.\u001b[39m_rewriting_take(\u001b[38;5;28mself\u001b[39m, idx)\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4143\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4140\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   4142\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m _split_index_for_jit(idx, arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m-> 4143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4144\u001b[0m                unique_indices, mode, fill_value)\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4152\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4150\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   4151\u001b[0m   idx \u001b[38;5;241m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 4152\u001b[0m   indexer \u001b[38;5;241m=\u001b[39m _index_to_gather(shape(arr), idx)  \u001b[38;5;66;03m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   4153\u001b[0m   y \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   4155\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4327\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4324\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[1;32m   4326\u001b[0m start_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gather_indices_shape)\n\u001b[0;32m-> 4327\u001b[0m gather_indices \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((lax\u001b[38;5;241m.\u001b[39mconvert_element_type(a, index_dtype), start_dim)\n\u001b[1;32m   4328\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m advanced_indexes)\n\u001b[1;32m   4329\u001b[0m gather_indices_shape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m   4331\u001b[0m start_index_map\u001b[38;5;241m.\u001b[39mextend(x_advanced_axes)\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4327\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4324\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[1;32m   4326\u001b[0m start_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gather_indices_shape)\n\u001b[0;32m-> 4327\u001b[0m gather_indices \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((lax\u001b[38;5;241m.\u001b[39mconvert_element_type(a, index_dtype), start_dim)\n\u001b[1;32m   4328\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m advanced_indexes)\n\u001b[1;32m   4329\u001b[0m gather_indices_shape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m   4331\u001b[0m start_index_map\u001b[38;5;241m.\u001b[39mextend(x_advanced_axes)\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/lax/lax.py:510\u001b[0m, in \u001b[0;36mconvert_element_type\u001b[0;34m(operand, new_dtype)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_element_type\u001b[39m(operand: ArrayLike, new_dtype: DTypeLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;124;03m\"\"\"Elementwise cast.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m  Wraps XLA's `ConvertElementType\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    An array with the same shape as `operand`, cast elementwise to `new_dtype`.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _convert_element_type(operand, new_dtype, weak_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/lax/lax.py:529\u001b[0m, in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    527\u001b[0m   new_dtype \u001b[38;5;241m=\u001b[39m old_dtype\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m   new_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(new_dtype)\n\u001b[1;32m    530\u001b[0m new_dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mdtype(new_dtype, canonicalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtypes\u001b[38;5;241m.\u001b[39missubdtype(old_dtype, np\u001b[38;5;241m.\u001b[39mcomplexfloating) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(new_dtype, np\u001b[38;5;241m.\u001b[39mcomplexfloating)):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for (x, y) in iter_data:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQw8dH8NnKLO"
      },
      "outputs": [],
      "source": [
        "class RNN(eqx.Module):\n",
        "    hidden_size: int\n",
        "    cell: eqx.Module\n",
        "    linear: eqx.nn.Linear\n",
        "    bias: jax.Array\n",
        "\n",
        "    def __init__(self, in_size, out_size, hidden_size, *, key):\n",
        "        ckey, lkey = jax.random.split(key)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.cell = eqx.nn.GRUCell(in_size, hidden_size, key=ckey)\n",
        "#         self.cell = eqx.nn.LSTMCell(in_size, hidden_size, key=ckey)\n",
        "        self.linear = eqx.nn.Linear(hidden_size, out_size, use_bias=False, key=lkey)\n",
        "        self.bias = jnp.zeros(out_size)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        hidden = jnp.zeros((self.hidden_size,))\n",
        "\n",
        "        def f(carry, inp):\n",
        "            return self.cell(inp, carry), None\n",
        "\n",
        "        out, _ = jax.lax.scan(f, hidden, input)\n",
        "        # sigmoid because we're performing binary classification\n",
        "        return jax.nn.sigmoid(self.linear(out) + self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4iCtgQCnKLO"
      },
      "outputs": [],
      "source": [
        "class RNNlstm(eqx.Module):\n",
        "    hidden_size: int\n",
        "    cell1: eqx.Module\n",
        "    cell2: eqx.Module\n",
        "    linear: eqx.nn.Linear\n",
        "#     bias: jax.Array\n",
        "\n",
        "    def __init__(self, in_size, out_size, hidden_size, *, key):\n",
        "        c1key, c2key, lkey = jax.random.split(key, 3)\n",
        "        self.hidden_size = hidden_size\n",
        "#         self.cell = eqx.nn.GRUCell(in_size, hidden_size, key=ckey)\n",
        "        self.cell1 = eqx.nn.LSTMCell(in_size, hidden_size, key=c1key)\n",
        "        self.cell2 = eqx.nn.LSTMCell(hidden_size, hidden_size, key=c2key)\n",
        "        self.linear = eqx.nn.Linear(hidden_size, out_size, use_bias=True, key=lkey)\n",
        "#         self.bias = jnp.zeros(out_size)\n",
        "\n",
        "    def __call__(self, xs):\n",
        "        scan_fn = lambda state, x: (self.cell1(x, state), None)\n",
        "        init_state = (jnp.zeros(self.cell1.hidden_size),\n",
        "                      jnp.zeros(self.cell1.hidden_size))\n",
        "        final_state, _ = jax.lax.scan(scan_fn, init_state, xs)\n",
        "\n",
        "        return self.linear(final_state[0]) # + self.bias\n",
        "#         return jax.nn.sigmoid(self.linear(final_state[0]) + self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ4u6V2dnKLO"
      },
      "outputs": [],
      "source": [
        "lstmeq = RNNlstm(2, 2, 32, key=model_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iprc8JtHnKLO",
        "outputId": "234666a6-fe57-499f-8249-7bbb1f19e881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([0.13397285, 0.09302421], dtype=float32)"
            ]
          },
          "execution_count": 324,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmeq(xs[0][:5, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms9XsQ6LnKLO",
        "outputId": "b1b0e2d9-7c00-4950-a7a8-57651f0743c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMCell(\n",
              "  weight_ih=f32[128,2],\n",
              "  weight_hh=f32[128,32],\n",
              "  bias=f32[128],\n",
              "  input_size=2,\n",
              "  hidden_size=32,\n",
              "  use_bias=True\n",
              ")"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstmeq.cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5lSWtzynKLO"
      },
      "outputs": [],
      "source": [
        "lstmeq = RNNlstm(100, 2, 32, key=model_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzJu5CaZnKLO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj5vJD9unKLO"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    dataset_size=100,\n",
        "    batch_size=10,\n",
        "    learning_rate=3e-3,\n",
        "    steps=200,\n",
        "    hidden_size=32,\n",
        "    depth=1,\n",
        "    seed=5678,\n",
        "):\n",
        "    data_key, model_key = jax.random.split(jax.random.PRNGKey(seed), 2)\n",
        "    xs, ys = get_data(dataset_size, seq_length=14, key=data_key)\n",
        "    iter_data = dataloader((xs, ys), batch_size)\n",
        "\n",
        "    model = RNN(in_size=2, out_size=1, hidden_size=hidden_size, key=model_key)\n",
        "#     model = RNNlstm(in_size=2, out_size=1, hidden_size=hidden_size, key=model_key)\n",
        "\n",
        "    @eqx.filter_value_and_grad\n",
        "    def compute_loss(model, x, y):\n",
        "        pred_y = jax.vmap(model)(x)\n",
        "        # Trains with respect to binary cross-entropy\n",
        "        return -jnp.mean(y * jnp.log(pred_y) + (1 - y) * jnp.log(1 - pred_y))\n",
        "\n",
        "    # Important for efficiency whenever you use JAX: wrap everything into a single JIT\n",
        "    # region.\n",
        "    @eqx.filter_jit\n",
        "    def make_step(model, x, y, opt_state):\n",
        "        loss, grads = compute_loss(model, x, y)\n",
        "        updates, opt_state = optim.update(grads, opt_state)\n",
        "        model = eqx.apply_updates(model, updates)\n",
        "        return loss, model, opt_state\n",
        "\n",
        "    optim = optax.adam(learning_rate)\n",
        "    opt_state = optim.init(model)\n",
        "    for step, (x, y) in zip(range(steps), iter_data):\n",
        "        loss, model, opt_state = make_step(model, x, y, opt_state)\n",
        "        loss = loss.item()\n",
        "        print(f\"step={step}, loss={loss}\")\n",
        "\n",
        "    pred_ys = jax.vmap(model)(xs)\n",
        "    num_correct = jnp.sum((pred_ys > 0.5) == ys)\n",
        "    final_accuracy = (num_correct / dataset_size).item()\n",
        "    print(f\"final_accuracy={final_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imoKyE3tnKLO",
        "outputId": "89c0b991-6eda-4f75-e668-f42c3af2f926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting epoch 0\n",
            "step=0, loss=0.7081233263015747\n",
            "step=1, loss=0.6880833506584167\n",
            "step=2, loss=0.6670365333557129\n",
            "step=3, loss=0.6492072343826294\n",
            "step=4, loss=0.628685712814331\n",
            "step=5, loss=0.7848258018493652\n",
            "step=6, loss=0.7960376739501953\n",
            "step=7, loss=0.7989193797111511\n",
            "step=8, loss=0.7965542674064636\n",
            "step=9, loss=0.7902571558952332\n",
            "starting epoch 1\n",
            "step=10, loss=0.6111821532249451\n",
            "step=11, loss=0.6148279309272766\n",
            "step=12, loss=0.6153644919395447\n",
            "step=13, loss=0.6149423718452454\n",
            "step=14, loss=0.6114858984947205\n",
            "step=15, loss=0.7869271636009216\n",
            "step=16, loss=0.7895097732543945\n",
            "step=17, loss=0.7881371378898621\n",
            "step=18, loss=0.7853938937187195\n",
            "step=19, loss=0.7801624536514282\n",
            "starting epoch 2\n",
            "step=20, loss=0.6177666187286377\n",
            "step=21, loss=0.6210214495658875\n",
            "step=22, loss=0.6220059394836426\n",
            "step=23, loss=0.6227951645851135\n",
            "step=24, loss=0.6206672787666321\n",
            "step=25, loss=0.7737724184989929\n",
            "step=26, loss=0.7754095196723938\n",
            "step=27, loss=0.7729578018188477\n",
            "step=28, loss=0.771012008190155\n",
            "step=29, loss=0.7666424512863159\n",
            "starting epoch 3\n",
            "step=30, loss=0.6281981468200684\n",
            "step=31, loss=0.6309759020805359\n",
            "step=32, loss=0.6317358613014221\n",
            "step=33, loss=0.6328434348106384\n",
            "step=34, loss=0.6308444738388062\n",
            "step=35, loss=0.7612904906272888\n",
            "step=36, loss=0.7628366351127625\n",
            "step=37, loss=0.7596843242645264\n",
            "step=38, loss=0.758539617061615\n",
            "step=39, loss=0.7548076510429382\n",
            "starting epoch 4\n",
            "step=40, loss=0.6376927495002747\n",
            "step=41, loss=0.6400644779205322\n",
            "step=42, loss=0.6405410170555115\n",
            "step=43, loss=0.6417579650878906\n",
            "step=44, loss=0.6396514177322388\n",
            "step=45, loss=0.7509427070617676\n",
            "step=46, loss=0.7525714039802551\n",
            "step=47, loss=0.7487707138061523\n",
            "step=48, loss=0.7483318448066711\n",
            "step=49, loss=0.7450731992721558\n",
            "starting epoch 5\n",
            "step=50, loss=0.6456381678581238\n",
            "step=51, loss=0.6476673483848572\n",
            "step=52, loss=0.647902250289917\n",
            "step=53, loss=0.6491414904594421\n",
            "step=54, loss=0.6468966007232666\n",
            "step=55, loss=0.7425406575202942\n",
            "step=56, loss=0.7442739605903625\n",
            "step=57, loss=0.7397820353507996\n",
            "step=58, loss=0.7399742007255554\n",
            "step=59, loss=0.7370814085006714\n",
            "starting epoch 6\n",
            "step=60, loss=0.6521660685539246\n",
            "step=61, loss=0.6538891196250916\n",
            "step=62, loss=0.6539434194564819\n",
            "step=63, loss=0.6551335453987122\n",
            "step=64, loss=0.6527813076972961\n",
            "step=65, loss=0.7356585264205933\n",
            "step=66, loss=0.7374739646911621\n",
            "step=67, loss=0.7321969270706177\n",
            "step=68, loss=0.7329829931259155\n",
            "step=69, loss=0.7303933501243591\n",
            "starting epoch 7\n",
            "step=70, loss=0.6575227379798889\n",
            "step=71, loss=0.6589489579200745\n",
            "step=72, loss=0.6588859558105469\n",
            "step=73, loss=0.6599346995353699\n",
            "step=74, loss=0.6575307846069336\n",
            "step=75, loss=0.7299025654792786\n",
            "step=76, loss=0.7317559123039246\n",
            "step=77, loss=0.7255516052246094\n",
            "step=78, loss=0.7269302010536194\n",
            "step=79, loss=0.7246161103248596\n",
            "starting epoch 8\n",
            "step=80, loss=0.6619173288345337\n",
            "step=81, loss=0.66302889585495\n",
            "step=82, loss=0.6629173159599304\n",
            "step=83, loss=0.6636810302734375\n",
            "step=84, loss=0.6613005995750427\n",
            "step=85, loss=0.7249372005462646\n",
            "step=86, loss=0.7267576456069946\n",
            "step=87, loss=0.7194223999977112\n",
            "step=88, loss=0.7214216589927673\n",
            "step=89, loss=0.7193850874900818\n",
            "starting epoch 9\n",
            "step=90, loss=0.6654810309410095\n",
            "step=91, loss=0.6662306785583496\n",
            "step=92, loss=0.666154146194458\n",
            "step=93, loss=0.6663903594017029\n",
            "step=94, loss=0.6641355752944946\n",
            "step=95, loss=0.720433235168457\n",
            "step=96, loss=0.7221000790596008\n",
            "step=97, loss=0.7133452296257019\n",
            "step=98, loss=0.716009795665741\n",
            "step=99, loss=0.7142783403396606\n",
            "starting epoch 10\n",
            "step=100, loss=0.6682253479957581\n",
            "step=101, loss=0.6685246825218201\n",
            "step=102, loss=0.6685991287231445\n",
            "step=103, loss=0.6678609251976013\n",
            "step=104, loss=0.6658801436424255\n",
            "step=105, loss=0.7159437537193298\n",
            "step=106, loss=0.7172329425811768\n",
            "step=107, loss=0.7066518664360046\n",
            "step=108, loss=0.7100018858909607\n",
            "step=109, loss=0.7086126208305359\n",
            "starting epoch 11\n",
            "step=110, loss=0.6698940992355347\n",
            "step=111, loss=0.6695809364318848\n",
            "step=112, loss=0.6699852347373962\n",
            "step=113, loss=0.6673414707183838\n",
            "step=114, loss=0.6658520102500916\n",
            "step=115, loss=0.7105499505996704\n",
            "step=116, loss=0.7110269665718079\n",
            "step=117, loss=0.6980485916137695\n",
            "step=118, loss=0.701930820941925\n",
            "step=119, loss=0.7008163928985596\n",
            "starting epoch 12\n",
            "step=120, loss=0.6693370938301086\n",
            "step=121, loss=0.6680587530136108\n",
            "step=122, loss=0.6690753698348999\n",
            "step=123, loss=0.6621615886688232\n",
            "step=124, loss=0.6613988876342773\n",
            "step=125, loss=0.7015583515167236\n",
            "step=126, loss=0.7004317045211792\n",
            "step=127, loss=0.6840901374816895\n",
            "step=128, loss=0.6876676082611084\n",
            "step=129, loss=0.6859175562858582\n",
            "starting epoch 13\n",
            "step=130, loss=0.6612083911895752\n",
            "step=131, loss=0.6577549576759338\n",
            "step=132, loss=0.6597406268119812\n",
            "step=133, loss=0.6401106119155884\n",
            "step=134, loss=0.6395274996757507\n",
            "step=135, loss=0.6786186099052429\n",
            "step=136, loss=0.6752338409423828\n",
            "step=137, loss=0.6515180468559265\n",
            "step=138, loss=0.6522802114486694\n",
            "step=139, loss=0.6436147093772888\n",
            "starting epoch 14\n",
            "step=140, loss=0.6129977703094482\n",
            "step=141, loss=0.5992938280105591\n",
            "step=142, loss=0.6023333072662354\n",
            "step=143, loss=0.5322228670120239\n",
            "step=144, loss=0.5270711183547974\n",
            "step=145, loss=0.6016469597816467\n",
            "step=146, loss=0.6018531918525696\n",
            "step=147, loss=0.5450334548950195\n",
            "step=148, loss=0.5462079048156738\n",
            "step=149, loss=0.5020980834960938\n",
            "starting epoch 15\n",
            "step=150, loss=0.402963250875473\n",
            "step=151, loss=0.35235586762428284\n",
            "step=152, loss=0.41301342844963074\n",
            "step=153, loss=0.2516065537929535\n",
            "step=154, loss=0.30638018250465393\n",
            "step=155, loss=0.34477362036705017\n",
            "step=156, loss=0.33307501673698425\n",
            "step=157, loss=0.26496219635009766\n",
            "step=158, loss=0.2411365509033203\n",
            "step=159, loss=0.16124409437179565\n",
            "starting epoch 16\n",
            "step=160, loss=0.17684267461299896\n",
            "step=161, loss=0.13445021212100983\n",
            "step=162, loss=0.25944140553474426\n",
            "step=163, loss=0.08969908207654953\n",
            "step=164, loss=0.1700640767812729\n",
            "step=165, loss=0.05427923426032066\n",
            "step=166, loss=0.05462702736258507\n",
            "step=167, loss=0.057220470160245895\n",
            "step=168, loss=0.048549897968769073\n",
            "step=169, loss=0.04518388211727142\n",
            "starting epoch 17\n",
            "step=170, loss=0.03832395374774933\n",
            "step=171, loss=0.026241526007652283\n",
            "step=172, loss=0.0699397400021553\n",
            "step=173, loss=0.01836138591170311\n",
            "step=174, loss=0.05860127881169319\n",
            "step=175, loss=0.018325507640838623\n",
            "step=176, loss=0.017489729449152946\n",
            "step=177, loss=0.018490208312869072\n",
            "step=178, loss=0.014323261566460133\n",
            "step=179, loss=0.013486470095813274\n",
            "starting epoch 18\n",
            "step=180, loss=0.016694223508238792\n",
            "step=181, loss=0.013115172274410725\n",
            "step=182, loss=0.034832511097192764\n",
            "step=183, loss=0.009571398608386517\n",
            "step=184, loss=0.0307565089315176\n",
            "step=185, loss=0.007578036282211542\n",
            "step=186, loss=0.0072209774516522884\n",
            "step=187, loss=0.00762914726510644\n",
            "step=188, loss=0.006583090405911207\n",
            "step=189, loss=0.006611695047467947\n",
            "starting epoch 19\n",
            "step=190, loss=0.010540422052145004\n",
            "step=191, loss=0.00940848607569933\n",
            "step=192, loss=0.02012576162815094\n",
            "step=193, loss=0.006525758188217878\n",
            "step=194, loss=0.01740238629281521\n",
            "step=195, loss=0.0049327160231769085\n",
            "step=196, loss=0.0048207929357886314\n",
            "step=197, loss=0.0052036442793905735\n",
            "step=198, loss=0.0047072055749595165\n",
            "step=199, loss=0.004804616328328848\n",
            "final_accuracy=1.0\n"
          ]
        }
      ],
      "source": [
        "main()  # All right, let's run the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0V60DAcnKLO"
      },
      "outputs": [],
      "source": [
        "model = RNN(in_size=2, out_size=1, hidden_size=32, key=model_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVejaZOWnKLO",
        "outputId": "002cab26-af7d-4148-e2cd-addec8c1fa86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cell.input_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms0zaTFxnKLO",
        "outputId": "2717a4ca-e21a-4c17-eef5-c5113cc4c5e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96, 32)"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cell.weight_hh.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5yLaXuTnKLO",
        "outputId": "cb405048-63da-4e1b-c377-19b0c6682875"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96, 2)"
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cell.weight_ih.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO00No_7nKLO",
        "outputId": "f7723d1e-3b9b-479e-d4e7-e1ec79335b7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([0.47193635], dtype=float32)"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(xs[0][:2, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB4Z87IgnKLO",
        "outputId": "cfaaa384-749a-4bb1-b713-a2584def0a67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[-0.8662967 ,  0.49952984],\n",
              "       [-0.6736304 ,  0.0267801 ]], dtype=float32)"
            ]
          },
          "execution_count": 224,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs[0][:2, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqAESIgsnKLO",
        "outputId": "38961071-ac6d-4c00-a897-b0109c5610fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[-0.8662967 ,  0.49952984],\n",
              "       [-0.6736304 ,  0.0267801 ],\n",
              "       [-0.45926854, -0.21823113],\n",
              "       [-0.24502712, -0.3264408 ],\n",
              "       [-0.05450387, -0.33652925],\n",
              "       [ 0.09283558, -0.2775747 ],\n",
              "       [ 0.18502338, -0.17752427],\n",
              "       [ 0.21916799, -0.06335385],\n",
              "       [ 0.20130827,  0.04121126],\n",
              "       [ 0.1447245 ,  0.11829499],\n",
              "       [ 0.06710994,  0.1577503 ],\n",
              "       [-0.01282473,  0.15779418],\n",
              "       [-0.07866701,  0.12425242],\n",
              "       [-0.11894477,  0.06858669]], dtype=float32)"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot96toNinKLO"
      },
      "outputs": [],
      "source": [
        "data_key, model_key = random.split(jax.random.PRNGKey(212), 2)\n",
        "lstmj = LSTMjax(100, 500, 2)\n",
        "params = lstmj.initialize_params(model_key)\n",
        "for i in params.keys():\n",
        "    print(i, params[i].shape)\n",
        "\n",
        "# optimizer\n",
        "# import optax\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "#data_loader = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)\n",
        "\n",
        "# train_size = X_train.shape[0]\n",
        "num_epochs = 500\n",
        "def fit(params: optax.Params, optimizer: optax.GradientTransformation) -> optax.Params:\n",
        "    opt_state = optimizer.init(params)\n",
        "\n",
        "    def l2_loss(params, x, y):\n",
        "        y_pred = lstmj.forward(x, params)\n",
        "        l2 = jnp.mean((y_pred[-3:] - y[-3:])**2)\n",
        "        return l2\n",
        "\n",
        "    @jax.jit\n",
        "    def run_batch(params, opt_state, batch_x, batch_y):\n",
        "        loss_value, grads = jax.value_and_grad(l2_loss)(params, batch_x, batch_y)\n",
        "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "        params = optax.apply_updates(params, updates)\n",
        "        return params, opt_state, loss_value\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        data_loader = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)\n",
        "        j = 0\n",
        "        for batch in data_loader:\n",
        "            params, opt_state, loss_value = run_batch(params, opt_state, batch[0], batch[1])\n",
        "#             if j % 2 == 0:\n",
        "#                 print(f'batch {j}, loss: {loss_value}')\n",
        "#             j += 1\n",
        "        if i % 10 == 0: print(f'epoch {i}, loss: {loss_value}')\n",
        "        i += 1\n",
        "\n",
        "    return params\n",
        "\n",
        "# Fit our parametrized function using the Adam optimizer\n",
        "\n",
        "optimizer = optax.adam(learning_rate=learning_rate)\n",
        "params = fit(params, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DnmTZosnKLP"
      },
      "outputs": [],
      "source": [
        "# apply to spy ts\n",
        "def main_spy(\n",
        "    batch_size=100,\n",
        "    learning_rate=3e-2,\n",
        "    steps=1000,\n",
        "    hidden_size=64,\n",
        "#     depth=1,\n",
        "    seed=5678,\n",
        "):\n",
        "    data_key, model_key = jax.random.split(jax.random.PRNGKey(seed), 2)\n",
        "#     xs, ys = get_data(dataset_size, seq_length=14, key=data_key)\n",
        "    iter_data = dataloader(datasetHL111, batch_size)\n",
        "#     iter_data = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)\n",
        "\n",
        "#    model = RNN(in_size=2, out_size=1, hidden_size=hidden_size, key=model_key)\n",
        "    model = RNNlstm(in_size=2, out_size=2, hidden_size=hidden_size, key=model_key)\n",
        "\n",
        "    @eqx.filter_value_and_grad\n",
        "    def compute_loss(model, x, y):\n",
        "        pred_y = jax.vmap(model)(x)\n",
        "        l2 = jnp.mean((pred_y - y)**2)\n",
        "        return l2\n",
        "#         Trains with respect to binary cross-entropy\n",
        "#         return -jnp.mean(y * jnp.log(pred_y) + (1 - y) * jnp.log(1 - pred_y))\n",
        "\n",
        "    # Important for efficiency whenever you use JAX: wrap everything into a single JIT\n",
        "    # region.\n",
        "    @eqx.filter_jit\n",
        "    def make_step(model, x, y, opt_state):\n",
        "        loss, grads = compute_loss(model, x, y)\n",
        "        updates, opt_state = optim.update(grads, opt_state)\n",
        "        model = eqx.apply_updates(model, updates)\n",
        "        return loss, model, opt_state\n",
        "\n",
        "    optim = optax.adam(learning_rate)\n",
        "    opt_state = optim.init(model)\n",
        "    for step, (x, y) in zip(range(steps), iter_data):\n",
        "        loss, model, opt_state = make_step(model, x, y, opt_state)\n",
        "        loss = loss.item()\n",
        "        if step % 100 == 0: print(f\"step={step}, loss={loss}\")\n",
        "\n",
        "    pred_ys = jax.vmap(model)(xs)\n",
        "#     num_correct = jnp.sum((pred_ys > 0.5) == ys)\n",
        "#     final_accuracy = (num_correct / dataset_size).item()\n",
        "    final_loss = compute_loss(model, datasetHL111[0], datasetHL111[1])\n",
        "    print(f\"final_loss={final_loss}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy_t3WktnKLP",
        "outputId": "41cf61f7-7b92-4240-88f0-1028bd381d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(100, 50, 2)\n",
            "(100, 2)\n",
            "1\n",
            "(100, 50, 2)\n",
            "(100, 2)\n"
          ]
        }
      ],
      "source": [
        "iter_data = dataloader(datasetHL111, 100)\n",
        "for step, (x, y) in zip(range(2), iter_data):\n",
        "    print(step)\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgftCFTknKLP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PymBJ1rnKLP",
        "outputId": "09f51c29-f570-422b-f4d1-4dedd2164e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting epoch 0\n",
            "step=0, loss=1.1267670392990112\n",
            "starting epoch 1\n",
            "starting epoch 2\n",
            "starting epoch 3\n",
            "starting epoch 4\n",
            "starting epoch 5\n",
            "starting epoch 6\n",
            "starting epoch 7\n",
            "step=100, loss=0.0003193573502358049\n",
            "starting epoch 8\n",
            "starting epoch 9\n",
            "starting epoch 10\n",
            "starting epoch 11\n",
            "starting epoch 12\n",
            "starting epoch 13\n",
            "starting epoch 14\n",
            "starting epoch 15\n",
            "step=200, loss=0.0014156115939840674\n",
            "starting epoch 16\n",
            "starting epoch 17\n",
            "starting epoch 18\n",
            "starting epoch 19\n",
            "starting epoch 20\n",
            "starting epoch 21\n",
            "starting epoch 22\n",
            "starting epoch 23\n",
            "step=300, loss=0.00041224464075639844\n",
            "starting epoch 24\n",
            "starting epoch 25\n",
            "starting epoch 26\n",
            "starting epoch 27\n",
            "starting epoch 28\n",
            "starting epoch 29\n",
            "starting epoch 30\n",
            "step=400, loss=0.0006295951316133142\n",
            "starting epoch 31\n",
            "starting epoch 32\n",
            "starting epoch 33\n",
            "starting epoch 34\n",
            "starting epoch 35\n",
            "starting epoch 36\n",
            "starting epoch 37\n",
            "starting epoch 38\n",
            "step=500, loss=0.00031347310869023204\n",
            "starting epoch 39\n",
            "starting epoch 40\n",
            "starting epoch 41\n",
            "starting epoch 42\n",
            "starting epoch 43\n",
            "starting epoch 44\n",
            "starting epoch 45\n",
            "starting epoch 46\n",
            "step=600, loss=0.00015195498417597264\n",
            "starting epoch 47\n",
            "starting epoch 48\n",
            "starting epoch 49\n",
            "starting epoch 50\n",
            "starting epoch 51\n",
            "starting epoch 52\n",
            "starting epoch 53\n",
            "step=700, loss=0.0004832888371311128\n",
            "starting epoch 54\n",
            "starting epoch 55\n",
            "starting epoch 56\n",
            "starting epoch 57\n",
            "starting epoch 58\n",
            "starting epoch 59\n",
            "starting epoch 60\n",
            "starting epoch 61\n",
            "step=800, loss=0.0002076220844173804\n",
            "starting epoch 62\n",
            "starting epoch 63\n",
            "starting epoch 64\n",
            "starting epoch 65\n",
            "starting epoch 66\n",
            "starting epoch 67\n",
            "starting epoch 68\n",
            "starting epoch 69\n",
            "step=900, loss=0.00018414456280879676\n",
            "starting epoch 70\n",
            "starting epoch 71\n",
            "starting epoch 72\n",
            "starting epoch 73\n",
            "starting epoch 74\n",
            "starting epoch 75\n",
            "starting epoch 76\n",
            "final_loss=(Array(0.000441, dtype=float32), RNNlstm(\n",
            "  hidden_size=None,\n",
            "  cell1=LSTMCell(\n",
            "    weight_ih=f32[256,2],\n",
            "    weight_hh=f32[256,64],\n",
            "    bias=f32[256],\n",
            "    input_size=2,\n",
            "    hidden_size=64,\n",
            "    use_bias=True\n",
            "  ),\n",
            "  cell2=LSTMCell(\n",
            "    weight_ih=f32[256,64],\n",
            "    weight_hh=f32[256,64],\n",
            "    bias=f32[256],\n",
            "    input_size=64,\n",
            "    hidden_size=64,\n",
            "    use_bias=True\n",
            "  ),\n",
            "  linear=Linear(\n",
            "    weight=f32[2,64],\n",
            "    bias=f32[2],\n",
            "    in_features=64,\n",
            "    out_features=2,\n",
            "    use_bias=True\n",
            "  )\n",
            "))\n"
          ]
        }
      ],
      "source": [
        "model = main_spy(batch_size=100, steps=1000, hidden_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfC85Z_dnKLP",
        "outputId": "e977d44c-9962-4aaa-d62b-702acd58a9f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1.0074005 , 0.98364043], dtype=float32)"
            ]
          },
          "execution_count": 480,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(datasetHL111[0][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxc0mR8pnKLP",
        "outputId": "988ab0c1-5d42-40ac-d104-511fb1e11b28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[1.0010432 , 1.0071555 ],\n",
              "       [0.98412615, 1.1107165 ],\n",
              "       [0.9957643 , 1.0042644 ],\n",
              "       [1.0199081 , 0.90392786],\n",
              "       [1.0085351 , 0.92660004],\n",
              "       [0.99899024, 1.0190114 ],\n",
              "       [0.9887608 , 1.1057215 ],\n",
              "       [0.993136  , 1.031496  ],\n",
              "       [0.992917  , 1.0954199 ],\n",
              "       [1.0185126 , 0.8556496 ],\n",
              "       [1.0002666 , 0.98778355],\n",
              "       [0.9956147 , 1.0429918 ],\n",
              "       [1.0046724 , 0.9565218 ],\n",
              "       [0.998256  , 0.9994097 ],\n",
              "       [0.9986898 , 1.0059067 ],\n",
              "       [1.00345   , 1.0052848 ],\n",
              "       [0.99331737, 1.0508177 ],\n",
              "       [1.012139  , 0.93774325],\n",
              "       [1.0096332 , 0.9513929 ],\n",
              "       [0.99854493, 1.0473521 ],\n",
              "       [1.0004061 , 1.0237954 ],\n",
              "       [0.98877716, 1.0766997 ],\n",
              "       [0.9927551 , 1.0809498 ],\n",
              "       [1.00866   , 0.9555666 ],\n",
              "       [1.0129507 , 0.93782663],\n",
              "       [1.000381  , 0.97270185],\n",
              "       [0.9944548 , 1.0274915 ],\n",
              "       [1.009501  , 0.87235224],\n",
              "       [1.0144612 , 0.9329074 ],\n",
              "       [0.9980838 , 1.0089041 ],\n",
              "       [1.0021775 , 0.9477258 ],\n",
              "       [0.9965422 , 0.9985673 ],\n",
              "       [1.0060487 , 0.97919655],\n",
              "       [1.0017942 , 1.0131868 ],\n",
              "       [1.0090718 , 1.0853218 ],\n",
              "       [1.0065929 , 0.97335106],\n",
              "       [1.0011908 , 0.95003426],\n",
              "       [1.0123976 , 1.0446686 ],\n",
              "       [0.9965938 , 0.9337931 ],\n",
              "       [0.99481183, 1.0251108 ],\n",
              "       [0.99487627, 0.9510086 ],\n",
              "       [1.0036097 , 0.9780303 ],\n",
              "       [0.99244   , 1.0410534 ],\n",
              "       [0.9959142 , 1.0602679 ],\n",
              "       [1.0109633 , 0.9642105 ],\n",
              "       [1.0005044 , 0.97743815],\n",
              "       [1.0039414 , 1.0081906 ],\n",
              "       [1.0118008 , 1.0036927 ],\n",
              "       [1.0011505 , 0.9985283 ],\n",
              "       [0.9985128 , 1.0449522 ]], dtype=float32)"
            ]
          },
          "execution_count": 464,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL111[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hev9juLnKLP",
        "outputId": "ae8e8689-d98b-4f37-9e91-835d58f9afe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1.0225174 , 0.99747527], dtype=float32)"
            ]
          },
          "execution_count": 478,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasetHL111[1][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4QLv6G2nKLP",
        "outputId": "ba552cb8-4799-48f0-d61b-78063258218d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Ret</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-05-02</th>\n",
              "      <td>0.988761</td>\n",
              "      <td>1.105721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-03</th>\n",
              "      <td>0.993136</td>\n",
              "      <td>1.031496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-04</th>\n",
              "      <td>0.992917</td>\n",
              "      <td>1.095420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-05</th>\n",
              "      <td>1.018513</td>\n",
              "      <td>0.855650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-08</th>\n",
              "      <td>1.000266</td>\n",
              "      <td>0.987784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-09</th>\n",
              "      <td>0.995615</td>\n",
              "      <td>1.042992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-10</th>\n",
              "      <td>1.004672</td>\n",
              "      <td>0.956522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-11</th>\n",
              "      <td>0.998256</td>\n",
              "      <td>0.999410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-12</th>\n",
              "      <td>0.998690</td>\n",
              "      <td>1.005907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-15</th>\n",
              "      <td>1.003450</td>\n",
              "      <td>1.005285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-16</th>\n",
              "      <td>0.993317</td>\n",
              "      <td>1.050818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-17</th>\n",
              "      <td>1.012139</td>\n",
              "      <td>0.937743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-18</th>\n",
              "      <td>1.009633</td>\n",
              "      <td>0.951393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-19</th>\n",
              "      <td>0.998545</td>\n",
              "      <td>1.047352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-22</th>\n",
              "      <td>1.000406</td>\n",
              "      <td>1.023795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-23</th>\n",
              "      <td>0.988777</td>\n",
              "      <td>1.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-24</th>\n",
              "      <td>0.992755</td>\n",
              "      <td>1.080950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-25</th>\n",
              "      <td>1.008660</td>\n",
              "      <td>0.955567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-26</th>\n",
              "      <td>1.012951</td>\n",
              "      <td>0.937827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-30</th>\n",
              "      <td>1.000381</td>\n",
              "      <td>0.972702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-31</th>\n",
              "      <td>0.994455</td>\n",
              "      <td>1.027491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-01</th>\n",
              "      <td>1.009501</td>\n",
              "      <td>0.872352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-02</th>\n",
              "      <td>1.014461</td>\n",
              "      <td>0.932907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-05</th>\n",
              "      <td>0.998084</td>\n",
              "      <td>1.008904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-06</th>\n",
              "      <td>1.002177</td>\n",
              "      <td>0.947726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-07</th>\n",
              "      <td>0.996542</td>\n",
              "      <td>0.998567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-08</th>\n",
              "      <td>1.006049</td>\n",
              "      <td>0.979197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-09</th>\n",
              "      <td>1.001794</td>\n",
              "      <td>1.013187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-12</th>\n",
              "      <td>1.009072</td>\n",
              "      <td>1.085322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-13</th>\n",
              "      <td>1.006593</td>\n",
              "      <td>0.973351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-14</th>\n",
              "      <td>1.001191</td>\n",
              "      <td>0.950034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-15</th>\n",
              "      <td>1.012398</td>\n",
              "      <td>1.044669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-16</th>\n",
              "      <td>0.996594</td>\n",
              "      <td>0.933793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-20</th>\n",
              "      <td>0.994812</td>\n",
              "      <td>1.025111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-21</th>\n",
              "      <td>0.994876</td>\n",
              "      <td>0.951009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-22</th>\n",
              "      <td>1.003610</td>\n",
              "      <td>0.978030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-23</th>\n",
              "      <td>0.992440</td>\n",
              "      <td>1.041053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-26</th>\n",
              "      <td>0.995914</td>\n",
              "      <td>1.060268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-27</th>\n",
              "      <td>1.010963</td>\n",
              "      <td>0.964211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-28</th>\n",
              "      <td>1.000504</td>\n",
              "      <td>0.977438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-29</th>\n",
              "      <td>1.003941</td>\n",
              "      <td>1.008191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30</th>\n",
              "      <td>1.011801</td>\n",
              "      <td>1.003693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-03</th>\n",
              "      <td>1.001151</td>\n",
              "      <td>0.998528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-05</th>\n",
              "      <td>0.998513</td>\n",
              "      <td>1.044952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-06</th>\n",
              "      <td>0.992169</td>\n",
              "      <td>1.088857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-07</th>\n",
              "      <td>0.997475</td>\n",
              "      <td>0.960492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-10</th>\n",
              "      <td>1.002531</td>\n",
              "      <td>1.016183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-11</th>\n",
              "      <td>1.006369</td>\n",
              "      <td>0.984738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-12</th>\n",
              "      <td>1.008046</td>\n",
              "      <td>0.912399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-13</th>\n",
              "      <td>1.007937</td>\n",
              "      <td>1.005170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Ret          \n",
              "                 SPY      ^VIX\n",
              "Date                          \n",
              "2023-05-02  0.988761  1.105721\n",
              "2023-05-03  0.993136  1.031496\n",
              "2023-05-04  0.992917  1.095420\n",
              "2023-05-05  1.018513  0.855650\n",
              "2023-05-08  1.000266  0.987784\n",
              "2023-05-09  0.995615  1.042992\n",
              "2023-05-10  1.004672  0.956522\n",
              "2023-05-11  0.998256  0.999410\n",
              "2023-05-12  0.998690  1.005907\n",
              "2023-05-15  1.003450  1.005285\n",
              "2023-05-16  0.993317  1.050818\n",
              "2023-05-17  1.012139  0.937743\n",
              "2023-05-18  1.009633  0.951393\n",
              "2023-05-19  0.998545  1.047352\n",
              "2023-05-22  1.000406  1.023795\n",
              "2023-05-23  0.988777  1.076700\n",
              "2023-05-24  0.992755  1.080950\n",
              "2023-05-25  1.008660  0.955567\n",
              "2023-05-26  1.012951  0.937827\n",
              "2023-05-30  1.000381  0.972702\n",
              "2023-05-31  0.994455  1.027491\n",
              "2023-06-01  1.009501  0.872352\n",
              "2023-06-02  1.014461  0.932907\n",
              "2023-06-05  0.998084  1.008904\n",
              "2023-06-06  1.002177  0.947726\n",
              "2023-06-07  0.996542  0.998567\n",
              "2023-06-08  1.006049  0.979197\n",
              "2023-06-09  1.001794  1.013187\n",
              "2023-06-12  1.009072  1.085322\n",
              "2023-06-13  1.006593  0.973351\n",
              "2023-06-14  1.001191  0.950034\n",
              "2023-06-15  1.012398  1.044669\n",
              "2023-06-16  0.996594  0.933793\n",
              "2023-06-20  0.994812  1.025111\n",
              "2023-06-21  0.994876  0.951009\n",
              "2023-06-22  1.003610  0.978030\n",
              "2023-06-23  0.992440  1.041053\n",
              "2023-06-26  0.995914  1.060268\n",
              "2023-06-27  1.010963  0.964211\n",
              "2023-06-28  1.000504  0.977438\n",
              "2023-06-29  1.003941  1.008191\n",
              "2023-06-30  1.011801  1.003693\n",
              "2023-07-03  1.001151  0.998528\n",
              "2023-07-05  0.998513  1.044952\n",
              "2023-07-06  0.992169  1.088857\n",
              "2023-07-07  0.997475  0.960492\n",
              "2023-07-10  1.002531  1.016183\n",
              "2023-07-11  1.006369  0.984738\n",
              "2023-07-12  1.008046  0.912399\n",
              "2023-07-13  1.007937  1.005170"
            ]
          },
          "execution_count": 479,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[[('Ret', 'SPY'), ('Ret', '^VIX')]].tail(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6Gj8ufknKLP",
        "outputId": "dc7683f1-c592-4045-ed66-1218af01a8f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([1.0061555, 0.9840479], dtype=float32)"
            ]
          },
          "execution_count": 481,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(jnp.array(data[[('Ret', 'SPY'), ('Ret', '^VIX')]].tail(50)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHcXt_1jnKLP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nDLRUlvnKLP"
      },
      "source": [
        "#### Walk forward train/test cycle for a specified date range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE22HSpvnKLP"
      },
      "outputs": [],
      "source": [
        "def main_spy_wf(\n",
        "    date,\n",
        "    data, # pandas df\n",
        "    batch_size=50,\n",
        "    learning_rate=3e-2,\n",
        "    steps=100,\n",
        "    hidden_size=16,\n",
        "#     depth=1,\n",
        "    seed=5678,\n",
        "):\n",
        "    data_key, model_key = jax.random.split(jax.random.PRNGKey(seed), 2)\n",
        "    dset_trainTS, test_x = prepTrainigSetAtDate(date, data, batch_size=batch_size)\n",
        "#     iter_data = dataloader(dset_trainTS, batch_size)\n",
        "#     iter_data = DataLoaderXY(datasetHL[0], datasetHL[1], batch_size=batch_size)\n",
        "\n",
        "#    model = RNN(in_size=2, out_size=1, hidden_size=hidden_size, key=model_key)\n",
        "    model = RNNlstm(in_size=2, out_size=2, hidden_size=hidden_size, key=model_key)\n",
        "\n",
        "    @eqx.filter_value_and_grad\n",
        "    def compute_loss(model, x, y):\n",
        "        pred_y = jax.vmap(model)(x)\n",
        "        l2 = jnp.mean((pred_y - y)**2)\n",
        "        return l2\n",
        "#         Trains with respect to binary cross-entropy\n",
        "#         return -jnp.mean(y * jnp.log(pred_y) + (1 - y) * jnp.log(1 - pred_y))\n",
        "\n",
        "    # Important for efficiency whenever you use JAX: wrap everything into a single JIT\n",
        "    # region.\n",
        "    @eqx.filter_jit\n",
        "    def make_step(model, x, y, opt_state):\n",
        "        loss, grads = compute_loss(model, x, y)\n",
        "        updates, opt_state = optim.update(grads, opt_state)\n",
        "        model = eqx.apply_updates(model, updates)\n",
        "        return loss, model, opt_state\n",
        "\n",
        "    optim = optax.adam(learning_rate)\n",
        "    opt_state = optim.init(model)\n",
        "    for step in range(steps):\n",
        "        # use full training data in every step\n",
        "        loss, model, opt_state = make_step(model, dset_trainTS[0], dset_trainTS[1], opt_state)\n",
        "        loss = loss.item()\n",
        "        if step % 10 == 0: print(f\"step={step}, loss={loss}\")\n",
        "\n",
        "    pred_y = model(test_x)\n",
        "#     final_loss = compute_loss(model, datasetHL111[0], datasetHL111[1])\n",
        "#     print(f\"final_loss={final_loss}\")\n",
        "#     return model\n",
        "    return pred_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXbNTteVnKLP"
      },
      "outputs": [],
      "source": [
        "# dset_trainTS, test_x = prepTrainigSetAtDate('2023-07-14', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us_4MSFEnKLP",
        "outputId": "294302ad-725f-4dc6-f3ef-77fb21000653"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m main_spy_wf(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-07-14\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 3\u001b[0m     data, \u001b[38;5;66;03m# pandas df\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-2\u001b[39m,\n\u001b[1;32m      6\u001b[0m     steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      8\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m212\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mexp(pred_y)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "pred_y = main_spy_wf(\n",
        "    '2023-07-14',\n",
        "    data, # pandas df\n",
        "    batch_size=50,\n",
        "    learning_rate=3e-2,\n",
        "    steps=200,\n",
        "    hidden_size=16,\n",
        "    seed=212,\n",
        ")\n",
        "np.exp(pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt39e7-rnKLP",
        "outputId": "fe67d101-c6c7-4132-8fa6-06a05b07d9f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatetimeIndex(['2023-05-01', '2023-05-02', '2023-05-03', '2023-05-04',\n",
              "               '2023-05-05', '2023-05-08', '2023-05-09', '2023-05-10',\n",
              "               '2023-05-11', '2023-05-12', '2023-05-15', '2023-05-16',\n",
              "               '2023-05-17', '2023-05-18', '2023-05-19', '2023-05-22',\n",
              "               '2023-05-23', '2023-05-24', '2023-05-25', '2023-05-26',\n",
              "               '2023-05-30', '2023-05-31', '2023-06-01', '2023-06-02',\n",
              "               '2023-06-05', '2023-06-06', '2023-06-07', '2023-06-08',\n",
              "               '2023-06-09', '2023-06-12', '2023-06-13', '2023-06-14',\n",
              "               '2023-06-15', '2023-06-16', '2023-06-20', '2023-06-21',\n",
              "               '2023-06-22', '2023-06-23', '2023-06-26', '2023-06-27',\n",
              "               '2023-06-28', '2023-06-29', '2023-06-30', '2023-07-03',\n",
              "               '2023-07-05', '2023-07-06', '2023-07-07'],\n",
              "              dtype='datetime64[ns]', freq=None)"
            ]
          },
          "execution_count": 713,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dates = pd.date_range(start='2023-05-01', end='2023-07-07', freq='B')\n",
        "dates = dates[dates.isin(data.index)]\n",
        "dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLeznGemnKLP",
        "outputId": "c50c0533-1f6b-4706-da73-d9c3575d86bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step=0, loss=0.0017501869006082416\n",
            "step=10, loss=5.610095024108887\n",
            "step=20, loss=0.13103024661540985\n",
            "step=30, loss=0.0064748660661280155\n",
            "step=40, loss=0.0018381845438852906\n",
            "step=50, loss=0.003777878126129508\n",
            "step=60, loss=0.0022188262082636356\n",
            "step=70, loss=0.0002897168742492795\n",
            "step=80, loss=0.00019555793551262468\n",
            "step=90, loss=9.576497541274875e-05\n",
            "step=100, loss=7.0026952016633e-05\n",
            "step=110, loss=4.091154187335633e-05\n",
            "step=120, loss=4.1840074118226767e-05\n",
            "step=130, loss=4.084798274561763e-05\n",
            "step=140, loss=3.9362192183034495e-05\n",
            "step=150, loss=3.9078073314158246e-05\n",
            "step=160, loss=3.892123277182691e-05\n",
            "step=170, loss=3.88242733606603e-05\n",
            "step=180, loss=3.8744121411582455e-05\n",
            "step=190, loss=3.866172846755944e-05\n",
            "[ 0.01030557 -0.00679606]\n",
            "step=0, loss=0.0017467342549934983\n",
            "step=10, loss=0.2811931073665619\n",
            "step=20, loss=0.05880257487297058\n",
            "step=30, loss=0.01422820519655943\n",
            "step=40, loss=0.003423547837883234\n",
            "step=50, loss=0.002292012330144644\n",
            "step=60, loss=0.00017649811343289912\n",
            "step=70, loss=0.00033064736635424197\n",
            "step=80, loss=0.000139026073156856\n",
            "step=90, loss=0.00010877503518713638\n",
            "step=100, loss=7.856232696212828e-05\n",
            "step=110, loss=6.64371473249048e-05\n",
            "step=120, loss=6.379256956279278e-05\n",
            "step=130, loss=6.281132664298639e-05\n",
            "step=140, loss=6.264802505029365e-05\n",
            "step=150, loss=6.263889372348785e-05\n",
            "step=160, loss=6.256231426959857e-05\n",
            "step=170, loss=6.256306369323283e-05\n",
            "step=180, loss=6.255599873838946e-05\n",
            "step=190, loss=6.25554021098651e-05\n",
            "[ 0.00527565 -0.00426789]\n",
            "step=0, loss=0.001763401203788817\n",
            "step=10, loss=6.529541969299316\n",
            "step=20, loss=1.1598249673843384\n",
            "step=30, loss=0.20890991389751434\n",
            "step=40, loss=0.005810603033751249\n",
            "step=50, loss=0.046647850424051285\n",
            "step=60, loss=0.011276029981672764\n",
            "step=70, loss=0.001272575231269002\n",
            "step=80, loss=0.00243377685546875\n",
            "step=90, loss=0.00011655988782877102\n",
            "step=100, loss=0.0003162965876981616\n",
            "step=110, loss=9.205926471622661e-05\n",
            "step=120, loss=4.9231050070375204e-05\n",
            "step=130, loss=5.598003190243617e-05\n",
            "step=140, loss=4.3061794713139534e-05\n",
            "step=150, loss=4.0855917177395895e-05\n",
            "step=160, loss=4.121455640415661e-05\n",
            "step=170, loss=4.105125117348507e-05\n",
            "step=180, loss=4.087309571332298e-05\n",
            "step=190, loss=4.081163933733478e-05\n",
            "[ 0.01245075 -0.02230461]\n",
            "step=0, loss=0.0018684035167098045\n",
            "step=10, loss=0.49444371461868286\n",
            "step=20, loss=0.007090231869369745\n",
            "step=30, loss=0.0034902708139270544\n",
            "step=40, loss=0.017611270770430565\n",
            "step=50, loss=0.010142688639461994\n",
            "step=60, loss=0.003925589378923178\n",
            "step=70, loss=0.0014379703206941485\n",
            "step=80, loss=0.0004624182474799454\n",
            "step=90, loss=0.00010053153528133407\n",
            "step=100, loss=4.6388788177864626e-05\n",
            "step=110, loss=6.280431989580393e-05\n",
            "step=120, loss=4.866776362177916e-05\n",
            "step=130, loss=4.4321139284875244e-05\n",
            "step=140, loss=4.45994664914906e-05\n",
            "step=150, loss=4.376620927359909e-05\n",
            "step=160, loss=4.376483411761001e-05\n",
            "step=170, loss=4.371638715383597e-05\n",
            "step=180, loss=4.367985820863396e-05\n",
            "step=190, loss=4.368132067611441e-05\n",
            "[-0.00221404 -0.0110548 ]\n",
            "step=0, loss=0.002044354798272252\n",
            "step=10, loss=1.4314645528793335\n",
            "step=20, loss=0.02345733530819416\n",
            "step=30, loss=0.02655952051281929\n",
            "step=40, loss=0.015313083305954933\n",
            "step=50, loss=0.000602168554905802\n",
            "step=60, loss=0.0016458906466141343\n",
            "step=70, loss=0.00027430569753050804\n",
            "step=80, loss=0.000318416568916291\n",
            "step=90, loss=9.565177606418729e-05\n",
            "step=100, loss=3.577677489374764e-05\n",
            "step=110, loss=3.360732807777822e-05\n",
            "step=120, loss=3.315232606837526e-05\n",
            "step=130, loss=3.222121449653059e-05\n",
            "step=140, loss=3.240373916924e-05\n",
            "step=150, loss=3.23226377076935e-05\n",
            "step=160, loss=3.219343125238083e-05\n",
            "step=170, loss=3.214202661183663e-05\n",
            "step=180, loss=3.214452226529829e-05\n",
            "step=190, loss=3.2137577363755554e-05\n",
            "[ 0.00173947 -0.01780803]\n",
            "step=0, loss=0.002234006067737937\n",
            "step=10, loss=0.09428949654102325\n",
            "step=20, loss=0.002808263525366783\n",
            "step=30, loss=0.0031451599206775427\n",
            "step=40, loss=0.0002820008376147598\n",
            "step=50, loss=0.0001487614936195314\n",
            "step=60, loss=0.0001312551903538406\n",
            "step=70, loss=5.515252269105986e-05\n",
            "step=80, loss=2.217042310803663e-05\n",
            "step=90, loss=1.3850432878825814e-05\n",
            "step=100, loss=1.5520990928052925e-05\n",
            "step=110, loss=1.391287241858663e-05\n",
            "step=120, loss=1.3538049643102568e-05\n",
            "step=130, loss=1.3379122719925363e-05\n",
            "step=140, loss=1.3381823919189628e-05\n",
            "step=150, loss=1.3335084076970816e-05\n",
            "step=160, loss=1.3313090676092543e-05\n",
            "step=170, loss=1.3300086720846593e-05\n",
            "step=180, loss=1.3288806258060504e-05\n",
            "step=190, loss=1.3278545338835102e-05\n",
            "[ 0.0031168  -0.02040456]\n",
            "step=0, loss=0.0024088830687105656\n",
            "step=10, loss=0.06505337357521057\n",
            "step=20, loss=0.29083451628685\n",
            "step=30, loss=0.11684741079807281\n",
            "step=40, loss=0.04169195890426636\n",
            "step=50, loss=0.013652640394866467\n",
            "step=60, loss=0.004908911418169737\n",
            "step=70, loss=0.0016813442343845963\n",
            "step=80, loss=0.00045223167398944497\n",
            "step=90, loss=0.00018906363402493298\n",
            "step=100, loss=0.00013041292550042272\n",
            "step=110, loss=7.512958109145984e-05\n",
            "step=120, loss=7.14568595867604e-05\n",
            "step=130, loss=6.243915413506329e-05\n",
            "step=140, loss=6.254861364141107e-05\n",
            "step=150, loss=6.140872574178502e-05\n",
            "step=160, loss=6.10757851973176e-05\n",
            "step=170, loss=6.104526983108371e-05\n",
            "step=180, loss=6.0935541114304215e-05\n",
            "step=190, loss=6.084365304559469e-05\n",
            "[ 0.0085724  -0.01811066]\n",
            "step=0, loss=0.002580583794042468\n",
            "step=10, loss=1.334443211555481\n",
            "step=20, loss=0.5480811595916748\n",
            "step=30, loss=0.569619357585907\n",
            "step=40, loss=0.3359639346599579\n",
            "step=50, loss=0.9727634787559509\n",
            "step=60, loss=1.1727386713027954\n",
            "step=70, loss=0.41654887795448303\n",
            "step=80, loss=0.03173218294978142\n",
            "step=90, loss=0.012739084661006927\n",
            "step=100, loss=0.017990661785006523\n",
            "step=110, loss=0.004405611660331488\n",
            "step=120, loss=0.0005337334587238729\n",
            "step=130, loss=0.0002583642490208149\n",
            "step=140, loss=0.00023545305884908885\n",
            "step=150, loss=0.00019467120000626892\n",
            "step=160, loss=0.00017016497440636158\n",
            "step=170, loss=0.0001597645168658346\n",
            "step=180, loss=0.0001559613592689857\n",
            "step=190, loss=0.00015476909175049514\n",
            "[ 0.00762181 -0.00549595]\n",
            "step=0, loss=0.0026444413233548403\n",
            "step=10, loss=7.145881652832031\n",
            "step=20, loss=0.6433740854263306\n",
            "step=30, loss=0.17161880433559418\n",
            "step=40, loss=0.2943154275417328\n",
            "step=50, loss=0.027853338047862053\n",
            "step=60, loss=0.02868177369236946\n",
            "step=70, loss=0.0045687174424529076\n",
            "step=80, loss=0.004624081309884787\n",
            "step=90, loss=0.0005446758586913347\n",
            "step=100, loss=0.0004359144368208945\n",
            "step=110, loss=0.00030668333056382835\n",
            "step=120, loss=0.00015884409367572516\n",
            "step=130, loss=0.00011375353642506525\n",
            "step=140, loss=0.00010586142161628231\n",
            "step=150, loss=0.00010460051998961717\n",
            "step=160, loss=0.00010413098061690107\n",
            "step=170, loss=0.0001038593691191636\n",
            "step=180, loss=0.00010372243559686467\n",
            "step=190, loss=0.00010366329661337659\n",
            "[ 0.01548067 -0.01055808]\n",
            "step=0, loss=0.0026065499987453222\n",
            "step=10, loss=0.6785432696342468\n",
            "step=20, loss=0.04638497158885002\n",
            "step=30, loss=0.012727341614663601\n",
            "step=40, loss=0.018594780936837196\n",
            "step=50, loss=0.002318593906238675\n",
            "step=60, loss=0.00354590080678463\n",
            "step=70, loss=0.0011236744467169046\n",
            "step=80, loss=0.00032208181801252067\n",
            "step=90, loss=0.00025249223108403385\n",
            "step=100, loss=0.00018871563952416182\n",
            "step=110, loss=0.0001718527782941237\n",
            "step=120, loss=0.0001521103986306116\n",
            "step=130, loss=0.0001490582653786987\n",
            "step=140, loss=0.0001494021707912907\n",
            "step=150, loss=0.00014825908874627203\n",
            "step=160, loss=0.0001481542713008821\n",
            "step=170, loss=0.000147905113408342\n",
            "step=180, loss=0.0001477631740272045\n",
            "step=190, loss=0.00014762618229724467\n",
            "[ 0.01412281 -0.01224361]\n",
            "step=0, loss=0.0025129204150289297\n",
            "step=10, loss=0.16695857048034668\n",
            "step=20, loss=0.136824831366539\n",
            "step=30, loss=0.03890189528465271\n",
            "step=40, loss=0.014337501488626003\n",
            "step=50, loss=0.0035268545616418123\n",
            "step=60, loss=0.0002153615205315873\n",
            "step=70, loss=0.0007976456545293331\n",
            "step=80, loss=0.000248162163188681\n",
            "step=90, loss=0.0002750288404058665\n",
            "step=100, loss=0.00018887105397880077\n",
            "step=110, loss=0.0001937643246492371\n",
            "step=120, loss=0.0001914204767672345\n",
            "step=130, loss=0.0001878088223747909\n",
            "step=140, loss=0.00018614291911944747\n",
            "step=150, loss=0.00018521968740969896\n",
            "step=160, loss=0.0001844693615566939\n",
            "step=170, loss=0.00018375217041466385\n",
            "step=180, loss=0.0001830398105084896\n",
            "step=190, loss=0.00018232781440019608\n",
            "[ 0.0086188 -0.0119462]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step=0, loss=0.00234016845934093\n",
            "step=10, loss=0.1465047150850296\n",
            "step=20, loss=0.6615361571311951\n",
            "step=30, loss=0.105466328561306\n",
            "step=40, loss=0.02620530128479004\n",
            "step=50, loss=0.03808169439435005\n",
            "step=60, loss=0.011398420669138432\n",
            "step=70, loss=0.002466653473675251\n",
            "step=80, loss=0.0007538283243775368\n",
            "step=90, loss=0.0003835064417216927\n",
            "step=100, loss=0.0002581873850431293\n",
            "step=110, loss=0.00020327884703874588\n",
            "step=120, loss=0.0001768302608979866\n",
            "step=130, loss=0.00016079725173767656\n",
            "step=140, loss=0.0001534046168671921\n",
            "step=150, loss=0.00015343433187808841\n",
            "step=160, loss=0.00015319041267503053\n",
            "step=170, loss=0.00015275442274287343\n",
            "step=180, loss=0.00015281359083019197\n",
            "step=190, loss=0.00015274992620106786\n",
            "[ 0.00690245 -0.01474823]\n",
            "step=0, loss=0.0021959152072668076\n",
            "step=10, loss=1.4596799612045288\n",
            "step=20, loss=0.03293544426560402\n",
            "step=30, loss=0.0030812197364866734\n",
            "step=40, loss=0.001476626144722104\n",
            "step=50, loss=0.0006630904972553253\n",
            "step=60, loss=0.00023721174511592835\n",
            "step=70, loss=7.544054096797481e-05\n",
            "step=80, loss=6.66648120386526e-05\n",
            "step=90, loss=4.001309207524173e-05\n",
            "step=100, loss=3.412388468859717e-05\n",
            "step=110, loss=3.093042323598638e-05\n",
            "step=120, loss=2.7731786758522503e-05\n",
            "step=130, loss=2.6326762963435613e-05\n",
            "step=140, loss=2.465213583491277e-05\n",
            "step=150, loss=2.3064714696374722e-05\n",
            "step=160, loss=2.1538895452977158e-05\n",
            "step=170, loss=2.0020990632474422e-05\n",
            "step=180, loss=1.850595072028227e-05\n",
            "step=190, loss=1.7006021153065376e-05\n",
            "[ 0.00198843 -0.01976109]\n",
            "step=0, loss=0.0021573598496615887\n",
            "step=10, loss=1.4167203903198242\n",
            "step=20, loss=1.273990511894226\n",
            "step=30, loss=2.832152843475342\n",
            "step=40, loss=0.3032824397087097\n",
            "step=50, loss=0.033973872661590576\n",
            "step=60, loss=0.09820898622274399\n",
            "step=70, loss=0.06648784130811691\n",
            "step=80, loss=0.025927448645234108\n",
            "step=90, loss=0.006592392921447754\n",
            "step=100, loss=0.0033170394599437714\n",
            "step=110, loss=0.0005238897865638137\n",
            "step=120, loss=0.00030047507607378066\n",
            "step=130, loss=0.00020913015760015696\n",
            "step=140, loss=0.0001893509761430323\n",
            "step=150, loss=0.00015787074516993016\n",
            "step=160, loss=0.0001535253832116723\n",
            "step=170, loss=0.00015140362665988505\n",
            "step=180, loss=0.00014944122813176364\n",
            "step=190, loss=0.0001494542957516387\n",
            "[ 0.00635068 -0.01263023]\n",
            "step=0, loss=0.0020002571400254965\n",
            "step=10, loss=0.5701740384101868\n",
            "step=20, loss=0.08316931873559952\n",
            "step=30, loss=0.01641642116010189\n",
            "step=40, loss=0.03444831445813179\n",
            "step=50, loss=0.0037282630801200867\n",
            "step=60, loss=0.003458193736150861\n",
            "step=70, loss=0.0002616949495859444\n",
            "step=80, loss=0.0006785981822758913\n",
            "step=90, loss=0.0003382223076187074\n",
            "step=100, loss=0.00018059516150970012\n",
            "step=110, loss=0.0001418729079887271\n",
            "step=120, loss=0.00013365309860091656\n",
            "step=130, loss=0.0001318004069617018\n",
            "step=140, loss=0.00012879374844487756\n",
            "step=150, loss=0.00012683319800999016\n",
            "step=160, loss=0.00012532055552583188\n",
            "step=170, loss=0.00012414270895533264\n",
            "step=180, loss=0.0001229214685736224\n",
            "step=190, loss=0.00012174151925137267\n",
            "[ 0.00513637 -0.00681491]\n",
            "step=0, loss=0.0019022884080186486\n",
            "step=10, loss=0.09119997918605804\n",
            "step=20, loss=0.023032648488879204\n",
            "step=30, loss=0.009149990975856781\n",
            "step=40, loss=0.06718193739652634\n",
            "step=50, loss=0.017916424199938774\n",
            "step=60, loss=0.005338693503290415\n",
            "step=70, loss=0.0020823366940021515\n",
            "step=80, loss=0.0006623833905905485\n",
            "step=90, loss=0.00041000806959345937\n",
            "step=100, loss=0.00014841754455119371\n",
            "step=110, loss=9.442047303309664e-05\n",
            "step=120, loss=6.827893230365589e-05\n",
            "step=130, loss=7.194066711235791e-05\n",
            "step=140, loss=6.877989653730765e-05\n",
            "step=150, loss=6.764299905626103e-05\n",
            "step=160, loss=6.710550223942846e-05\n",
            "step=170, loss=6.705449777655303e-05\n",
            "step=180, loss=6.690233567496762e-05\n",
            "step=190, loss=6.68484135530889e-05\n",
            "[ 0.00745173 -0.00313669]\n",
            "step=0, loss=0.0018635548185557127\n",
            "step=10, loss=0.9186917543411255\n",
            "step=20, loss=0.041078586131334305\n",
            "step=30, loss=0.578373908996582\n",
            "step=40, loss=2.2645015716552734\n",
            "step=50, loss=0.717414379119873\n",
            "step=60, loss=0.24775998294353485\n",
            "step=70, loss=0.1488254815340042\n",
            "step=80, loss=0.05125027894973755\n",
            "step=90, loss=0.014145015738904476\n",
            "step=100, loss=0.003900192677974701\n",
            "step=110, loss=0.0008335857419297099\n",
            "step=120, loss=0.00024389509053435177\n",
            "step=130, loss=0.00031408126233145595\n",
            "step=140, loss=0.0002477130910847336\n",
            "step=150, loss=0.00018854282097890973\n",
            "step=160, loss=0.00017664283222984523\n",
            "step=170, loss=0.00016225301078520715\n",
            "step=180, loss=0.00016146378766279668\n",
            "step=190, loss=0.00016023304488044232\n",
            "[0.00047454 0.00910233]\n",
            "step=0, loss=0.001827344996854663\n",
            "step=10, loss=0.03268790617585182\n",
            "step=20, loss=0.007821437902748585\n",
            "step=30, loss=0.0027673719450831413\n",
            "step=40, loss=0.0026531710755079985\n",
            "step=50, loss=0.00014502060366794467\n",
            "step=60, loss=0.0002521516289561987\n",
            "step=70, loss=0.00014525583537761122\n",
            "step=80, loss=5.467821756610647e-05\n",
            "step=90, loss=5.879793025087565e-05\n",
            "step=100, loss=4.9918216973310336e-05\n",
            "step=110, loss=4.802156036021188e-05\n",
            "step=120, loss=4.756706766784191e-05\n",
            "step=130, loss=4.724816244561225e-05\n",
            "step=140, loss=4.712591180577874e-05\n",
            "step=150, loss=4.7075995098566636e-05\n",
            "step=160, loss=4.70467348350212e-05\n",
            "step=170, loss=4.7024870582390577e-05\n",
            "step=180, loss=4.7008212277432904e-05\n",
            "step=190, loss=4.699191413237713e-05\n",
            "[ 0.00690891 -0.0012677 ]\n",
            "step=0, loss=0.0018654624000191689\n",
            "step=10, loss=0.010035648010671139\n",
            "step=20, loss=0.01238708384335041\n",
            "step=30, loss=0.00034023771877400577\n",
            "step=40, loss=0.00047193176578730345\n",
            "step=50, loss=0.00022051483392715454\n",
            "step=60, loss=8.686345245223492e-05\n",
            "step=70, loss=6.283214315772057e-05\n",
            "step=80, loss=5.165988841326907e-05\n",
            "step=90, loss=4.55972840427421e-05\n",
            "step=100, loss=4.4466982217272744e-05\n",
            "step=110, loss=4.39496616309043e-05\n",
            "step=120, loss=4.3600091885309666e-05\n",
            "step=130, loss=4.342896136222407e-05\n",
            "step=140, loss=4.329517105361447e-05\n",
            "step=150, loss=4.318122228141874e-05\n",
            "step=160, loss=4.306960181565955e-05\n",
            "step=170, loss=4.29637948400341e-05\n",
            "step=180, loss=4.285953764338046e-05\n",
            "step=190, loss=4.275680839782581e-05\n",
            "[0.00118573 0.00423041]\n",
            "step=0, loss=0.0019116480834782124\n",
            "step=10, loss=1.2550733089447021\n",
            "step=20, loss=0.16035592555999756\n",
            "step=30, loss=0.09151562303304672\n",
            "step=40, loss=0.030176464468240738\n",
            "step=50, loss=0.0011478171218186617\n",
            "step=60, loss=0.003484658896923065\n",
            "step=70, loss=0.0008311073761433363\n",
            "step=80, loss=0.0002092879731208086\n",
            "step=90, loss=0.0002511957718525082\n",
            "step=100, loss=9.995675645768642e-05\n",
            "step=110, loss=4.385010106489062e-05\n",
            "step=120, loss=3.4540156775619835e-05\n",
            "step=130, loss=3.0460787456831895e-05\n",
            "step=140, loss=2.8053418645868078e-05\n",
            "step=150, loss=2.72361849056324e-05\n",
            "step=160, loss=2.717456482059788e-05\n",
            "step=170, loss=2.7100701117888093e-05\n",
            "step=180, loss=2.706170744204428e-05\n",
            "step=190, loss=2.7064783353125677e-05\n",
            "[ 0.00783125 -0.00427634]\n",
            "step=0, loss=0.002208089455962181\n",
            "step=10, loss=0.6849414110183716\n",
            "step=20, loss=2.173147201538086\n",
            "step=30, loss=0.4935149550437927\n",
            "step=40, loss=0.05889866501092911\n",
            "step=50, loss=3.0136804580688477\n",
            "step=60, loss=5.673107147216797\n",
            "step=70, loss=0.15461264550685883\n",
            "step=80, loss=0.04877500236034393\n",
            "step=90, loss=0.08528374135494232\n",
            "step=100, loss=0.01968803070485592\n",
            "step=110, loss=0.003686398733407259\n",
            "step=120, loss=0.0027696460019797087\n",
            "step=130, loss=0.0014576249523088336\n",
            "step=140, loss=0.000338414974976331\n",
            "step=150, loss=8.11421632533893e-05\n",
            "step=160, loss=9.635442984290421e-05\n",
            "step=170, loss=6.263448449317366e-05\n",
            "step=180, loss=4.9440273869549856e-05\n",
            "step=190, loss=4.468212864594534e-05\n",
            "[ 0.0199001  -0.01928967]\n",
            "step=0, loss=0.0022906120866537094\n",
            "step=10, loss=0.021976133808493614\n",
            "step=20, loss=0.003639174159616232\n",
            "step=30, loss=0.019492000341415405\n",
            "step=40, loss=0.008336003869771957\n",
            "step=50, loss=0.001081516733393073\n",
            "step=60, loss=7.949089194880798e-05\n",
            "step=70, loss=7.299408025573939e-05\n",
            "step=80, loss=3.323220516904257e-05\n",
            "step=90, loss=4.013389479951002e-05\n",
            "step=100, loss=4.067654663231224e-05\n",
            "step=110, loss=3.756787918973714e-05\n",
            "step=120, loss=3.214088064851239e-05\n",
            "step=130, loss=2.9974622520967387e-05\n",
            "step=140, loss=3.00521423923783e-05\n",
            "step=150, loss=2.9723534680670127e-05\n",
            "step=160, loss=2.957597462227568e-05\n",
            "step=170, loss=2.9491158784367144e-05\n",
            "step=180, loss=2.9403217922663316e-05\n",
            "step=190, loss=2.9322989576030523e-05\n",
            "[ 0.01388149 -0.00197427]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step=0, loss=0.0023166481405496597\n",
            "step=10, loss=0.7477125525474548\n",
            "step=20, loss=0.18429753184318542\n",
            "step=30, loss=0.1293153613805771\n",
            "step=40, loss=0.028592675924301147\n",
            "step=50, loss=0.005131595768034458\n",
            "step=60, loss=0.0016681910492479801\n",
            "step=70, loss=0.0010111931478604674\n",
            "step=80, loss=0.0007283705053851008\n",
            "step=90, loss=0.00037148778210394084\n",
            "step=100, loss=0.00012265580880921334\n",
            "step=110, loss=0.0001031403080560267\n",
            "step=120, loss=0.00010057831968879327\n",
            "step=130, loss=8.759195043239743e-05\n",
            "step=140, loss=8.834554319037125e-05\n",
            "step=150, loss=8.608156349509954e-05\n",
            "step=160, loss=8.551722567062825e-05\n",
            "step=170, loss=8.486029400955886e-05\n",
            "step=180, loss=8.418610377702862e-05\n",
            "step=190, loss=8.358553168363869e-05\n",
            "[ 0.01674813 -0.00925325]\n",
            "step=0, loss=0.0022675050422549248\n",
            "step=10, loss=4.346724510192871\n",
            "step=20, loss=0.4403804540634155\n",
            "step=30, loss=0.13228002190589905\n",
            "step=40, loss=0.060407113283872604\n",
            "step=50, loss=0.005721199791878462\n",
            "step=60, loss=0.005170976277440786\n",
            "step=70, loss=0.003325133118778467\n",
            "step=80, loss=0.0008292092243209481\n",
            "step=90, loss=0.0003067797515541315\n",
            "step=100, loss=0.0002153683890355751\n",
            "step=110, loss=0.00017677160212770104\n",
            "step=120, loss=0.00017623009625822306\n",
            "step=130, loss=0.0001702338340692222\n",
            "step=140, loss=0.00016635438078083098\n",
            "step=150, loss=0.00016470572154503316\n",
            "step=160, loss=0.0001637614768696949\n",
            "step=170, loss=0.00016291564679704607\n",
            "step=180, loss=0.00016205116116907448\n",
            "step=190, loss=0.0001611891493666917\n",
            "[-0.00549519  0.00843067]\n",
            "step=0, loss=0.0022233373019844294\n",
            "step=10, loss=4.345776557922363\n",
            "step=20, loss=0.8781420588493347\n",
            "step=30, loss=0.028888890519738197\n",
            "step=40, loss=0.15923915803432465\n",
            "step=50, loss=0.06932143121957779\n",
            "step=60, loss=0.016916265711188316\n",
            "step=70, loss=0.004400506149977446\n",
            "step=80, loss=0.0017917485674843192\n",
            "step=90, loss=0.0010104588000103831\n",
            "step=100, loss=0.0005354099557735026\n",
            "step=110, loss=0.0002073468203889206\n",
            "step=120, loss=9.491024684393778e-05\n",
            "step=130, loss=0.00010101228690473363\n",
            "step=140, loss=9.653044980950654e-05\n",
            "step=150, loss=9.072075044969097e-05\n",
            "step=160, loss=9.127688099397346e-05\n",
            "step=170, loss=9.045115439221263e-05\n",
            "step=180, loss=9.048845822690055e-05\n",
            "step=190, loss=9.037850395543501e-05\n",
            "[ 0.01138194 -0.01405895]\n",
            "step=0, loss=0.002181977266445756\n",
            "step=10, loss=1.4198209047317505\n",
            "step=20, loss=0.053173065185546875\n",
            "step=30, loss=0.04186949506402016\n",
            "step=40, loss=0.007151228375732899\n",
            "step=50, loss=0.002212244551628828\n",
            "step=60, loss=0.0003252838214393705\n",
            "step=70, loss=0.00010595605999697\n",
            "step=80, loss=0.00014360700151883066\n",
            "step=90, loss=0.00013812682300340384\n",
            "step=100, loss=0.0001302642049267888\n",
            "step=110, loss=0.00011553972581168637\n",
            "step=120, loss=0.00010103191016241908\n",
            "step=130, loss=9.727369615575299e-05\n",
            "step=140, loss=9.750870958669111e-05\n",
            "step=150, loss=9.669594874139875e-05\n",
            "step=160, loss=9.654184395913035e-05\n",
            "step=170, loss=9.638312621973455e-05\n",
            "step=180, loss=9.626893734093755e-05\n",
            "step=190, loss=9.614516602596268e-05\n",
            "[ 0.00571371 -0.00976582]\n",
            "step=0, loss=0.0021700484212487936\n",
            "step=10, loss=0.8744673132896423\n",
            "step=20, loss=0.14195488393306732\n",
            "step=30, loss=0.028576800599694252\n",
            "step=40, loss=0.008412535302340984\n",
            "step=50, loss=0.0045448774471879005\n",
            "step=60, loss=0.0024637330789119005\n",
            "step=70, loss=0.0004914978635497391\n",
            "step=80, loss=6.585587107110769e-05\n",
            "step=90, loss=0.00013850684626959264\n",
            "step=100, loss=2.898112688853871e-05\n",
            "step=110, loss=3.7917499867035076e-05\n",
            "step=120, loss=2.9189030101406388e-05\n",
            "step=130, loss=2.5972554794861935e-05\n",
            "step=140, loss=2.607059468573425e-05\n",
            "step=150, loss=2.5943769287550822e-05\n",
            "step=160, loss=2.5791392545215786e-05\n",
            "step=170, loss=2.570535616541747e-05\n",
            "step=180, loss=2.5652174372226e-05\n",
            "step=190, loss=2.5609784643165767e-05\n",
            "[ 0.00678921 -0.01478884]\n",
            "step=0, loss=0.0022895175497978926\n",
            "step=10, loss=0.8146330118179321\n",
            "step=20, loss=0.03213892877101898\n",
            "step=30, loss=0.019017716869711876\n",
            "step=40, loss=0.010009109042584896\n",
            "step=50, loss=0.004314611665904522\n",
            "step=60, loss=0.0021217961329966784\n",
            "step=70, loss=0.0008550033089704812\n",
            "step=80, loss=0.00025063520297408104\n",
            "step=90, loss=0.00018116238061338663\n"
          ]
        }
      ],
      "source": [
        "l = []\n",
        "for d in dates:\n",
        "    preds = main_spy_wf(d, data, batch_size=10, steps=200, hidden_size=)\n",
        "    print(preds)\n",
        "    l.append(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3A1Ld6EnKLP",
        "outputId": "b2c709a2-25d2-4674-8895-23d4946d7b25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(47, 47)"
            ]
          },
          "execution_count": 693,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(len(l), len(dates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9RDpncXnKLQ"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame(l, columns=['wh', 'wl'], index=dates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_DOte9JnKLQ",
        "outputId": "2b723983-c399-43cd-81e1-56c4286d5d53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4103/3771618165.py:1: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (1 levels on the left, 2 on the right)\n",
            "  pred_df = pred_df.merge(data[[('hh', 'SPY'), ('ll', 'SPY')]], how='left', left_index=True, right_index=True)\n"
          ]
        }
      ],
      "source": [
        "pred_df = pred_df.merge(data[[('hh', 'SPY'), ('ll', 'SPY')]], how='left', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU4wqShSnKLQ",
        "outputId": "158dcfb6-4519-427b-ba3e-c0bc370700c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wh</th>\n",
              "      <th>wl</th>\n",
              "      <th>(hh, SPY)</th>\n",
              "      <th>(ll, SPY)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-05-01</th>\n",
              "      <td>0.0059252307</td>\n",
              "      <td>-0.0016688667</td>\n",
              "      <td>-0.006689</td>\n",
              "      <td>-0.025299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-02</th>\n",
              "      <td>0.0083300695</td>\n",
              "      <td>-0.0033333711</td>\n",
              "      <td>0.004614</td>\n",
              "      <td>-0.013996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-03</th>\n",
              "      <td>0.0022533685</td>\n",
              "      <td>-0.027214494</td>\n",
              "      <td>0.011768</td>\n",
              "      <td>-0.007108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-04</th>\n",
              "      <td>0.00293497</td>\n",
              "      <td>-0.03109688</td>\n",
              "      <td>0.018876</td>\n",
              "      <td>0.014215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-05</th>\n",
              "      <td>0.007947236</td>\n",
              "      <td>-0.012138411</td>\n",
              "      <td>0.000533</td>\n",
              "      <td>-0.004128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      wh             wl  (hh, SPY)  (ll, SPY)\n",
              "2023-05-01  0.0059252307  -0.0016688667  -0.006689  -0.025299\n",
              "2023-05-02  0.0083300695  -0.0033333711   0.004614  -0.013996\n",
              "2023-05-03  0.0022533685   -0.027214494   0.011768  -0.007108\n",
              "2023-05-04    0.00293497    -0.03109688   0.018876   0.014215\n",
              "2023-05-05   0.007947236   -0.012138411   0.000533  -0.004128"
            ]
          },
          "execution_count": 702,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t24MGnZknKLQ",
        "outputId": "ef0f42bf-14a1-418a-8468-d58d83673123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='wh', ylabel='(hh, SPY)'>"
            ]
          },
          "execution_count": 703,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred_df.plot.scatter('wh', ('hh', 'SPY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2A0o_eAnKLQ",
        "outputId": "aa850174-a8be-4f62-8ba9-39526486574d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='wl', ylabel='(ll, SPY)'>"
            ]
          },
          "execution_count": 704,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred_df.plot.scatter('wl', ('ll', 'SPY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC7aVvQPnKLQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlhv21R-nKLQ",
        "outputId": "26adcb5a-e70d-4187-a49b-c7124dafd4a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['wh', 'wl', ('hh', 'SPY'), ('ll', 'SPY')], dtype='object')"
            ]
          },
          "execution_count": 607,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jaTB_8jnKLQ",
        "outputId": "07841fde-2f65-4c22-81df-3d68e5941c54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Adj Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">Close</th>\n",
              "      <th colspan=\"3\" halign=\"left\">High</th>\n",
              "      <th>Low</th>\n",
              "      <th>...</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Ret</th>\n",
              "      <th>hh</th>\n",
              "      <th>ll</th>\n",
              "      <th>Ret</th>\n",
              "      <th>hh</th>\n",
              "      <th>ll</th>\n",
              "      <th>Ret</th>\n",
              "      <th>hh</th>\n",
              "      <th>ll</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TLT</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>...</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>SPY</th>\n",
              "      <th>SPY</th>\n",
              "      <th>SPY</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>^VIX</th>\n",
              "      <th>TLT</th>\n",
              "      <th>TLT</th>\n",
              "      <th>TLT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-02</th>\n",
              "      <td>244.918686</td>\n",
              "      <td>111.429459</td>\n",
              "      <td>9.77</td>\n",
              "      <td>268.769989</td>\n",
              "      <td>125.489998</td>\n",
              "      <td>9.77</td>\n",
              "      <td>268.809998</td>\n",
              "      <td>126.510002</td>\n",
              "      <td>11.07</td>\n",
              "      <td>267.399994</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.021468</td>\n",
              "      <td>1.006325</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.031730</td>\n",
              "      <td>0.936540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.004782</td>\n",
              "      <td>0.987728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-03</th>\n",
              "      <td>246.467804</td>\n",
              "      <td>111.962280</td>\n",
              "      <td>9.15</td>\n",
              "      <td>270.470001</td>\n",
              "      <td>126.089996</td>\n",
              "      <td>9.15</td>\n",
              "      <td>270.640015</td>\n",
              "      <td>126.199997</td>\n",
              "      <td>9.65</td>\n",
              "      <td>268.959991</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.006325</td>\n",
              "      <td>1.015048</td>\n",
              "      <td>1.004215</td>\n",
              "      <td>0.936540</td>\n",
              "      <td>1.101639</td>\n",
              "      <td>1.007650</td>\n",
              "      <td>1.004782</td>\n",
              "      <td>0.999841</td>\n",
              "      <td>0.981838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-04</th>\n",
              "      <td>247.506668</td>\n",
              "      <td>111.944481</td>\n",
              "      <td>9.22</td>\n",
              "      <td>271.609985</td>\n",
              "      <td>126.070000</td>\n",
              "      <td>9.22</td>\n",
              "      <td>272.160004</td>\n",
              "      <td>126.160004</td>\n",
              "      <td>9.31</td>\n",
              "      <td>270.540009</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.004215</td>\n",
              "      <td>1.016604</td>\n",
              "      <td>1.006664</td>\n",
              "      <td>1.007650</td>\n",
              "      <td>1.093275</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999841</td>\n",
              "      <td>0.997145</td>\n",
              "      <td>0.981994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-05</th>\n",
              "      <td>249.156006</td>\n",
              "      <td>111.624825</td>\n",
              "      <td>9.22</td>\n",
              "      <td>273.420013</td>\n",
              "      <td>125.709999</td>\n",
              "      <td>9.22</td>\n",
              "      <td>273.559998</td>\n",
              "      <td>126.180000</td>\n",
              "      <td>9.54</td>\n",
              "      <td>271.950012</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.006664</td>\n",
              "      <td>1.016458</td>\n",
              "      <td>1.001829</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.101952</td>\n",
              "      <td>1.032538</td>\n",
              "      <td>0.997145</td>\n",
              "      <td>0.999363</td>\n",
              "      <td>0.984806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-08</th>\n",
              "      <td>249.611740</td>\n",
              "      <td>111.553749</td>\n",
              "      <td>9.52</td>\n",
              "      <td>273.920013</td>\n",
              "      <td>125.629997</td>\n",
              "      <td>9.52</td>\n",
              "      <td>274.100006</td>\n",
              "      <td>126.029999</td>\n",
              "      <td>9.89</td>\n",
              "      <td>272.980011</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.001829</td>\n",
              "      <td>1.014602</td>\n",
              "      <td>1.000730</td>\n",
              "      <td>1.032538</td>\n",
              "      <td>1.224790</td>\n",
              "      <td>1.031513</td>\n",
              "      <td>0.999363</td>\n",
              "      <td>0.995304</td>\n",
              "      <td>0.985434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Adj Close                         Close                    \\\n",
              "                   SPY         TLT  ^VIX         SPY         TLT  ^VIX   \n",
              "Date                                                                     \n",
              "2018-01-02  244.918686  111.429459  9.77  268.769989  125.489998  9.77   \n",
              "2018-01-03  246.467804  111.962280  9.15  270.470001  126.089996  9.15   \n",
              "2018-01-04  247.506668  111.944481  9.22  271.609985  126.070000  9.22   \n",
              "2018-01-05  249.156006  111.624825  9.22  273.420013  125.709999  9.22   \n",
              "2018-01-08  249.611740  111.553749  9.52  273.920013  125.629997  9.52   \n",
              "\n",
              "                  High                            Low  ... Volume       Ret  \\\n",
              "                   SPY         TLT   ^VIX         SPY  ...   ^VIX       SPY   \n",
              "Date                                                   ...                    \n",
              "2018-01-02  268.809998  126.510002  11.07  267.399994  ...      0       NaN   \n",
              "2018-01-03  270.640015  126.199997   9.65  268.959991  ...      0  1.006325   \n",
              "2018-01-04  272.160004  126.160004   9.31  270.540009  ...      0  1.004215   \n",
              "2018-01-05  273.559998  126.180000   9.54  271.950012  ...      0  1.006664   \n",
              "2018-01-08  274.100006  126.029999   9.89  272.980011  ...      0  1.001829   \n",
              "\n",
              "                  hh        ll       Ret        hh        ll       Ret  \\\n",
              "                 SPY       SPY      ^VIX      ^VIX      ^VIX       TLT   \n",
              "Date                                                                     \n",
              "2018-01-02  1.021468  1.006325       NaN  1.031730  0.936540       NaN   \n",
              "2018-01-03  1.015048  1.004215  0.936540  1.101639  1.007650  1.004782   \n",
              "2018-01-04  1.016604  1.006664  1.007650  1.093275  1.000000  0.999841   \n",
              "2018-01-05  1.016458  1.001829  1.000000  1.101952  1.032538  0.997145   \n",
              "2018-01-08  1.014602  1.000730  1.032538  1.224790  1.031513  0.999363   \n",
              "\n",
              "                  hh        ll  \n",
              "                 TLT       TLT  \n",
              "Date                            \n",
              "2018-01-02  1.004782  0.987728  \n",
              "2018-01-03  0.999841  0.981838  \n",
              "2018-01-04  0.997145  0.981994  \n",
              "2018-01-05  0.999363  0.984806  \n",
              "2018-01-08  0.995304  0.985434  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 587,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtkYGwatnKLQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuPyQklWnKLQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs7v4JIqnKLQ"
      },
      "source": [
        "#### LSTM implementation X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSAZkIEInKLQ"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import random, grad, jit\n",
        "import optax\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def initialize_params(self, rng):\n",
        "        k1, k2, k3, k4 = random.split(rng, 4)\n",
        "        input_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k1, (self.hidden_size, self.hidden_size))\n",
        "        forget_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k2, (self.hidden_size, self.hidden_size))\n",
        "        output_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k3, (self.hidden_size, self.hidden_size))\n",
        "        cell_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k4, (self.hidden_size, self.hidden_size))\n",
        "        output_weights_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k1, (self.hidden_size, self.output_size))\n",
        "        return input_init, forget_init, output_init, cell_init, output_weights_init\n",
        "\n",
        "    def lstm_cell(self, carry, inputs):\n",
        "        hidden_state, cell_state = carry\n",
        "        concat_input = np.concatenate([inputs, hidden_state], axis=-1)\n",
        "        input_gate = np.sigmoid(np.dot(concat_input, self.input_weights))\n",
        "        forget_gate = np.sigmoid(np.dot(concat_input, self.forget_weights))\n",
        "        output_gate = np.sigmoid(np.dot(concat_input, self.output_weights))\n",
        "        cell_candidate = np.tanh(np.dot(concat_input, self.cell_weights))\n",
        "        new_cell_state = forget_gate * cell_state + input_gate * cell_candidate\n",
        "        new_hidden_state = output_gate * np.tanh(new_cell_state)\n",
        "        return new_hidden_state, (new_hidden_state, new_cell_state)\n",
        "\n",
        "    def forward(self, inputs, params):\n",
        "        self.input_weights, self.forget_weights, self.output_weights, self.cell_weights, self.output_weights = params\n",
        "        _, final_state = jax.lax.scan(self.lstm_cell, (np.zeros((inputs.shape[0], self.hidden_size)),\n",
        "                                                       np.zeros((inputs.shape[0], self.hidden_size))),\n",
        "                                      inputs)\n",
        "        return np.dot(final_state[0], self.output_weights)\n",
        "\n",
        "    def loss(self, inputs, targets, params):\n",
        "        predictions = self.forward(inputs, params)\n",
        "        return np.mean((predictions - targets) ** 2)\n",
        "\n",
        "    def update(self, inputs, targets, params, opt_state):\n",
        "        loss_value, grads = jax.value_and_grad(self.loss)(inputs, targets, params)\n",
        "        updates, new_opt_state = opt_update(grads, opt_state)\n",
        "        new_params = optax.apply_updates(params, updates)\n",
        "        return loss_value, new_params, new_opt_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3D3sbm5nKLQ"
      },
      "outputs": [],
      "source": [
        "def train_lstm_model(model, inputs, targets, num_epochs, learning_rate, batch_size):\n",
        "    rng = jax.random.PRNGKey(0)\n",
        "    params = model.initialize_params(rng)\n",
        "#     opt_init, opt_update, get_params = optax.adam(learning_rate)\n",
        "    optim = optax.adam(learning_rate)\n",
        "    opt_state = optim.init(params)\n",
        "\n",
        "    @jit\n",
        "    def run_epoch(inputs, targets, params, opt_state):\n",
        "        num_batches = inputs.shape[0] // batch_size\n",
        "        losses = []\n",
        "        for batch_idx in range(num_batches):\n",
        "            batch_inputs = inputs[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
        "            batch_targets = targets[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
        "            loss_value, params, opt_state = model.update(batch_inputs, batch_targets, params, opt_state)\n",
        "            losses.append(loss_value)\n",
        "        return np.mean(losses), params, opt_state\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        loss_value, params, opt_state = run_epoch(inputs, targets, params, opt_state)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss_value}\")\n",
        "\n",
        "    return get_params(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I5kQ4jWnKLQ"
      },
      "outputs": [],
      "source": [
        "# Prepare your time series data (inputs and targets)\n",
        "\n",
        "# Define hyperparameters\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "\n",
        "# Create an instance of the LSTM model\n",
        "model = LSTM(hidden_size, output_size)\n",
        "\n",
        "# Train the LSTM model\n",
        "trained_params = train_lstm_model(model, inputs, targets, num_epochs, learning_rate, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Roe5IdQnKLQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1neNdh8nKLQ"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import random, grad, jit\n",
        "import optax\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def initialize_params(self, rng):\n",
        "        k1, k2, k3, k4 = random.split(rng, 4)\n",
        "        input_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k1, (self.input_size, self.hidden_size))\n",
        "        forget_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k2, (self.input_size, self.hidden_size))\n",
        "        output_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k3, (self.input_size, self.hidden_size))\n",
        "        cell_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k4, (self.input_size, self.hidden_size))\n",
        "        output_weights_init = np.sqrt(1.0 / self.hidden_size) * random.normal(k1, (self.hidden_size, self.output_size))\n",
        "        return input_init, forget_init, output_init, cell_init, output_weights_init\n",
        "\n",
        "    def lstm_cell(self, carry, inputs):\n",
        "        hidden_state, cell_state = carry\n",
        "        #concat_input = np.concatenate([inputs, hidden_state], axis=-1)\n",
        "        input_gate = jax.nn.sigmoid(inputs@self.input_weights)\n",
        "        forget_gate = jax.nn.sigmoid(np.dot(inputs, self.forget_weights))\n",
        "        output_gate = jax.nn.sigmoid(np.dot(inputs, self.output_weights))\n",
        "        cell_candidate = jax.nn.tanh(np.dot(inputs, self.cell_weights))\n",
        "        new_cell_state = forget_gate * cell_state + input_gate * cell_candidate\n",
        "        new_hidden_state = output_gate * jax.nn.tanh(new_cell_state)\n",
        "        return new_hidden_state, (new_hidden_state, new_cell_state)\n",
        "\n",
        "    def forward(self, inputs, params):\n",
        "        self.input_weights, self.forget_weights, self.output_weights, self.cell_weights, self.output_weights = params\n",
        "        print(inputs.shape[0], self.hidden_size)\n",
        "        _, final_state = jax.lax.scan(self.lstm_cell, (np.zeros((inputs.shape[0], self.hidden_size)),\n",
        "                                                       np.zeros((inputs.shape[0], self.hidden_size))),\n",
        "                                      inputs)\n",
        "        return np.dot(final_state[0], self.output_weights)\n",
        "\n",
        "    def loss(self, inputs, targets, params):\n",
        "        predictions = self.forward(inputs, params)\n",
        "        return np.mean((predictions - targets) ** 2)\n",
        "\n",
        "    def update(self, inputs, targets, params, opt_state):\n",
        "        loss_value, grads = jax.value_and_grad(self.loss)(inputs, targets, params)\n",
        "        updates, new_opt_state = opt_update(grads, opt_state)\n",
        "        new_params = optax.apply_updates(params, updates)\n",
        "        return loss_value, new_params, new_opt_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ap4yTAXnKLQ"
      },
      "outputs": [],
      "source": [
        "input_size = 50\n",
        "hidden_size = 64\n",
        "output_size = 2\n",
        "model = LSTM(input_size, hidden_size, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRtNliB2nKLQ",
        "outputId": "152ea2e2-d6bf-4375-8886-13211af37930"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(50, 64), (50, 64), (50, 64), (50, 64), (64, 2)]"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "params = model.initialize_params(rng)\n",
        "list(map(lambda i: i.shape, params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcR6VpHXnKLR",
        "outputId": "08837cfc-d123-4996-d305-0c8399b6442e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 64)"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.nn.sigmoid(np.array(df[0:50]).transpose()@params[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTxDHBvQnKLR",
        "outputId": "cc854538-b7d0-43c2-b6af-bc6b22e8c430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 64)"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jax.nn.sigmoid(np.dot(np.array(df[0:50]).transpose(), params[0])).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTwFdI2-nKLR",
        "outputId": "758dd27d-ad81-4eb9-fc11-1a6200f3063c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 64\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Incompatible shapes for dot: got (50,) and (64, 2).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[155], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mforward(np\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m50\u001b[39m])\u001b[38;5;241m.\u001b[39mtranspose(), params)\n",
            "Cell \u001b[0;32mIn[150], line 35\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, inputs, params)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforget_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_weights \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m---> 35\u001b[0m _, final_state \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mscan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm_cell, (np\u001b[38;5;241m.\u001b[39mzeros((inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)),\n\u001b[1;32m     36\u001b[0m                                                np\u001b[38;5;241m.\u001b[39mzeros((inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size))),\n\u001b[1;32m     37\u001b[0m                               inputs)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(final_state[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_weights)\n",
            "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
            "Cell \u001b[0;32mIn[150], line 26\u001b[0m, in \u001b[0;36mLSTM.lstm_cell\u001b[0;34m(self, carry, inputs)\u001b[0m\n\u001b[1;32m     24\u001b[0m input_gate \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid(inputs\u001b[38;5;129m@self\u001b[39m\u001b[38;5;241m.\u001b[39minput_weights)\n\u001b[1;32m     25\u001b[0m forget_gate \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid(np\u001b[38;5;241m.\u001b[39mdot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforget_weights))\n\u001b[0;32m---> 26\u001b[0m output_gate \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid(np\u001b[38;5;241m.\u001b[39mdot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_weights))\n\u001b[1;32m     27\u001b[0m cell_candidate \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mtanh(np\u001b[38;5;241m.\u001b[39mdot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_weights))\n\u001b[1;32m     28\u001b[0m new_cell_state \u001b[38;5;241m=\u001b[39m forget_gate \u001b[38;5;241m*\u001b[39m cell_state \u001b[38;5;241m+\u001b[39m input_gate \u001b[38;5;241m*\u001b[39m cell_candidate\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:3021\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   3019\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mmul(a, b)\n\u001b[1;32m   3020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(a_ndim, b_ndim) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 3021\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdot(a, b, precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b_ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3024\u001b[0m   contract_dims \u001b[38;5;241m=\u001b[39m ((a_ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), (\u001b[38;5;241m0\u001b[39m,))\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/lax/lax.py:698\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dot_general(lhs, rhs, (((lhs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), (\u001b[38;5;241m0\u001b[39m,)), ((), ())),\n\u001b[1;32m    695\u001b[0m                      precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[1;32m    696\u001b[0m                      preferred_element_type\u001b[38;5;241m=\u001b[39mpreferred_element_type)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for dot: got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    699\u001b[0m       lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape))\n",
            "\u001b[0;31mTypeError\u001b[0m: Incompatible shapes for dot: got (50,) and (64, 2)."
          ]
        }
      ],
      "source": [
        "model.forward(np.array(df[0:50]).transpose(), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6_yOo6XnKLS",
        "outputId": "b925bd98-59e5-45bb-f5ad-3ae26d1dd1d3"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "dot_general requires contracting dimensions to have the same shape, got (64,) and (50,).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m50\u001b[39m])\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:258\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    256\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 258\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m    260\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported operand type(s) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopchar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:3088\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   3086\u001b[0m a \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m   3087\u001b[0m b \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m-> 3088\u001b[0m out \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mdot_general(\n\u001b[1;32m   3089\u001b[0m   a, b, (((ndim(a) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), (ndim(b) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m b_is_mat,)), (a_batch, b_batch)),\n\u001b[1;32m   3090\u001b[0m   precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n",
            "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/options/lib/python3.11/site-packages/jax/_src/lax/lax.py:2463\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39msymbolic_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2461\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2462\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2463\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
            "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (64,) and (50,)."
          ]
        }
      ],
      "source": [
        "params[0]@np.array(df[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz9YapwNnKLT",
        "outputId": "5f5d0093-ed32-4831-e32a-a4a7229bc2b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 64)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(np.array(df[0:50]).transpose()@params[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1czkWQYnKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38hToaKInKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-XzO8QPnKLT",
        "outputId": "48f2d086-890c-41ca-ef57-389671d8a59e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.ArrayImpl"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(np.array(df[0:100]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0Ptjw0lnKLT",
        "outputId": "de72a824-4d1f-450d-bf9f-a54ad98a7316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 64) (4,)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mforward(np\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m]))\n",
            "Cell \u001b[0;32mIn[79], line 30\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     29\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[0;32m---> 30\u001b[0m     _, final_state \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mscan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm_cell, initial_state, inputs)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(final_state[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_ho)\n",
            "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
            "Cell \u001b[0;32mIn[79], line 21\u001b[0m, in \u001b[0;36mLSTM.lstm_cell\u001b[0;34m(self, carry, inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlstm_cell\u001b[39m(\u001b[38;5;28mself\u001b[39m, carry, inputs):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(carry\u001b[38;5;241m.\u001b[39mshape, inputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 21\u001b[0m     hidden_state, cell_state \u001b[38;5;241m=\u001b[39m carry\n\u001b[1;32m     22\u001b[0m     gates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_ih) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(hidden_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_fh) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(cell_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_ch)\n\u001b[1;32m     23\u001b[0m     i, f, c, o \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(gates, \u001b[38;5;241m4\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "model.forward(np.array(df[0:100]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU4i-4M3nKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFCNr6GMnKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgusVhGcnKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glYyjT9BnKLT"
      },
      "outputs": [],
      "source": [
        "# Prepare your time series data (inputs and targets)\n",
        "\n",
        "# Define hyperparameters\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "\n",
        "# Train the LSTM model\n",
        "trained_params = train_lstm_model(inputs, targets, num_epochs, learning_rate, batch_size, hidden_size, output_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEZJr6ebnKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue5T-orRnKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNJ7fbAPnKLT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMvQnHw5nKLT",
        "outputId": "a0c0e8d0-f875-42b3-a886-e43d334d5c0f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'jax.nn' has no attribute 'Module'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[85], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLSTM\u001b[39;00m(jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size, num_layers):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'jax.nn' has no attribute 'Module'"
          ]
        }
      ],
      "source": [
        "import jax.numpy as jnp\n",
        "import optax\n",
        "\n",
        "class LSTM(jax.nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.W_i = jax.nn.Dense(hidden_size, activation=\"relu\")\n",
        "        self.W_f = jax.nn.Dense(hidden_size, activation=\"relu\")\n",
        "        self.W_o = jax.nn.Dense(hidden_size, activation=\"relu\")\n",
        "        self.W_c = jax.nn.Dense(hidden_size, activation=\"relu\")\n",
        "\n",
        "    def __call__(self, x, h, c):\n",
        "        # x is the input sequence, h is the hidden state, and c is the cell state\n",
        "\n",
        "        # Compute the forget gate\n",
        "        f = self.W_f(x) * h\n",
        "\n",
        "        # Compute the input gate\n",
        "        i = self.W_i(x) * h\n",
        "\n",
        "        # Compute the output gate\n",
        "        o = self.W_o(x) * h\n",
        "\n",
        "        # Compute the new cell state\n",
        "        c_new = f * c + i * self.W_c(x)\n",
        "\n",
        "        # Compute the new hidden state\n",
        "        h_new = o * jnp.tanh(c_new)\n",
        "\n",
        "        return h_new, c_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU89we43nKLT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "kerascore",
      "language": "python",
      "name": "kerascore"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}